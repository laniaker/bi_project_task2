{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "560946ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Ziel-Dataset gefunden: taxi-bi-project.aggregational\n"
     ]
    }
   ],
   "source": [
    "# Zelle 1: Setup & Config\n",
    "from google.cloud import bigquery\n",
    "import pandas as pd\n",
    "import logging\n",
    "\n",
    "# Config\n",
    "PROJECT_ID = \"taxi-bi-project\"  \n",
    "DIM_DATASET = \"dimensional\"     # Quelle (Star Schema)\n",
    "AGG_DATASET = \"aggregational\"       # Ziel (Data Marts)\n",
    "\n",
    "client = bigquery.Client(project=PROJECT_ID)\n",
    "\n",
    "# Hilfsfunktion, um Datasets zu finden/erstellen\n",
    "def create_dataset_if_not_exists(dataset_id):\n",
    "    full_dataset_id = f\"{PROJECT_ID}.{dataset_id}\"\n",
    "    try:\n",
    "        client.get_dataset(full_dataset_id)\n",
    "        print(f\"‚úÖ Ziel-Dataset gefunden: {full_dataset_id}\")\n",
    "    except:\n",
    "        print(f\"Erstelle neues Dataset: {full_dataset_id} ...\")\n",
    "        # Wir holen uns die Region vom Quell-Dataset, damit alles gleich liegt (EU/US)\n",
    "        src_ds = client.get_dataset(f\"{PROJECT_ID}.{DIM_DATASET}\")\n",
    "        new_ds = bigquery.Dataset(full_dataset_id)\n",
    "        new_ds.location = src_ds.location\n",
    "        client.create_dataset(new_ds)\n",
    "        print(f\"‚úÖ Dataset erstellt (Region: {src_ds.location})\")\n",
    "\n",
    "create_dataset_if_not_exists(AGG_DATASET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0ae9323a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1. Erstelle Tabelle: agg_monthly_kpis ---\n",
      "‚úÖ agg_monthly_kpis erfolgreich erstellt.\n"
     ]
    }
   ],
   "source": [
    "# Zelle 2: Aggregation 1 - Monthly KPIs (Management View)\n",
    "# Diese Tabelle beantwortet: \"Wie entwickeln sich Umsatz und Fahrtenzahlen?\"\n",
    "\n",
    "def create_monthly_kpis():\n",
    "    print(\"--- 1. Erstelle Tabelle: agg_monthly_kpis ---\")\n",
    "    \n",
    "    sql = f\"\"\"\n",
    "    CREATE OR REPLACE TABLE `{PROJECT_ID}.{AGG_DATASET}.agg_monthly_kpis`\n",
    "    AS\n",
    "    SELECT\n",
    "        -- Dimensionen (Woran wollen wir schneiden?)\n",
    "        d.year,\n",
    "        d.month,\n",
    "        d.month_name,\n",
    "        d.quarter,\n",
    "        f.source_system,      -- Yellow vs Green vs FHV\n",
    "        v.vendor_name,        -- Creative Mobile vs Uber/Lyft Bases\n",
    "        p.payment_description, -- Cash vs Credit\n",
    "        \n",
    "        -- Metriken (Hier wird gerechnet!)\n",
    "        COUNT(f.trip_id) AS total_trips,\n",
    "        \n",
    "        -- Summen (Runden auf 2 Nachkommastellen spart Speicher und sieht besser aus)\n",
    "        ROUND(SUM(f.total_amount), 2) AS total_revenue,\n",
    "        ROUND(SUM(f.fare_amount), 2) AS total_fare,\n",
    "        ROUND(SUM(f.tip_amount), 2) AS total_tips,\n",
    "        \n",
    "        -- Durchschnitte (KPIs)\n",
    "        ROUND(AVG(f.total_amount), 2) AS avg_ticket_size,\n",
    "        ROUND(AVG(f.trip_distance), 2) AS avg_distance_miles,\n",
    "        ROUND(AVG(f.duration_minutes), 1) AS avg_duration_min\n",
    "\n",
    "    FROM `{PROJECT_ID}.{DIM_DATASET}.Fact_Trips` f\n",
    "    \n",
    "    -- JOINs zum Star Schema\n",
    "    LEFT JOIN `{PROJECT_ID}.{DIM_DATASET}.dim_date` d ON f.pickup_date_key = d.date_key\n",
    "    LEFT JOIN `{PROJECT_ID}.{DIM_DATASET}.dim_vendor` v ON f.vendor_id = v.vendor_id\n",
    "    LEFT JOIN `{PROJECT_ID}.{DIM_DATASET}.dim_payment_type` p ON f.payment_type_id = p.payment_type_id\n",
    "\n",
    "    -- FILTER:\n",
    "    -- Wir wollen hier nur \"echte\" Fahrten f√ºr die Statistik.\n",
    "    -- Wir schlie√üen 0$-Fahrten (Geister) aus.\n",
    "    -- Aber: Deine 3.80$ Fahrt (Short Trip) bleibt drin, weil total_amount > 0!\n",
    "    WHERE f.total_amount > 0\n",
    "    \n",
    "    GROUP BY 1, 2, 3, 4, 5, 6, 7\n",
    "    ORDER BY year DESC, month DESC, total_revenue DESC\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        job = client.query(sql)\n",
    "        job.result() # Warten auf Fertigstellung\n",
    "        print(\"‚úÖ agg_monthly_kpis erfolgreich erstellt.\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Fehler: {e}\")\n",
    "\n",
    "create_monthly_kpis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0f44a87e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 2. Erstelle Tabelle: agg_geo_stats ---\n",
      "‚úÖ agg_geo_stats erfolgreich erstellt!\n"
     ]
    }
   ],
   "source": [
    "def create_geo_stats_final():\n",
    "    print(\"--- 2. Erstelle Tabelle: agg_geo_stats ---\")\n",
    "    \n",
    "    # Wir nutzen SAFE_CAST und FORMAT_DATE, um sicherzugehen, dass der Key matcht\n",
    "    sql = f\"\"\"\n",
    "    CREATE OR REPLACE TABLE `{PROJECT_ID}.{AGG_DATASET}.agg_geo_stats` AS\n",
    "    SELECT\n",
    "        d.year,\n",
    "        d.quarter,\n",
    "        loc.borough AS pickup_borough,\n",
    "        loc.zone AS pickup_zone,\n",
    "        IFNULL(loc.service_zone, 'Other') AS service_zone,\n",
    "        f.source_system,\n",
    "        \n",
    "        COUNT(f.trip_id) AS pickup_count,\n",
    "        ROUND(SUM(f.total_amount), 0) AS total_revenue_generated,\n",
    "        ROUND(AVG(f.tip_amount), 2) AS avg_tip_here\n",
    "\n",
    "    FROM `{PROJECT_ID}.{DIM_DATASET}.Fact_Trips` f\n",
    "    \n",
    "    -- JOIN zur Datumstabelle\n",
    "    -- Wir wandeln das Trip-Datum in das Format YYYYMMDD um (Standard f√ºr date_key)\n",
    "    LEFT JOIN `{PROJECT_ID}.{DIM_DATASET}.dim_date` d \n",
    "        ON CAST(FORMAT_DATE('%Y%m%d', DATE(f.pickup_datetime)) AS INT64) = CAST(d.date_key AS INT64)\n",
    "        \n",
    "    LEFT JOIN `{PROJECT_ID}.{DIM_DATASET}.dim_location` loc \n",
    "        ON f.pickup_location_id = loc.location_id\n",
    "\n",
    "    WHERE f.total_amount > 0 \n",
    "    GROUP BY 1, 2, 3, 4, 5, 6\n",
    "    ORDER BY pickup_count DESC\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        client.query(sql).result()\n",
    "        print(\"‚úÖ agg_geo_stats erfolgreich erstellt!\")\n",
    "    except Exception as e:\n",
    "        # Falls date_key doch ein DATE-Typ ist, w Fallback:\n",
    "    \n",
    "        fallback_sql = sql.replace(\n",
    "            \"CAST(FORMAT_DATE('%Y%m%d', DATE(f.pickup_datetime)) AS INT64) = CAST(d.date_key AS INT64)\",\n",
    "            \"DATE(f.pickup_datetime) = d.date_key\"\n",
    "        )\n",
    "        try:\n",
    "            client.query(fallback_sql).result()\n",
    "            print(\"‚úÖ agg_geo_stats erfolgreich erstellt!\")\n",
    "        except Exception as e_inner:\n",
    "            print(f\"Kritischer Fehler: {e_inner}\")\n",
    "\n",
    "create_geo_stats_final()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "099ade7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- CHECK: Monthly KPIs (Top 5 Rows) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lania/Documents/GitHub/bi_project_task2/.venv/lib/python3.12/site-packages/google/cloud/bigquery/table.py:1994: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " year month_name source_system  total_trips  total_revenue  avg_ticket_size\n",
      " 2010       June        YELLOW      4628917    48508294.19            10.48\n",
      " 2011       June        YELLOW      4232780    44625418.33            10.54\n",
      " 2010       June        YELLOW      4225814    43097295.83            10.20\n",
      " 2011       June        YELLOW      4108120    44230599.26            10.77\n",
      " 2015       June        YELLOW      4056209    73857571.43            18.21\n",
      "\n",
      "--- CHECK: Geo Stats (Top 5 Zones) ---\n",
      "pickup_borough           pickup_zone source_system  pickup_count  total_revenue_generated\n",
      "     Manhattan Upper East Side South        YELLOW        541769                5080112.0\n",
      "     Manhattan        Midtown Center        YELLOW        532814                5729221.0\n",
      "     Manhattan Upper East Side South        YELLOW        530182                5210931.0\n",
      "     Manhattan Upper East Side South        YELLOW        522302                5185967.0\n",
      "     Manhattan        Midtown Center        YELLOW        513124                5759794.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lania/Documents/GitHub/bi_project_task2/.venv/lib/python3.12/site-packages/google/cloud/bigquery/table.py:1994: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Zelle 4: Quality Check (Kurzer Blick auf das Ergebnis)\n",
    "# Pr√ºfen, ob die Tabellen gef√ºllt sind und die Geisterfahrten weg sind\n",
    "\n",
    "def check_aggregation():\n",
    "    print(\"\\n--- CHECK: Monthly KPIs (Top 5 Rows) ---\")\n",
    "    query_kpi = f\"\"\"\n",
    "    SELECT year, month_name, source_system, total_trips, total_revenue, avg_ticket_size \n",
    "    FROM `{PROJECT_ID}.{AGG_DATASET}.agg_monthly_kpis` \n",
    "    ORDER BY total_trips DESC \n",
    "    LIMIT 5\n",
    "    \"\"\"\n",
    "    print(client.query(query_kpi).to_dataframe().to_string(index=False))\n",
    "\n",
    "    print(\"\\n--- CHECK: Geo Stats (Top 5 Zones) ---\")\n",
    "    query_geo = f\"\"\"\n",
    "    SELECT pickup_borough, pickup_zone, source_system, pickup_count, total_revenue_generated\n",
    "    FROM `{PROJECT_ID}.{AGG_DATASET}.agg_geo_stats`\n",
    "    WHERE pickup_zone != 'NV' -- Wir ignorieren kurz die Unknowns\n",
    "    ORDER BY pickup_count DESC\n",
    "    LIMIT 5\n",
    "    \"\"\"\n",
    "    print(client.query(query_geo).to_dataframe().to_string(index=False))\n",
    "\n",
    "check_aggregation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2c069628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 3. Erstelle Tabelle: agg_time_trends ---\n",
      "‚úÖ agg_time_trends erstellt.\n"
     ]
    }
   ],
   "source": [
    "def create_time_trends():\n",
    "    print(\"--- 3. Erstelle Tabelle: agg_time_trends ---\")\n",
    "    \n",
    "    sql = f\"\"\"\n",
    "    CREATE OR REPLACE TABLE `taxi-bi-project.dimensional.dim_date` AS\n",
    "    SELECT\n",
    "        datum AS date_key,\n",
    "        EXTRACT(YEAR FROM datum) AS year,\n",
    "        EXTRACT(MONTH FROM datum) AS month,\n",
    "        FORMAT_DATE('%B', datum) AS month_name,\n",
    "        FORMAT_DATE('%A', datum) AS day_name,             -- WICHTIG: F√ºr dein Skript\n",
    "        EXTRACT(DAYOFWEEK FROM datum) AS day_of_week_num, -- WICHTIG: F√ºr dein Skript\n",
    "        EXTRACT(QUARTER FROM datum) AS quarter,\n",
    "        CASE WHEN EXTRACT(DAYOFWEEK FROM datum) IN (1, 7) THEN TRUE ELSE FALSE END AS is_weekend\n",
    "    FROM UNNEST(GENERATE_DATE_ARRAY('2010-01-01', '2025-12-31')) AS datum;\n",
    "    \"\"\"\n",
    "    try:\n",
    "        client.query(sql).result()\n",
    "        print(\"‚úÖ agg_time_trends erstellt.\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Fehler: {e}\")\n",
    "\n",
    "create_time_trends()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8ca09fc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 4. Erstelle Tabelle: agg_route_stats ---\n",
      "‚úÖ agg_route_stats erfolgreich erstellt.\n"
     ]
    }
   ],
   "source": [
    "def create_route_stats():\n",
    "    print(\"--- 4. Erstelle Tabelle: agg_route_stats ---\")\n",
    "    \n",
    "    # Hinweis: Ich habe LocationID zu location_id ge√§ndert. \n",
    "    # Bitte pr√ºfe, ob die Spalte in deiner dim_location tats√§chlich so hei√üt.\n",
    "    sql = f\"\"\"\n",
    "    CREATE OR REPLACE TABLE `{PROJECT_ID}.{AGG_DATASET}.agg_route_stats` AS\n",
    "    SELECT\n",
    "        d.year,\n",
    "        d.month, -- Empfehlung: Monat hinzuf√ºgen f√ºr bessere Zeitreihen\n",
    "        \n",
    "        -- VON -> NACH\n",
    "        pu.Borough AS pickup_borough,\n",
    "        do.Borough AS dropoff_borough,\n",
    "        \n",
    "        COUNT(*) AS trip_count,\n",
    "        ROUND(AVG(f.total_amount), 2) AS avg_cost,\n",
    "        -- Falls duration_minutes in Fact_Trips existiert:\n",
    "        ROUND(AVG(SAFE_DIVIDE(TIMESTAMP_DIFF(f.dropoff_datetime, f.pickup_datetime, SECOND), 60)), 1) AS avg_duration_min\n",
    "        \n",
    "    FROM `{PROJECT_ID}.{DIM_DATASET}.Fact_Trips` f\n",
    "    -- Join auf deine neue dim_date (oder dim_datetime)\n",
    "    JOIN `{PROJECT_ID}.{DIM_DATASET}.dim_date` d ON DATE(f.pickup_datetime) = d.date_key\n",
    "    -- Achte hier auf den Spaltennamen: location_id vs LocationID\n",
    "    JOIN `{PROJECT_ID}.{DIM_DATASET}.dim_location` pu ON f.pickup_location_id = pu.location_id\n",
    "    JOIN `{PROJECT_ID}.{DIM_DATASET}.dim_location` do ON f.dropoff_location_id = do.location_id\n",
    "    \n",
    "    WHERE f.total_amount > 0 \n",
    "      AND pu.Borough != 'Unknown' \n",
    "      AND do.Borough != 'Unknown'\n",
    "      \n",
    "    GROUP BY 1, 2, 3, 4\n",
    "    ORDER BY trip_count DESC\n",
    "    \"\"\"\n",
    "    try:\n",
    "        client.query(sql).result()\n",
    "        print(\"‚úÖ agg_route_stats erfolgreich erstellt.\")\n",
    "    except Exception as e:\n",
    "        # Detailliertere Fehlerausgabe\n",
    "        print(f\"‚ùå Fehler bei der Erstellung von agg_route_stats: {e}\")\n",
    "\n",
    "create_route_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "56f55d15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 5. Erstelle Tabelle: agg_airport_trips ---\n",
      "‚úÖ agg_airport_trips erstellt.\n"
     ]
    }
   ],
   "source": [
    "def create_airport_stats():\n",
    "    print(\"--- 5. Erstelle Tabelle: agg_airport_trips ---\")\n",
    "    \n",
    "    sql = f\"\"\"\n",
    "    CREATE OR REPLACE TABLE `{PROJECT_ID}.{AGG_DATASET}.agg_airport_trips` AS\n",
    "    SELECT\n",
    "        d.year,\n",
    "        d.month_name,\n",
    "        f.source_system,\n",
    "        \n",
    "        -- War es eine Fahrt ZUM oder VOM Flughafen?\n",
    "        CASE \n",
    "            WHEN rc.rate_description LIKE '%JFK%' OR rc.rate_description LIKE '%Newark%' THEN 'Airport Rate'\n",
    "            ELSE 'Standard Rate to Airport Zone'\n",
    "        END AS trip_category,\n",
    "        \n",
    "        COUNT(*) AS total_trips,\n",
    "        ROUND(AVG(f.total_amount), 2) AS avg_ticket,\n",
    "        ROUND(AVG(f.tip_amount), 2) AS avg_tip\n",
    "        \n",
    "    FROM `{PROJECT_ID}.{DIM_DATASET}.Fact_Trips` f\n",
    "    JOIN `{PROJECT_ID}.{DIM_DATASET}.dim_date` d ON f.pickup_date_key = d.date_key\n",
    "    JOIN `{PROJECT_ID}.{DIM_DATASET}.dim_rate_code` rc ON f.rate_code_id = rc.rate_code_id\n",
    "    \n",
    "    -- Location Filter: 132=JFK, 138=LaGuardia, 1=Newark\n",
    "    WHERE (f.pickup_location_id IN (132, 138, 1) OR f.dropoff_location_id IN (132, 138, 1))\n",
    "      AND f.total_amount > 0\n",
    "      \n",
    "    GROUP BY 1, 2, 3, 4\n",
    "    \"\"\"\n",
    "    try:\n",
    "        client.query(sql).result()\n",
    "        print(\"‚úÖ agg_airport_trips erstellt.\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Fehler: {e}\")\n",
    "\n",
    "create_airport_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ed1c7461",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 8. Erstelle Tabelle: agg_quality_audit ---\n",
      "‚úÖ agg_quality_audit erstellt.\n"
     ]
    }
   ],
   "source": [
    "def create_quality_audit_mart():\n",
    "    print(\"--- 8. Erstelle Tabelle: agg_quality_audit ---\")\n",
    "    sql = f\"\"\"\n",
    "    CREATE OR REPLACE TABLE `{PROJECT_ID}.{AGG_DATASET}.agg_quality_audit` AS\n",
    "    SELECT\n",
    "        DATE_TRUNC(pickup_datetime, MONTH) as month,\n",
    "        source_system,\n",
    "        COUNT(*) as total_trips,\n",
    "        COUNTIF(trip_distance = 0 AND source_system != 'FHV') as gps_failures,\n",
    "        COUNTIF(pickup_location_id IN (263, 264)) as unknown_locations,\n",
    "        COUNTIF(dq_issue_flag = TRUE) as total_issues\n",
    "    FROM `{PROJECT_ID}.{DIM_DATASET}.Fact_Trips`\n",
    "    GROUP BY 1, 2\n",
    "    \"\"\"\n",
    "    client.query(sql).result()\n",
    "    print(\"‚úÖ agg_quality_audit erstellt.\")\n",
    "create_quality_audit_mart()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d92a09a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 7. Erstelle Tabelle: agg_shared_rides ---\n",
      "‚úÖ agg_shared_rides erstellt.\n"
     ]
    }
   ],
   "source": [
    "def create_shared_ride_stats():\n",
    "    print(\"--- 7. Erstelle Tabelle: agg_shared_rides ---\")\n",
    "    sql = f\"\"\"\n",
    "    CREATE OR REPLACE TABLE `{PROJECT_ID}.{AGG_DATASET}.agg_shared_rides` AS\n",
    "    SELECT\n",
    "        d.year,\n",
    "        f.source_system,\n",
    "        f.sr_flag,\n",
    "        COUNT(*) AS trip_count,\n",
    "        ROUND(AVG(f.fare_amount), 2) AS avg_fare -- Nur f√ºr Yellow/Green sinnvoll\n",
    "    FROM `{PROJECT_ID}.{DIM_DATASET}.Fact_Trips` f\n",
    "    JOIN `{PROJECT_ID}.{DIM_DATASET}.dim_date` d ON f.pickup_date_key = d.date_key\n",
    "    GROUP BY 1, 2, 3\n",
    "    \"\"\"\n",
    "    client.query(sql).result()\n",
    "    print(\"‚úÖ agg_shared_rides erstellt.\")\n",
    "create_shared_ride_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7c37255a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- üìä FINAL DATA MART CHECK ---\n",
      "\n",
      "üïê TOP 5 ZEITFENSTER (agg_time_trends):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lania/Documents/GitHub/bi_project_task2/.venv/lib/python3.12/site-packages/google/cloud/bigquery/table.py:1994: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " day_name  hour_of_day source_system  trip_count  avg_fare\n",
      " Thursday           18        YELLOW      429644     29.42\n",
      "Wednesday           18        YELLOW      423982     28.90\n",
      "  Tuesday           18        YELLOW      403973     28.57\n",
      "   Friday           18        YELLOW      397860     28.56\n",
      " Thursday           17        YELLOW      396463     31.39\n",
      "\n",
      "üìç TOP 5 ROUTEN (agg_route_stats):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lania/Documents/GitHub/bi_project_task2/.venv/lib/python3.12/site-packages/google/cloud/bigquery/table.py:1994: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pickup_borough dropoff_borough  trip_count  avg_cost\n",
      "     Manhattan       Manhattan    12410566     10.13\n",
      "     Manhattan       Manhattan    12330416      9.96\n",
      "     Manhattan       Manhattan    12316988      9.62\n",
      "     Manhattan       Manhattan    11819999     11.80\n",
      "     Manhattan       Manhattan    11183007     12.05\n",
      "\n",
      "‚úàÔ∏è FLUGHAFEN STATS (agg_airport_trips):\n",
      " year                 trip_category source_system  total_trips  avg_ticket\n",
      " 2014 Standard Rate to Airport Zone        YELLOW       614827       41.43\n",
      " 2013 Standard Rate to Airport Zone        YELLOW       601767       40.22\n",
      " 2012 Standard Rate to Airport Zone        YELLOW       596237       33.02\n",
      " 2015 Standard Rate to Airport Zone        YELLOW       587991       43.20\n",
      " 2011 Standard Rate to Airport Zone        YELLOW       578500       32.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lania/Documents/GitHub/bi_project_task2/.venv/lib/python3.12/site-packages/google/cloud/bigquery/table.py:1994: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "def check_new_marts():\n",
    "    # Stelle sicher, dass die Variablen passen\n",
    "    PROJECT_ID = \"taxi-bi-project\"\n",
    "    AGG_DATASET = \"aggregational\"\n",
    "    \n",
    "    print(\"--- üìä FINAL DATA MART CHECK ---\")\n",
    "\n",
    "    # 1. RUSH HOUR (Wann ist am meisten los?)\n",
    "    print(\"\\nüïê TOP 5 ZEITFENSTER (agg_time_trends):\")\n",
    "    # Wir sortieren nach trip_count, um die gesch√§ftigsten Stunden zu sehen\n",
    "    sql_time = f\"\"\"\n",
    "    SELECT day_name, hour_of_day, source_system, trip_count, avg_fare\n",
    "    FROM `{PROJECT_ID}.{AGG_DATASET}.agg_time_trends`\n",
    "    ORDER BY trip_count DESC\n",
    "    LIMIT 5\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df_time = client.query(sql_time).to_dataframe()\n",
    "        print(df_time.to_string(index=False))\n",
    "    except Exception as e:\n",
    "        print(f\"Fehler: {e}\")\n",
    "\n",
    "    # 2. ROUTEN (Wer f√§hrt von wo nach wo?)\n",
    "    print(\"\\nüìç TOP 5 ROUTEN (agg_route_stats):\")\n",
    "    sql_routes = f\"\"\"\n",
    "    SELECT pickup_borough, dropoff_borough, trip_count, avg_cost\n",
    "    FROM `{PROJECT_ID}.{AGG_DATASET}.agg_route_stats`\n",
    "    ORDER BY trip_count DESC\n",
    "    LIMIT 5\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df_routes = client.query(sql_routes).to_dataframe()\n",
    "        print(df_routes.to_string(index=False))\n",
    "    except Exception as e:\n",
    "        print(f\"Fehler: {e}\")\n",
    "\n",
    "    # 3. FLUGHAFEN (Die Cash Cows)\n",
    "    print(\"\\n‚úàÔ∏è FLUGHAFEN STATS (agg_airport_trips):\")\n",
    "    sql_air = f\"\"\"\n",
    "    SELECT year, trip_category, source_system, total_trips, avg_ticket\n",
    "    FROM `{PROJECT_ID}.{AGG_DATASET}.agg_airport_trips`\n",
    "    ORDER BY total_trips DESC\n",
    "    LIMIT 5\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df_air = client.query(sql_air).to_dataframe()\n",
    "        print(df_air.to_string(index=False))\n",
    "    except Exception as e:\n",
    "        print(f\"Fehler: {e}\")\n",
    "\n",
    "check_new_marts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "560946ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vincentgoldmann/Documents/GitHub/bi_project_task2/venv/lib/python3.13/site-packages/google/auth/_default.py:108: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK without a quota project. You might receive a \"quota exceeded\" or \"API not enabled\" error. See the following page for troubleshooting: https://cloud.google.com/docs/authentication/adc-troubleshooting/user-creds. \n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Ziel-Dataset gefunden: taxi-bi-project.aggregational\n"
     ]
    }
   ],
   "source": [
    "# Zelle 1: Setup & Config\n",
    "from google.cloud import bigquery\n",
    "import pandas as pd\n",
    "import logging\n",
    "\n",
    "# Config\n",
    "PROJECT_ID = \"taxi-bi-project\"  \n",
    "DIM_DATASET = \"dimensional\"     # Quelle (Star Schema)\n",
    "AGG_DATASET = \"aggregational\"       # Ziel (Data Marts)\n",
    "\n",
    "client = bigquery.Client(project=PROJECT_ID)\n",
    "\n",
    "# Hilfsfunktion, um Datasets zu finden/erstellen\n",
    "def create_dataset_if_not_exists(dataset_id):\n",
    "    full_dataset_id = f\"{PROJECT_ID}.{dataset_id}\"\n",
    "    try:\n",
    "        client.get_dataset(full_dataset_id)\n",
    "        print(f\"‚úÖ Ziel-Dataset gefunden: {full_dataset_id}\")\n",
    "    except:\n",
    "        print(f\"Erstelle neues Dataset: {full_dataset_id} ...\")\n",
    "        # Wir holen uns die Region vom Quell-Dataset, damit alles gleich liegt (EU/US)\n",
    "        src_ds = client.get_dataset(f\"{PROJECT_ID}.{DIM_DATASET}\")\n",
    "        new_ds = bigquery.Dataset(full_dataset_id)\n",
    "        new_ds.location = src_ds.location\n",
    "        client.create_dataset(new_ds)\n",
    "        print(f\"‚úÖ Dataset erstellt (Region: {src_ds.location})\")\n",
    "\n",
    "create_dataset_if_not_exists(AGG_DATASET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ae9323a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1. Erstelle Tabelle: agg_monthly_kpis ---\n",
      "‚úÖ agg_monthly_kpis erfolgreich erstellt.\n"
     ]
    }
   ],
   "source": [
    "# Zelle 2: Aggregation 1 - Monthly KPIs (Management View)\n",
    "# Diese Tabelle beantwortet: \"Wie entwickeln sich Umsatz und Fahrtenzahlen?\"\n",
    "\n",
    "def create_monthly_kpis():\n",
    "    print(\"--- 1. Erstelle Tabelle: agg_monthly_kpis ---\")\n",
    "    \n",
    "    sql = f\"\"\"\n",
    "    CREATE OR REPLACE TABLE `{PROJECT_ID}.{AGG_DATASET}.agg_monthly_kpis`\n",
    "    AS\n",
    "    SELECT\n",
    "        -- Dimensionen (Woran wollen wir schneiden?)\n",
    "        d.year,\n",
    "        d.month,\n",
    "        d.month_name,\n",
    "        d.quarter,\n",
    "        f.source_system,      -- Yellow vs Green vs FHV\n",
    "        v.vendor_name,        -- Creative Mobile vs Uber/Lyft Bases\n",
    "        p.payment_description, -- Cash vs Credit\n",
    "        \n",
    "        -- Metriken (Hier wird gerechnet!)\n",
    "        COUNT(f.trip_id) AS total_trips,\n",
    "        \n",
    "        -- Summen (Runden auf 2 Nachkommastellen spart Speicher und sieht besser aus)\n",
    "        ROUND(SUM(f.total_amount), 2) AS total_revenue,\n",
    "        ROUND(SUM(f.fare_amount), 2) AS total_fare,\n",
    "        ROUND(SUM(f.tip_amount), 2) AS total_tips,\n",
    "        \n",
    "        -- Durchschnitte (KPIs)\n",
    "        ROUND(AVG(f.total_amount), 2) AS avg_ticket_size,\n",
    "        ROUND(AVG(f.trip_distance), 2) AS avg_distance_miles,\n",
    "        ROUND(AVG(f.duration_minutes), 1) AS avg_duration_min\n",
    "\n",
    "    FROM `{PROJECT_ID}.{DIM_DATASET}.Fact_Trips` f\n",
    "    \n",
    "    -- JOINs zum Star Schema\n",
    "    LEFT JOIN `{PROJECT_ID}.{DIM_DATASET}.dim_date` d ON f.pickup_date_key = d.date_key\n",
    "    LEFT JOIN `{PROJECT_ID}.{DIM_DATASET}.dim_vendor` v ON f.vendor_id = v.vendor_id\n",
    "    LEFT JOIN `{PROJECT_ID}.{DIM_DATASET}.dim_payment_type` p ON f.payment_type_id = p.payment_type_id\n",
    "\n",
    "    -- FILTER:\n",
    "    -- Wir wollen hier nur \"echte\" Fahrten f√ºr die Statistik.\n",
    "    -- Wir schlie√üen 0$-Fahrten (Geister) aus.\n",
    "    -- Aber: Deine 3.80$ Fahrt (Short Trip) bleibt drin, weil total_amount > 0!\n",
    "    WHERE f.total_amount > 0\n",
    "    \n",
    "    GROUP BY 1, 2, 3, 4, 5, 6, 7\n",
    "    ORDER BY year DESC, month DESC, total_revenue DESC\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        job = client.query(sql)\n",
    "        job.result() # Warten auf Fertigstellung\n",
    "        print(\"‚úÖ agg_monthly_kpis erfolgreich erstellt.\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Fehler: {e}\")\n",
    "\n",
    "create_monthly_kpis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f44a87e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 2. Erstelle Tabelle: agg_geo_stats ---\n",
      "‚úÖ agg_geo_stats erfolgreich erstellt.\n"
     ]
    }
   ],
   "source": [
    "# Zelle 3: Aggregation 2 - Geo Stats (Map View)\n",
    "# Diese Tabelle beantwortet: \"Welche Stadtteile sind am lukrativsten?\"\n",
    "\n",
    "def create_geo_stats():\n",
    "    print(\"--- 2. Erstelle Tabelle: agg_geo_stats ---\")\n",
    "    \n",
    "    sql = f\"\"\"\n",
    "    CREATE OR REPLACE TABLE `{PROJECT_ID}.{AGG_DATASET}.agg_geo_stats`\n",
    "    AS\n",
    "    SELECT\n",
    "        d.year,\n",
    "        d.quarter,\n",
    "        \n",
    "        -- Feldnamen auf Kleinschreibung korrigiert\n",
    "        loc.borough AS pickup_borough,\n",
    "        loc.zone AS pickup_zone,\n",
    "        loc.service_zone,\n",
    "        \n",
    "        f.source_system,\n",
    "        \n",
    "        COUNT(f.trip_id) AS pickup_count,\n",
    "        ROUND(SUM(f.total_amount), 0) AS total_revenue_generated,\n",
    "        ROUND(AVG(f.tip_amount), 2) AS avg_tip_here\n",
    "\n",
    "    FROM `{PROJECT_ID}.{DIM_DATASET}.Fact_Trips` f\n",
    "    \n",
    "    -- Korrektur: location_id statt LocationID\n",
    "    LEFT JOIN `{PROJECT_ID}.{DIM_DATASET}.dim_location` loc ON f.pickup_location_id = loc.location_id\n",
    "    LEFT JOIN `{PROJECT_ID}.{DIM_DATASET}.dim_date` d ON f.pickup_date_key = d.date_key\n",
    "\n",
    "    WHERE f.total_amount > 0\n",
    "    \n",
    "    GROUP BY 1, 2, 3, 4, 5, 6\n",
    "    ORDER BY pickup_count DESC\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        job = client.query(sql)\n",
    "        job.result()\n",
    "        print(\"‚úÖ agg_geo_stats erfolgreich erstellt.\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Fehler: {e}\")\n",
    "\n",
    "create_geo_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "099ade7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- CHECK: Monthly KPIs (Top 5 Rows) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lania/Documents/GitHub/bi_project_task2/.venv/lib/python3.12/site-packages/google/cloud/bigquery/table.py:1994: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " year month_name source_system  total_trips  total_revenue  avg_ticket_size\n",
      " <NA>       None        YELLOW     18583128   212632111.82            11.44\n",
      " <NA>       None        YELLOW     18571532   207398754.56            11.17\n",
      " <NA>       None        YELLOW     17350741   278040333.89            16.02\n",
      " <NA>       None        YELLOW     16939149   267008644.23            15.76\n",
      " 2015       June        YELLOW      4056201    73857611.68            18.21\n",
      "\n",
      "--- CHECK: Geo Stats (Top 5 Zones) ---\n",
      "pickup_borough               pickup_zone source_system  pickup_count  total_revenue_generated\n",
      "     Manhattan     Upper East Side South        YELLOW       2577047               27047460.0\n",
      "     Manhattan            Midtown Center        YELLOW       2472275               30124537.0\n",
      "     Manhattan              East Village        YELLOW       2390112               29673556.0\n",
      "     Manhattan Times Sq/Theatre District        YELLOW       2374174               31971137.0\n",
      "     Manhattan              Midtown East        YELLOW       2365586               29162290.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lania/Documents/GitHub/bi_project_task2/.venv/lib/python3.12/site-packages/google/cloud/bigquery/table.py:1994: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Zelle 4: Quality Check (Kurzer Blick auf das Ergebnis)\n",
    "# Pr√ºfen, ob die Tabellen gef√ºllt sind und die Geisterfahrten weg sind\n",
    "\n",
    "def check_aggregation():\n",
    "    print(\"\\n--- CHECK: Monthly KPIs (Top 5 Rows) ---\")\n",
    "    query_kpi = f\"\"\"\n",
    "    SELECT year, month_name, source_system, total_trips, total_revenue, avg_ticket_size \n",
    "    FROM `{PROJECT_ID}.{AGG_DATASET}.agg_monthly_kpis` \n",
    "    ORDER BY total_trips DESC \n",
    "    LIMIT 5\n",
    "    \"\"\"\n",
    "    print(client.query(query_kpi).to_dataframe().to_string(index=False))\n",
    "\n",
    "    print(\"\\n--- CHECK: Geo Stats (Top 5 Zones) ---\")\n",
    "    query_geo = f\"\"\"\n",
    "    SELECT pickup_borough, pickup_zone, source_system, pickup_count, total_revenue_generated\n",
    "    FROM `{PROJECT_ID}.{AGG_DATASET}.agg_geo_stats`\n",
    "    WHERE pickup_zone != 'NV' -- Wir ignorieren kurz die Unknowns\n",
    "    ORDER BY pickup_count DESC\n",
    "    LIMIT 5\n",
    "    \"\"\"\n",
    "    print(client.query(query_geo).to_dataframe().to_string(index=False))\n",
    "\n",
    "check_aggregation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2c069628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 3. Erstelle Tabelle: agg_time_trends ---\n",
      "‚úÖ agg_time_trends erstellt.\n"
     ]
    }
   ],
   "source": [
    "def create_time_trends():\n",
    "    print(\"--- 3. Erstelle Tabelle: agg_time_trends ---\")\n",
    "    \n",
    "    sql = f\"\"\"\n",
    "    CREATE OR REPLACE TABLE `taxi-bi-project.dimensional.dim_date` AS\n",
    "    SELECT\n",
    "        datum AS date_key,\n",
    "        EXTRACT(YEAR FROM datum) AS year,\n",
    "        EXTRACT(MONTH FROM datum) AS month,\n",
    "        FORMAT_DATE('%B', datum) AS month_name,\n",
    "        FORMAT_DATE('%A', datum) AS day_name,             -- WICHTIG: F√ºr dein Skript\n",
    "        EXTRACT(DAYOFWEEK FROM datum) AS day_of_week_num, -- WICHTIG: F√ºr dein Skript\n",
    "        EXTRACT(QUARTER FROM datum) AS quarter,\n",
    "        CASE WHEN EXTRACT(DAYOFWEEK FROM datum) IN (1, 7) THEN TRUE ELSE FALSE END AS is_weekend\n",
    "    FROM UNNEST(GENERATE_DATE_ARRAY('2010-01-01', '2025-12-31')) AS datum;\n",
    "    \"\"\"\n",
    "    try:\n",
    "        client.query(sql).result()\n",
    "        print(\"‚úÖ agg_time_trends erstellt.\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Fehler: {e}\")\n",
    "\n",
    "create_time_trends()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8ca09fc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 4. Erstelle Tabelle: agg_route_stats ---\n",
      "‚ùå Fehler: 400 Name LocationID not found inside pu at [20:85]; reason: invalidQuery, location: query, message: Name LocationID not found inside pu at [20:85]\n",
      "\n",
      "Location: EU\n",
      "Job ID: 9507c2d4-584c-44a9-b219-90b31158dc8c\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def create_route_stats():\n",
    "    print(\"--- 4. Erstelle Tabelle: agg_route_stats ---\")\n",
    "    \n",
    "    sql = f\"\"\"\n",
    "    CREATE OR REPLACE TABLE `{PROJECT_ID}.{AGG_DATASET}.agg_route_stats` AS\n",
    "    SELECT\n",
    "        d.year,\n",
    "        \n",
    "        -- VON -> NACH\n",
    "        pu.Borough AS pickup_borough,\n",
    "        do.Borough AS dropoff_borough,\n",
    "        \n",
    "        -- Optional: Wenn du es feiner willst, nimm die Zonen dazu (wird aber gr√∂√üer)\n",
    "        -- pu.Zone as pickup_zone,\n",
    "        -- do.Zone as dropoff_zone,\n",
    "        \n",
    "        COUNT(*) AS trip_count,\n",
    "        ROUND(AVG(f.total_amount), 2) AS avg_cost,\n",
    "        ROUND(AVG(f.duration_minutes), 1) AS avg_duration\n",
    "        \n",
    "    FROM `{PROJECT_ID}.{DIM_DATASET}.Fact_Trips` f\n",
    "    JOIN `{PROJECT_ID}.{DIM_DATASET}.dim_date` d ON f.pickup_date_key = d.date_key\n",
    "    JOIN `{PROJECT_ID}.{DIM_DATASET}.dim_location` pu ON f.pickup_location_id = pu.LocationID\n",
    "    JOIN `{PROJECT_ID}.{DIM_DATASET}.dim_location` do ON f.dropoff_location_id = do.LocationID\n",
    "    \n",
    "    WHERE f.total_amount > 0 \n",
    "      AND pu.Borough != 'Unknown' \n",
    "      AND do.Borough != 'Unknown'\n",
    "      \n",
    "    GROUP BY 1, 2, 3\n",
    "    ORDER BY trip_count DESC\n",
    "    \"\"\"\n",
    "    try:\n",
    "        client.query(sql).result()\n",
    "        print(\"‚úÖ agg_route_stats erstellt.\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Fehler: {e}\")\n",
    "\n",
    "create_route_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "56f55d15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 5. Erstelle Tabelle: agg_airport_trips ---\n",
      "‚úÖ agg_airport_trips erstellt.\n"
     ]
    }
   ],
   "source": [
    "def create_airport_stats():\n",
    "    print(\"--- 5. Erstelle Tabelle: agg_airport_trips ---\")\n",
    "    \n",
    "    sql = f\"\"\"\n",
    "    CREATE OR REPLACE TABLE `{PROJECT_ID}.{AGG_DATASET}.agg_airport_trips` AS\n",
    "    SELECT\n",
    "        d.year,\n",
    "        d.month_name,\n",
    "        f.source_system,\n",
    "        \n",
    "        -- War es eine Fahrt ZUM oder VOM Flughafen?\n",
    "        CASE \n",
    "            WHEN rc.rate_description LIKE '%JFK%' OR rc.rate_description LIKE '%Newark%' THEN 'Airport Rate'\n",
    "            ELSE 'Standard Rate to Airport Zone'\n",
    "        END AS trip_category,\n",
    "        \n",
    "        COUNT(*) AS total_trips,\n",
    "        ROUND(AVG(f.total_amount), 2) AS avg_ticket,\n",
    "        ROUND(AVG(f.tip_amount), 2) AS avg_tip\n",
    "        \n",
    "    FROM `{PROJECT_ID}.{DIM_DATASET}.Fact_Trips` f\n",
    "    JOIN `{PROJECT_ID}.{DIM_DATASET}.dim_date` d ON f.pickup_date_key = d.date_key\n",
    "    JOIN `{PROJECT_ID}.{DIM_DATASET}.dim_rate_code` rc ON f.rate_code_id = rc.rate_code_id\n",
    "    \n",
    "    -- Location Filter: 132=JFK, 138=LaGuardia, 1=Newark\n",
    "    WHERE (f.pickup_location_id IN (132, 138, 1) OR f.dropoff_location_id IN (132, 138, 1))\n",
    "      AND f.total_amount > 0\n",
    "      \n",
    "    GROUP BY 1, 2, 3, 4\n",
    "    \"\"\"\n",
    "    try:\n",
    "        client.query(sql).result()\n",
    "        print(\"‚úÖ agg_airport_trips erstellt.\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Fehler: {e}\")\n",
    "\n",
    "create_airport_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ed1c7461",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_quality_audit_mart():\n",
    "    print(\"--- 8. Erstelle Tabelle: agg_quality_audit ---\")\n",
    "    sql = f\"\"\"\n",
    "    CREATE OR REPLACE TABLE `{PROJECT_ID}.{AGG_DATASET}.agg_quality_audit` AS\n",
    "    SELECT\n",
    "        DATE_TRUNC(pickup_datetime, MONTH) as month,\n",
    "        source_system,\n",
    "        COUNT(*) as total_trips,\n",
    "        COUNTIF(trip_distance = 0 AND source_system != 'FHV') as gps_failures,\n",
    "        COUNTIF(pickup_location_id IN (263, 264)) as unknown_locations,\n",
    "        COUNTIF(dq_issue_flag = TRUE) as total_issues\n",
    "    FROM `{PROJECT_ID}.{DIM_DATASET}.Fact_Trips`\n",
    "    GROUP BY 1, 2\n",
    "    \"\"\"\n",
    "    client.query(sql).result()\n",
    "    print(\"‚úÖ agg_quality_audit erstellt.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d92a09a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_shared_ride_stats():\n",
    "    print(\"--- 7. Erstelle Tabelle: agg_shared_rides ---\")\n",
    "    sql = f\"\"\"\n",
    "    CREATE OR REPLACE TABLE `{PROJECT_ID}.{AGG_DATASET}.agg_shared_rides` AS\n",
    "    SELECT\n",
    "        d.year,\n",
    "        f.source_system,\n",
    "        f.sr_flag,\n",
    "        COUNT(*) AS trip_count,\n",
    "        ROUND(AVG(f.fare_amount), 2) AS avg_fare -- Nur f√ºr Yellow/Green sinnvoll\n",
    "    FROM `{PROJECT_ID}.{DIM_DATASET}.Fact_Trips` f\n",
    "    JOIN `{PROJECT_ID}.{DIM_DATASET}.dim_date` d ON f.pickup_date_key = d.date_key\n",
    "    GROUP BY 1, 2, 3\n",
    "    \"\"\"\n",
    "    client.query(sql).result()\n",
    "    print(\"‚úÖ agg_shared_rides erstellt.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7c37255a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- üìä FINAL DATA MART CHECK ---\n",
      "\n",
      "üïê TOP 5 ZEITFENSTER (agg_time_trends):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lania/Documents/GitHub/bi_project_task2/.venv/lib/python3.12/site-packages/google/cloud/bigquery/table.py:1994: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " day_name  hour_of_day source_system  trip_count  avg_fare\n",
      " Thursday           18        YELLOW      429644     29.42\n",
      "Wednesday           18        YELLOW      423982     28.90\n",
      "  Tuesday           18        YELLOW      403973     28.57\n",
      "   Friday           18        YELLOW      397860     28.56\n",
      " Thursday           17        YELLOW      396463     31.39\n",
      "\n",
      "üìç TOP 5 ROUTEN (agg_route_stats):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lania/Documents/GitHub/bi_project_task2/.venv/lib/python3.12/site-packages/google/cloud/bigquery/table.py:1994: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pickup_borough dropoff_borough  trip_count  avg_cost\n",
      "     Manhattan       Manhattan    20908052     20.34\n",
      "     Manhattan       Manhattan     7358395     12.41\n",
      "     Manhattan       Manhattan     6957972     12.28\n",
      "     Manhattan       Manhattan     6223453     12.24\n",
      "     Manhattan       Manhattan     5457148     12.20\n",
      "\n",
      "‚úàÔ∏è FLUGHAFEN STATS (agg_airport_trips):\n",
      " year                 trip_category source_system  total_trips  avg_ticket\n",
      " 2015 Standard Rate to Airport Zone        YELLOW       587996       43.19\n",
      " 2016 Standard Rate to Airport Zone        YELLOW       557057       43.96\n",
      " 2017 Standard Rate to Airport Zone        YELLOW       489819       45.04\n",
      " 2018 Standard Rate to Airport Zone        YELLOW       451924       44.57\n",
      " 2019 Standard Rate to Airport Zone        YELLOW       379443       44.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lania/Documents/GitHub/bi_project_task2/.venv/lib/python3.12/site-packages/google/cloud/bigquery/table.py:1994: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "def check_new_marts():\n",
    "    # Stelle sicher, dass die Variablen passen\n",
    "    PROJECT_ID = \"taxi-bi-project\"\n",
    "    AGG_DATASET = \"aggregational\"\n",
    "    \n",
    "    print(\"--- üìä FINAL DATA MART CHECK ---\")\n",
    "\n",
    "    # 1. RUSH HOUR (Wann ist am meisten los?)\n",
    "    print(\"\\nüïê TOP 5 ZEITFENSTER (agg_time_trends):\")\n",
    "    # Wir sortieren nach trip_count, um die gesch√§ftigsten Stunden zu sehen\n",
    "    sql_time = f\"\"\"\n",
    "    SELECT day_name, hour_of_day, source_system, trip_count, avg_fare\n",
    "    FROM `{PROJECT_ID}.{AGG_DATASET}.agg_time_trends`\n",
    "    ORDER BY trip_count DESC\n",
    "    LIMIT 5\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df_time = client.query(sql_time).to_dataframe()\n",
    "        print(df_time.to_string(index=False))\n",
    "    except Exception as e:\n",
    "        print(f\"Fehler: {e}\")\n",
    "\n",
    "    # 2. ROUTEN (Wer f√§hrt von wo nach wo?)\n",
    "    print(\"\\nüìç TOP 5 ROUTEN (agg_route_stats):\")\n",
    "    sql_routes = f\"\"\"\n",
    "    SELECT pickup_borough, dropoff_borough, trip_count, avg_cost\n",
    "    FROM `{PROJECT_ID}.{AGG_DATASET}.agg_route_stats`\n",
    "    ORDER BY trip_count DESC\n",
    "    LIMIT 5\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df_routes = client.query(sql_routes).to_dataframe()\n",
    "        print(df_routes.to_string(index=False))\n",
    "    except Exception as e:\n",
    "        print(f\"Fehler: {e}\")\n",
    "\n",
    "    # 3. FLUGHAFEN (Die Cash Cows)\n",
    "    print(\"\\n‚úàÔ∏è FLUGHAFEN STATS (agg_airport_trips):\")\n",
    "    sql_air = f\"\"\"\n",
    "    SELECT year, trip_category, source_system, total_trips, avg_ticket\n",
    "    FROM `{PROJECT_ID}.{AGG_DATASET}.agg_airport_trips`\n",
    "    ORDER BY total_trips DESC\n",
    "    LIMIT 5\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df_air = client.query(sql_air).to_dataframe()\n",
    "        print(df_air.to_string(index=False))\n",
    "    except Exception as e:\n",
    "        print(f\"Fehler: {e}\")\n",
    "\n",
    "check_new_marts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "362fa607",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erstelle Tabelle f√ºr Peak Hours: taxi-bi-project.aggregational.agg_peak_hours ...\n",
      "‚úÖ Tabelle 'taxi-bi-project.aggregational.agg_peak_hours' erfolgreich erstellt!\n",
      "   -> Enth√§lt 5979 aggregierte Zeilen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vincentgoldmann/Documents/GitHub/bi_project_task2/venv/lib/python3.13/site-packages/google/cloud/bigquery/table.py:1994: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Funktion f√ºr 1) Peak Hours ‚Äì Taxi Demand\n",
    "def create_agg_peak_hours():\n",
    "    \"\"\"\n",
    "    Erstellt die Tabelle 'agg_peak_hours' im Aggregational Layer.\n",
    "    \n",
    "    Logik:\n",
    "    1. Basis: dimensional.Fact_Trips (Hier sind die Zeitstempel und die Fahrten selbst)\n",
    "    2. Join: dimensional.dim_location (Um statt LocationIDs echte Borough-Namen zu haben)\n",
    "    3. Ergebnis: Eine kleine, schnelle Tabelle, die nur noch Stunden und Anzahl enth√§lt.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Ziel-Tabelle im Aggregational Dataset\n",
    "    table_id = f\"{PROJECT_ID}.{AGG_DATASET}.agg_peak_hours\"\n",
    "    \n",
    "    print(f\"Erstelle Tabelle f√ºr Peak Hours: {table_id} ...\")\n",
    "    \n",
    "    sql = f\"\"\"\n",
    "    CREATE OR REPLACE TABLE `{table_id}` AS\n",
    "    SELECT\n",
    "        -- 1. Zeit aus der Faktentabelle extrahieren\n",
    "        EXTRACT(HOUR FROM f.pickup_datetime) as hour,\n",
    "        EXTRACT(YEAR FROM f.pickup_datetime) as year,\n",
    "        \n",
    "        -- 2. Dimensionen aus Fact (Taxi Typ) und Dim (Borough)\n",
    "        f.source_system as taxi_type,\n",
    "        loc.Borough as borough,\n",
    "        \n",
    "        -- 3. Die eigentliche Messgr√∂√üe (Anzahl Fahrten)\n",
    "        COUNT(f.trip_id) as trip_count\n",
    "        \n",
    "    FROM `{PROJECT_ID}.{DIM_DATASET}.Fact_Trips` f\n",
    "    \n",
    "    -- Hier verbinden wir das Star Schema: Fakt + Dimension\n",
    "    LEFT JOIN `{PROJECT_ID}.{DIM_DATASET}.dim_location` loc \n",
    "        ON f.pickup_location_id = loc.location_id\n",
    "        \n",
    "    WHERE f.pickup_datetime IS NOT NULL\n",
    "    \n",
    "    -- Aggregation auf die Ebene, die das Dashboard braucht\n",
    "    GROUP BY \n",
    "        hour, \n",
    "        year, \n",
    "        taxi_type, \n",
    "        borough\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        # Query ausf√ºhren\n",
    "        job = client.query(sql)\n",
    "        job.result()\n",
    "        print(f\"Tabelle '{table_id}' erfolgreich erstellt!\")\n",
    "        \n",
    "        # Kurzer Check\n",
    "        rows = client.query(f\"SELECT COUNT(*) as cnt FROM `{table_id}`\").to_dataframe()\n",
    "        print(f\"   -> Enth√§lt {rows['cnt'][0]} aggregierte Zeilen.\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Fehler: {e}\")\n",
    "\n",
    "# Ausf√ºhren\n",
    "create_agg_peak_hours()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a39a97a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî® Erstelle Tabelle f√ºr Preis-Statistiken: taxi-bi-project.aggregational.agg_fare_stats ...\n",
      "‚úÖ Tabelle 'taxi-bi-project.aggregational.agg_fare_stats' erfolgreich erstellt!\n",
      "Vorschau (Median Preise):\n",
      " year taxi_type borough  min_fare  q1_fare  median_fare  q3_fare  max_fare  trip_count\n",
      " 2010    YELLOW   Bronx      2.50      5.7          8.1     12.9      28.9       15879\n",
      " 2011    YELLOW   Bronx      2.50      5.7          8.1     12.9      27.7       21179\n",
      " 2012    YELLOW   Bronx      2.50      5.7          8.5     13.7      28.9       16982\n",
      " 2015     GREEN   Bronx      0.01      6.5          9.5     14.5      29.5     1203056\n",
      " 2016     GREEN   Bronx      0.01      7.0         10.0     15.0      31.0      762069\n"
     ]
    }
   ],
   "source": [
    "# Funktion f√ºr 2) Fare Distribution ‚Äì Boxplot Stats\n",
    "def create_agg_fare_stats():\n",
    "    \"\"\"\n",
    "    Erstellt die Tabelle 'agg_fare_stats' im Aggregational Layer.\n",
    "    \n",
    "    Zweck: \n",
    "    Bereitstellung von statistischen Daten f√ºr Boxplots (Preisverteilung).\n",
    "    Anstatt Rohdaten zu laden, berechnen wir Quantile (Min, 25%, Median, 75%, Max).\n",
    "    \n",
    "    Logik:\n",
    "    1. Basis: dimensional.Fact_Trips (f√ºr fare_amount)\n",
    "    2. Join: dimensional.dim_location (f√ºr Boroughs)\n",
    "    3. Berechnung: APPROX_QUANTILES teilt die Daten in 100 Teile.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Ziel-Tabelle\n",
    "    table_id = f\"{PROJECT_ID}.{AGG_DATASET}.agg_fare_stats\"\n",
    "    \n",
    "    print(f\"üî® Erstelle Tabelle f√ºr Preis-Statistiken: {table_id} ...\")\n",
    "    \n",
    "    sql = f\"\"\"\n",
    "    CREATE OR REPLACE TABLE `{table_id}` AS\n",
    "    SELECT\n",
    "        -- 1. Dimensionen f√ºr Filter\n",
    "        EXTRACT(YEAR FROM f.pickup_datetime) as year,\n",
    "        f.source_system as taxi_type,\n",
    "        loc.Borough as borough,\n",
    "        \n",
    "        -- 2. Statistische Kennzahlen f√ºr den Boxplot (BigQuery Magic!)\n",
    "        -- Wir berechnen hier die \"Box\" und die \"Whiskers\" vor.\n",
    "        \n",
    "        APPROX_QUANTILES(f.fare_amount, 100)[OFFSET(0)] as min_fare,\n",
    "        APPROX_QUANTILES(f.fare_amount, 100)[OFFSET(25)] as q1_fare,     -- Unteres Quartil (25%)\n",
    "        APPROX_QUANTILES(f.fare_amount, 100)[OFFSET(50)] as median_fare, -- Der Median (50%)\n",
    "        APPROX_QUANTILES(f.fare_amount, 100)[OFFSET(75)] as q3_fare,     -- Oberes Quartil (75%)\n",
    "        APPROX_QUANTILES(f.fare_amount, 100)[OFFSET(95)] as max_fare,    -- 95% Perzentil (statt echtem Max, um extreme Ausrei√üer auszublenden)\n",
    "        \n",
    "        -- Anzahl der Fahrten zur Einordnung\n",
    "        COUNT(*) as trip_count\n",
    "        \n",
    "    FROM `{PROJECT_ID}.{DIM_DATASET}.Fact_Trips` f\n",
    "    \n",
    "    JOIN `{PROJECT_ID}.{DIM_DATASET}.dim_location` loc \n",
    "        ON f.pickup_location_id = loc.location_id\n",
    "        \n",
    "    WHERE f.fare_amount > 0          -- Nur g√ºltige Fahrten\n",
    "      AND f.fare_amount < 1000       -- Technischer Filter: Unrealistische Werte (>1000$) ignorieren\n",
    "      AND loc.Borough != 'Unknown'   \n",
    "      AND loc.Borough != 'NV'\n",
    "      \n",
    "    GROUP BY \n",
    "        year, \n",
    "        taxi_type, \n",
    "        borough\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        # Query ausf√ºhren\n",
    "        client.query(sql).result()\n",
    "        print(f\"Tabelle '{table_id}' erfolgreich erstellt!\")\n",
    "        \n",
    "        # Vorschau\n",
    "        print(\"Vorschau (Median Preise):\")\n",
    "        df_preview = client.query(f\"SELECT * FROM `{table_id}` LIMIT 5\").to_dataframe()\n",
    "        print(df_preview.to_string(index=False))\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Fehler: {e}\")\n",
    "\n",
    "# Ausf√ºhren\n",
    "create_agg_fare_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d31936c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erstelle Tabelle: taxi-bi-project.aggregational.agg_tip_stats\n",
      "Tabelle 'taxi-bi-project.aggregational.agg_tip_stats' erstellt.\n"
     ]
    }
   ],
   "source": [
    "def create_agg_tip_stats():\n",
    "    # Erstellt die Tabelle f√ºr die Trinkgeld-Analyse.\n",
    "    # Ber√ºcksichtigt nur Kreditkartenzahlungen, da Barzahlungen keine Tip-Informationen enthalten.\n",
    "    \n",
    "    table_id = f\"{PROJECT_ID}.{AGG_DATASET}.agg_tip_stats\"\n",
    "    print(f\"Erstelle Tabelle: {table_id}\")\n",
    "    \n",
    "    sql = f\"\"\"\n",
    "    CREATE OR REPLACE TABLE `{table_id}` AS\n",
    "    SELECT\n",
    "        EXTRACT(YEAR FROM f.pickup_datetime) as year,\n",
    "        f.source_system as taxi_type,\n",
    "        loc.Borough as borough,\n",
    "        \n",
    "        -- Speichern der Summen f√ºr sp√§tere Berechnung des gewichteten Durchschnitts\n",
    "        SUM(f.tip_amount) as total_tip,\n",
    "        SUM(f.fare_amount) as total_fare,\n",
    "        COUNT(*) as card_trips\n",
    "        \n",
    "    FROM `{PROJECT_ID}.{DIM_DATASET}.Fact_Trips` f\n",
    "    JOIN `{PROJECT_ID}.{DIM_DATASET}.dim_location` loc \n",
    "        ON f.pickup_location_id = loc.location_id\n",
    "    JOIN `{PROJECT_ID}.{DIM_DATASET}.dim_payment_type` pay \n",
    "        ON f.payment_type_id = pay.payment_type_id\n",
    "        \n",
    "    WHERE pay.payment_description = 'Credit Card' \n",
    "      AND f.fare_amount > 0\n",
    "      AND loc.Borough NOT IN ('Unknown', 'NV')\n",
    "      \n",
    "    GROUP BY year, taxi_type, borough\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        client.query(sql).result()\n",
    "        print(f\"Tabelle '{table_id}' erstellt.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Fehler: {e}\")\n",
    "\n",
    "create_agg_tip_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "677fc5aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî® Erstelle Tabelle f√ºr Jahres-Trends (Fix): taxi-bi-project.aggregational.agg_demand_years ...\n",
      "‚úÖ Tabelle 'taxi-bi-project.aggregational.agg_demand_years' erfolgreich aktualisiert!\n",
      "   -> FHV Trips in 2016: 1,080 (Sollte jetzt Millionen sein)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vincentgoldmann/Documents/GitHub/bi_project_task2/venv/lib/python3.13/site-packages/google/cloud/bigquery/table.py:1994: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Funktion f√ºr 4) Demand Shift over Years\n",
    "def create_agg_demand_years():\n",
    "    \"\"\"\n",
    "    Erstellt 'agg_demand_years' im Aggregational Layer.\n",
    "    \"\"\"\n",
    "    \n",
    "    table_id = f\"{PROJECT_ID}.{AGG_DATASET}.agg_demand_years\"\n",
    "    \n",
    "    print(f\"üî® Erstelle Tabelle f√ºr Jahres-Trends (Fix): {table_id} ...\")\n",
    "    \n",
    "    sql = f\"\"\"\n",
    "    CREATE OR REPLACE TABLE `{table_id}` AS\n",
    "    SELECT\n",
    "        EXTRACT(YEAR FROM f.pickup_datetime) as year,\n",
    "        f.source_system as taxi_type,\n",
    "        \n",
    "        -- Wenn kein Borough gefunden wird (NULL), nennen wir es 'Unknown'\n",
    "        COALESCE(loc.Borough, 'Unknown') as borough,\n",
    "        \n",
    "        COUNT(*) as total_trips\n",
    "        \n",
    "    FROM `{PROJECT_ID}.{DIM_DATASET}.Fact_Trips` f\n",
    "    \n",
    "     -- LEFT JOIN, damit Fahrten ohne Location erhalten bleiben\n",
    "    LEFT JOIN `{PROJECT_ID}.{DIM_DATASET}.dim_location` loc \n",
    "        ON f.pickup_location_id = loc.location_id\n",
    "        \n",
    "    WHERE f.pickup_datetime IS NOT NULL\n",
    "      \n",
    "    GROUP BY \n",
    "        year, \n",
    "        taxi_type, \n",
    "        borough\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        client.query(sql).result()\n",
    "        print(f\"Tabelle '{table_id}' erfolgreich aktualisiert!\")\n",
    "        \n",
    "        check_sql = f\"\"\"\n",
    "            SELECT sum(total_trips) as cnt \n",
    "            FROM `{table_id}` \n",
    "            WHERE year=2016 AND taxi_type='FHV'\n",
    "        \"\"\"\n",
    "        cnt = client.query(check_sql).to_dataframe()['cnt'][0]\n",
    "        print(f\"   -> FHV Trips in 2016: {cnt:,.0f}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Fehler: {e}\")\n",
    "\n",
    "# Ausf√ºhren\n",
    "create_agg_demand_years()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "55c9f9d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî® Erstelle Wochentags-Tabelle (mit dim_date): taxi-bi-project.aggregational.agg_weekly_patterns ...\n",
      "Fehler: 400 Name day_of_week not found inside d at [10:11]; reason: invalidQuery, location: query, message: Name day_of_week not found inside d at [10:11]\n",
      "\n",
      "Location: EU\n",
      "Job ID: dcd820a8-dcad-409b-a922-4fa0e6bc3e37\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def create_agg_weekly_patterns():\n",
    "    \"\"\"\n",
    "    Erstellt 'agg_weekly_patterns'.\n",
    "    FIX: Nutzt 'day_of_week_num' aus dim_date.\n",
    "    \"\"\"\n",
    "    table_id = f\"{PROJECT_ID}.{AGG_DATASET}.agg_weekly_patterns\"\n",
    "    print(f\"üî® Erstelle Wochentags-Tabelle (Final Fix): {table_id} ...\")\n",
    "    \n",
    "    sql = f\"\"\"\n",
    "    CREATE OR REPLACE TABLE `{table_id}` AS\n",
    "    SELECT\n",
    "        EXTRACT(YEAR FROM f.pickup_datetime) as year,\n",
    "        f.source_system as taxi_type,\n",
    "        COALESCE(loc.Borough, 'Unknown') as borough,\n",
    "        \n",
    "        -- Wochentag-Name (z.B. 'Monday')\n",
    "        d.day_name,\n",
    "        \n",
    "        -- Wochentag-Nummer f√ºr die Sortierung (aus deiner dim_date)\n",
    "        -- Wir nennen es 'day_of_week', damit der Data-Access-Code es sofort findet\n",
    "        d.day_of_week_num as day_of_week,\n",
    "        \n",
    "        EXTRACT(HOUR FROM f.pickup_datetime) as hour,\n",
    "        \n",
    "        COUNT(*) as trip_count\n",
    "        \n",
    "    FROM `{PROJECT_ID}.{DIM_DATASET}.Fact_Trips` f\n",
    "    \n",
    "    LEFT JOIN `{PROJECT_ID}.{DIM_DATASET}.dim_location` loc \n",
    "        ON f.pickup_location_id = loc.location_id\n",
    "        \n",
    "    INNER JOIN `{PROJECT_ID}.{DIM_DATASET}.dim_date` d\n",
    "        ON DATE(f.pickup_datetime) = d.date_key\n",
    "        \n",
    "    WHERE f.pickup_datetime IS NOT NULL\n",
    "      \n",
    "    GROUP BY \n",
    "        year, taxi_type, borough, d.day_name, d.day_of_week_num, hour\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        client.query(sql).result()\n",
    "        print(f\"‚úÖ Tabelle '{table_id}' erfolgreich erstellt!\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Fehler: {e}\")\n",
    "\n",
    "create_agg_weekly_patterns()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "51463f5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî® Erstelle Aggregations-Tabelle (Fare/Dist): taxi-bi-project.aggregational.agg_fare_dist ...\n",
      "‚úÖ Tabelle 'taxi-bi-project.aggregational.agg_fare_dist' erfolgreich erstellt!\n"
     ]
    }
   ],
   "source": [
    "def create_agg_fare_dist():\n",
    "    \"\"\"\n",
    "    Erstellt 'agg_fare_dist'.\n",
    "    Aggregiert Daten in Cluster (Bins) f√ºr Distanz und Preis.\n",
    "    \"\"\"\n",
    "    table_id = f\"{PROJECT_ID}.{AGG_DATASET}.agg_fare_dist\"\n",
    "    print(f\"Erstelle Aggregations-Tabelle (Fare/Dist): {table_id} ...\")\n",
    "    \n",
    "    sql = f\"\"\"\n",
    "    CREATE OR REPLACE TABLE `{table_id}` AS\n",
    "    SELECT\n",
    "        EXTRACT(YEAR FROM f.pickup_datetime) as year,\n",
    "        f.source_system as taxi_type,\n",
    "        COALESCE(loc.Borough, 'Unknown') as borough,\n",
    "        \n",
    "        -- Cluster-Bildung: Distanz auf 0.2 Meilen, Preis auf 1 Dollar gerundet\n",
    "        ROUND(f.trip_distance * 5) / 5 as dist_bin,\n",
    "        ROUND(f.fare_amount, 0) as fare_bin,\n",
    "        \n",
    "        -- Anzahl der Fahrten pro Cluster\n",
    "        COUNT(*) as trip_count\n",
    "        \n",
    "    FROM `{PROJECT_ID}.{DIM_DATASET}.Fact_Trips` f\n",
    "    LEFT JOIN `{PROJECT_ID}.{DIM_DATASET}.dim_location` loc \n",
    "        ON f.pickup_location_id = loc.location_id\n",
    "        \n",
    "    WHERE f.pickup_datetime IS NOT NULL\n",
    "      AND f.trip_distance > 0 AND f.trip_distance < 100\n",
    "      AND f.fare_amount > 0 AND f.fare_amount < 500\n",
    "      \n",
    "    GROUP BY \n",
    "        year, taxi_type, borough, dist_bin, fare_bin\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        client.query(sql).result()\n",
    "        print(f\"Tabelle '{table_id}' erfolgreich erstellt!\")\n",
    "    except Exception as e:\n",
    "        print(f\"Fehler: {e}\")\n",
    "\n",
    "create_agg_fare_dist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5be8bd67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erstelle Flow-Tabelle: taxi-bi-project.aggregational.agg_borough_flows ...\n",
      "Tabelle 'taxi-bi-project.aggregational.agg_borough_flows' erfolgreich erstellt!\n"
     ]
    }
   ],
   "source": [
    "def create_agg_flows():\n",
    "    \"\"\"\n",
    "    Erstellt 'agg_borough_flows'.\n",
    "    Basis f√ºr das Flow-Diagramm (Pickup -> Dropoff).\n",
    "    \"\"\"\n",
    "    table_id = f\"{PROJECT_ID}.{AGG_DATASET}.agg_borough_flows\"\n",
    "    print(f\"Erstelle Flow-Tabelle: {table_id} ...\")\n",
    "    \n",
    "    sql = f\"\"\"\n",
    "    CREATE OR REPLACE TABLE `{table_id}` AS\n",
    "    SELECT\n",
    "        EXTRACT(YEAR FROM f.pickup_datetime) as year,\n",
    "        f.source_system as taxi_type,\n",
    "        \n",
    "        -- Wir bereinigen NULL-Werte, damit im Diagramm keine L√ºcken entstehen\n",
    "        COALESCE(loc_pu.Borough, 'Unknown') as pickup_borough,\n",
    "        COALESCE(loc_do.Borough, 'Unknown') as dropoff_borough,\n",
    "        \n",
    "        COUNT(*) as trips\n",
    "        \n",
    "    FROM `{PROJECT_ID}.{DIM_DATASET}.Fact_Trips` f\n",
    "    LEFT JOIN `{PROJECT_ID}.{DIM_DATASET}.dim_location` loc_pu \n",
    "        ON f.pickup_location_id = loc_pu.location_id\n",
    "    LEFT JOIN `{PROJECT_ID}.{DIM_DATASET}.dim_location` loc_do \n",
    "        ON f.dropoff_location_id = loc_do.location_id\n",
    "        \n",
    "    WHERE f.pickup_datetime IS NOT NULL\n",
    "      -- Wir schlie√üen technisch bedingte 'Unknown'-Zonen aus, falls gew√ºnscht.\n",
    "      -- F√ºr eine saubere Optik oft besser:\n",
    "      AND loc_pu.Borough IS NOT NULL AND loc_pu.Borough != 'Unknown'\n",
    "      AND loc_do.Borough IS NOT NULL AND loc_do.Borough != 'Unknown'\n",
    "      \n",
    "    GROUP BY 1, 2, 3, 4\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        client.query(sql).result()\n",
    "        print(f\"Tabelle '{table_id}' erfolgreich erstellt!\")\n",
    "    except Exception as e:\n",
    "        print(f\"Fehler: {e}\")\n",
    "\n",
    "create_agg_flows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4df8a7ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî® Erstelle Efficiency-Tabelle (Boxplot Stats): taxi-bi-project.aggregational.agg_revenue_efficiency ...\n",
      "‚úÖ Tabelle 'taxi-bi-project.aggregational.agg_revenue_efficiency' erfolgreich erstellt!\n"
     ]
    }
   ],
   "source": [
    "def create_agg_revenue_efficiency():\n",
    "    \"\"\"\n",
    "    Erstellt 'agg_revenue_efficiency'.\n",
    "    \n",
    "    Features:\n",
    "    - Kategorisierung nach Fahrtdauer (Kurz/Mittel/Lang) -> f√ºr die Story\n",
    "    - Inklusive BOROUGH -> damit der Dashboard-Filter funktioniert!\n",
    "    \"\"\"\n",
    "    table_id = f\"{PROJECT_ID}.{AGG_DATASET}.agg_revenue_efficiency\"\n",
    "    print(f\"üî® Erstelle Efficiency-Tabelle (Duration Buckets + Borough): {table_id} ...\")\n",
    "    \n",
    "    sql = f\"\"\"\n",
    "    CREATE OR REPLACE TABLE `{table_id}` AS\n",
    "    WITH raw_calc AS (\n",
    "        SELECT\n",
    "            EXTRACT(YEAR FROM f.pickup_datetime) as year,\n",
    "            f.source_system as taxi_type,\n",
    "            \n",
    "            -- WICHTIG: Borough f√ºr den Filter holen\n",
    "            COALESCE(loc.Borough, 'Unknown') as borough,\n",
    "            \n",
    "            -- Dauer berechnen\n",
    "            TIMESTAMP_DIFF(f.dropoff_datetime, f.pickup_datetime, MINUTE) as duration_min,\n",
    "            f.fare_amount\n",
    "            \n",
    "        FROM `{PROJECT_ID}.{DIM_DATASET}.Fact_Trips` f\n",
    "        LEFT JOIN `{PROJECT_ID}.{DIM_DATASET}.dim_location` loc\n",
    "            ON f.pickup_location_id = loc.location_id\n",
    "            \n",
    "        WHERE f.pickup_datetime IS NOT NULL\n",
    "          AND f.fare_amount > 0\n",
    "          -- Plausible Dauer: 1 bis 180 Minuten\n",
    "          AND TIMESTAMP_DIFF(f.dropoff_datetime, f.pickup_datetime, MINUTE) BETWEEN 1 AND 180\n",
    "    ),\n",
    "    \n",
    "    categorized AS (\n",
    "        SELECT \n",
    "            year,\n",
    "            taxi_type,\n",
    "            borough,\n",
    "            duration_min,\n",
    "            fare_amount,\n",
    "            \n",
    "            -- Die Kategorien f√ºr die x-Achse\n",
    "            CASE\n",
    "                WHEN duration_min < 10 THEN '1. Kurzstrecke (< 10 min)'\n",
    "                WHEN duration_min < 20 THEN '2. Mittel (10 - 20 min)'\n",
    "                WHEN duration_min < 45 THEN '3. Lang (20 - 45 min)'\n",
    "                ELSE '4. Sehr Lang (> 45 min)'\n",
    "            END as trip_category,\n",
    "            \n",
    "            SAFE_DIVIDE(fare_amount, duration_min) as fare_per_min\n",
    "        FROM raw_calc\n",
    "    )\n",
    "    \n",
    "    SELECT\n",
    "        year,\n",
    "        taxi_type,\n",
    "        borough,       -- Jetzt dabei!\n",
    "        trip_category, -- Unsere x-Achse\n",
    "        \n",
    "        COUNT(*) as total_trips,\n",
    "        APPROX_QUANTILES(fare_per_min, 4) as quantiles\n",
    "        \n",
    "    FROM categorized\n",
    "    GROUP BY 1, 2, 3, 4\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        client.query(sql).result()\n",
    "        print(f\"‚úÖ Tabelle '{table_id}' erfolgreich erstellt (mit Borough & Duration)!\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Fehler: {e}\")\n",
    "\n",
    "create_agg_revenue_efficiency()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

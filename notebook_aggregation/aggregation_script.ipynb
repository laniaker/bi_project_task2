{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "560946ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Ziel-Dataset gefunden: taxi-bi-project.aggregational\n"
     ]
    }
   ],
   "source": [
    "# Zelle 1: Setup & Config\n",
    "from google.cloud import bigquery\n",
    "import pandas as pd\n",
    "import logging\n",
    "\n",
    "# Config\n",
    "PROJECT_ID = \"taxi-bi-project\"  \n",
    "DIM_DATASET = \"dimensional\"     # Quelle (Star Schema)\n",
    "AGG_DATASET = \"aggregational\"       # Ziel (Data Marts)\n",
    "\n",
    "client = bigquery.Client(project=PROJECT_ID)\n",
    "\n",
    "# Hilfsfunktion, um Datasets zu finden/erstellen\n",
    "def create_dataset_if_not_exists(dataset_id):\n",
    "    full_dataset_id = f\"{PROJECT_ID}.{dataset_id}\"\n",
    "    try:\n",
    "        client.get_dataset(full_dataset_id)\n",
    "        print(f\"‚úÖ Ziel-Dataset gefunden: {full_dataset_id}\")\n",
    "    except:\n",
    "        print(f\"Erstelle neues Dataset: {full_dataset_id} ...\")\n",
    "        # Wir holen uns die Region vom Quell-Dataset, damit alles gleich liegt (EU/US)\n",
    "        src_ds = client.get_dataset(f\"{PROJECT_ID}.{DIM_DATASET}\")\n",
    "        new_ds = bigquery.Dataset(full_dataset_id)\n",
    "        new_ds.location = src_ds.location\n",
    "        client.create_dataset(new_ds)\n",
    "        print(f\"‚úÖ Dataset erstellt (Region: {src_ds.location})\")\n",
    "\n",
    "create_dataset_if_not_exists(AGG_DATASET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ae9323a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1. Erstelle Tabelle: agg_monthly_kpis ---\n",
      "‚úÖ agg_monthly_kpis erfolgreich erstellt.\n"
     ]
    }
   ],
   "source": [
    "# Zelle 2: Aggregation 1 - Monthly KPIs (Management View)\n",
    "# Diese Tabelle beantwortet: \"Wie entwickeln sich Umsatz und Fahrtenzahlen?\"\n",
    "\n",
    "def create_monthly_kpis():\n",
    "    print(\"--- 1. Erstelle Tabelle: agg_monthly_kpis ---\")\n",
    "    \n",
    "    sql = f\"\"\"\n",
    "    CREATE OR REPLACE TABLE `{PROJECT_ID}.{AGG_DATASET}.agg_monthly_kpis`\n",
    "    AS\n",
    "    SELECT\n",
    "        -- Dimensionen (Woran wollen wir schneiden?)\n",
    "        d.year,\n",
    "        d.month,\n",
    "        d.month_name,\n",
    "        d.quarter,\n",
    "        f.source_system,      -- Yellow vs Green vs FHV\n",
    "        v.vendor_name,        -- Creative Mobile vs Uber/Lyft Bases\n",
    "        p.payment_description, -- Cash vs Credit\n",
    "        \n",
    "        -- Metriken (Hier wird gerechnet!)\n",
    "        COUNT(f.trip_id) AS total_trips,\n",
    "        \n",
    "        -- Summen (Runden auf 2 Nachkommastellen spart Speicher und sieht besser aus)\n",
    "        ROUND(SUM(f.total_amount), 2) AS total_revenue,\n",
    "        ROUND(SUM(f.fare_amount), 2) AS total_fare,\n",
    "        ROUND(SUM(f.tip_amount), 2) AS total_tips,\n",
    "        \n",
    "        -- Durchschnitte (KPIs)\n",
    "        ROUND(AVG(f.total_amount), 2) AS avg_ticket_size,\n",
    "        ROUND(AVG(f.trip_distance), 2) AS avg_distance_miles,\n",
    "        ROUND(AVG(f.duration_minutes), 1) AS avg_duration_min\n",
    "\n",
    "    FROM `{PROJECT_ID}.{DIM_DATASET}.Fact_Trips` f\n",
    "    \n",
    "    -- JOINs zum Star Schema\n",
    "    LEFT JOIN `{PROJECT_ID}.{DIM_DATASET}.dim_date` d ON f.pickup_date_key = d.date_key\n",
    "    LEFT JOIN `{PROJECT_ID}.{DIM_DATASET}.dim_vendor` v ON f.vendor_id = v.vendor_id\n",
    "    LEFT JOIN `{PROJECT_ID}.{DIM_DATASET}.dim_payment_type` p ON f.payment_type_id = p.payment_type_id\n",
    "\n",
    "    -- FILTER:\n",
    "    -- Wir wollen hier nur \"echte\" Fahrten f√ºr die Statistik.\n",
    "    -- Wir schlie√üen 0$-Fahrten (Geister) aus.\n",
    "    -- Aber: Deine 3.80$ Fahrt (Short Trip) bleibt drin, weil total_amount > 0!\n",
    "    WHERE f.total_amount > 0\n",
    "    \n",
    "    GROUP BY 1, 2, 3, 4, 5, 6, 7\n",
    "    ORDER BY year DESC, month DESC, total_revenue DESC\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        job = client.query(sql)\n",
    "        job.result() # Warten auf Fertigstellung\n",
    "        print(\"‚úÖ agg_monthly_kpis erfolgreich erstellt.\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Fehler: {e}\")\n",
    "\n",
    "create_monthly_kpis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f44a87e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 2. Erstelle Tabelle: agg_geo_stats ---\n",
      "‚úÖ agg_geo_stats erfolgreich erstellt.\n"
     ]
    }
   ],
   "source": [
    "# Zelle 3: Aggregation 2 - Geo Stats (Map View)\n",
    "# Diese Tabelle beantwortet: \"Welche Stadtteile sind am lukrativsten?\"\n",
    "\n",
    "def create_geo_stats():\n",
    "    print(\"--- 2. Erstelle Tabelle: agg_geo_stats ---\")\n",
    "    \n",
    "    sql = f\"\"\"\n",
    "    CREATE OR REPLACE TABLE `{PROJECT_ID}.{AGG_DATASET}.agg_geo_stats`\n",
    "    AS\n",
    "    SELECT\n",
    "        d.year,\n",
    "        d.quarter,\n",
    "        \n",
    "        -- Feldnamen auf Kleinschreibung korrigiert\n",
    "        loc.borough AS pickup_borough,\n",
    "        loc.zone AS pickup_zone,\n",
    "        loc.service_zone,\n",
    "        \n",
    "        f.source_system,\n",
    "        \n",
    "        COUNT(f.trip_id) AS pickup_count,\n",
    "        ROUND(SUM(f.total_amount), 0) AS total_revenue_generated,\n",
    "        ROUND(AVG(f.tip_amount), 2) AS avg_tip_here\n",
    "\n",
    "    FROM `{PROJECT_ID}.{DIM_DATASET}.Fact_Trips` f\n",
    "    \n",
    "    -- Korrektur: location_id statt LocationID\n",
    "    LEFT JOIN `{PROJECT_ID}.{DIM_DATASET}.dim_location` loc ON f.pickup_location_id = loc.location_id\n",
    "    LEFT JOIN `{PROJECT_ID}.{DIM_DATASET}.dim_date` d ON f.pickup_date_key = d.date_key\n",
    "\n",
    "    WHERE f.total_amount > 0\n",
    "    \n",
    "    GROUP BY 1, 2, 3, 4, 5, 6\n",
    "    ORDER BY pickup_count DESC\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        job = client.query(sql)\n",
    "        job.result()\n",
    "        print(\"‚úÖ agg_geo_stats erfolgreich erstellt.\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Fehler: {e}\")\n",
    "\n",
    "create_geo_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "099ade7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- CHECK: Monthly KPIs (Top 5 Rows) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lania/Documents/GitHub/bi_project_task2/.venv/lib/python3.12/site-packages/google/cloud/bigquery/table.py:1994: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " year month_name source_system  total_trips  total_revenue  avg_ticket_size\n",
      " <NA>       None        YELLOW     18583128   212632111.82            11.44\n",
      " <NA>       None        YELLOW     18571532   207398754.56            11.17\n",
      " <NA>       None        YELLOW     17350741   278040333.89            16.02\n",
      " <NA>       None        YELLOW     16939149   267008644.23            15.76\n",
      " 2015       June        YELLOW      4056201    73857611.68            18.21\n",
      "\n",
      "--- CHECK: Geo Stats (Top 5 Zones) ---\n",
      "pickup_borough               pickup_zone source_system  pickup_count  total_revenue_generated\n",
      "     Manhattan     Upper East Side South        YELLOW       2577047               27047460.0\n",
      "     Manhattan            Midtown Center        YELLOW       2472275               30124537.0\n",
      "     Manhattan              East Village        YELLOW       2390112               29673556.0\n",
      "     Manhattan Times Sq/Theatre District        YELLOW       2374174               31971137.0\n",
      "     Manhattan              Midtown East        YELLOW       2365586               29162290.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lania/Documents/GitHub/bi_project_task2/.venv/lib/python3.12/site-packages/google/cloud/bigquery/table.py:1994: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Zelle 4: Quality Check (Kurzer Blick auf das Ergebnis)\n",
    "# Pr√ºfen, ob die Tabellen gef√ºllt sind und die Geisterfahrten weg sind\n",
    "\n",
    "def check_aggregation():\n",
    "    print(\"\\n--- CHECK: Monthly KPIs (Top 5 Rows) ---\")\n",
    "    query_kpi = f\"\"\"\n",
    "    SELECT year, month_name, source_system, total_trips, total_revenue, avg_ticket_size \n",
    "    FROM `{PROJECT_ID}.{AGG_DATASET}.agg_monthly_kpis` \n",
    "    ORDER BY total_trips DESC \n",
    "    LIMIT 5\n",
    "    \"\"\"\n",
    "    print(client.query(query_kpi).to_dataframe().to_string(index=False))\n",
    "\n",
    "    print(\"\\n--- CHECK: Geo Stats (Top 5 Zones) ---\")\n",
    "    query_geo = f\"\"\"\n",
    "    SELECT pickup_borough, pickup_zone, source_system, pickup_count, total_revenue_generated\n",
    "    FROM `{PROJECT_ID}.{AGG_DATASET}.agg_geo_stats`\n",
    "    WHERE pickup_zone != 'NV' -- Wir ignorieren kurz die Unknowns\n",
    "    ORDER BY pickup_count DESC\n",
    "    LIMIT 5\n",
    "    \"\"\"\n",
    "    print(client.query(query_geo).to_dataframe().to_string(index=False))\n",
    "\n",
    "check_aggregation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2c069628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 3. Erstelle Tabelle: agg_time_trends ---\n",
      "‚úÖ agg_time_trends erstellt.\n"
     ]
    }
   ],
   "source": [
    "def create_time_trends():\n",
    "    print(\"--- 3. Erstelle Tabelle: agg_time_trends ---\")\n",
    "    \n",
    "    sql = f\"\"\"\n",
    "    CREATE OR REPLACE TABLE `taxi-bi-project.dimensional.dim_date` AS\n",
    "    SELECT\n",
    "        datum AS date_key,\n",
    "        EXTRACT(YEAR FROM datum) AS year,\n",
    "        EXTRACT(MONTH FROM datum) AS month,\n",
    "        FORMAT_DATE('%B', datum) AS month_name,\n",
    "        FORMAT_DATE('%A', datum) AS day_name,             -- WICHTIG: F√ºr dein Skript\n",
    "        EXTRACT(DAYOFWEEK FROM datum) AS day_of_week_num, -- WICHTIG: F√ºr dein Skript\n",
    "        EXTRACT(QUARTER FROM datum) AS quarter,\n",
    "        CASE WHEN EXTRACT(DAYOFWEEK FROM datum) IN (1, 7) THEN TRUE ELSE FALSE END AS is_weekend\n",
    "    FROM UNNEST(GENERATE_DATE_ARRAY('2010-01-01', '2025-12-31')) AS datum;\n",
    "    \"\"\"\n",
    "    try:\n",
    "        client.query(sql).result()\n",
    "        print(\"‚úÖ agg_time_trends erstellt.\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Fehler: {e}\")\n",
    "\n",
    "create_time_trends()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8ca09fc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 4. Erstelle Tabelle: agg_route_stats ---\n",
      "‚ùå Fehler: 400 Name LocationID not found inside pu at [20:85]; reason: invalidQuery, location: query, message: Name LocationID not found inside pu at [20:85]\n",
      "\n",
      "Location: EU\n",
      "Job ID: 9507c2d4-584c-44a9-b219-90b31158dc8c\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def create_route_stats():\n",
    "    print(\"--- 4. Erstelle Tabelle: agg_route_stats ---\")\n",
    "    \n",
    "    sql = f\"\"\"\n",
    "    CREATE OR REPLACE TABLE `{PROJECT_ID}.{AGG_DATASET}.agg_route_stats` AS\n",
    "    SELECT\n",
    "        d.year,\n",
    "        \n",
    "        -- VON -> NACH\n",
    "        pu.Borough AS pickup_borough,\n",
    "        do.Borough AS dropoff_borough,\n",
    "        \n",
    "        -- Optional: Wenn du es feiner willst, nimm die Zonen dazu (wird aber gr√∂√üer)\n",
    "        -- pu.Zone as pickup_zone,\n",
    "        -- do.Zone as dropoff_zone,\n",
    "        \n",
    "        COUNT(*) AS trip_count,\n",
    "        ROUND(AVG(f.total_amount), 2) AS avg_cost,\n",
    "        ROUND(AVG(f.duration_minutes), 1) AS avg_duration\n",
    "        \n",
    "    FROM `{PROJECT_ID}.{DIM_DATASET}.Fact_Trips` f\n",
    "    JOIN `{PROJECT_ID}.{DIM_DATASET}.dim_date` d ON f.pickup_date_key = d.date_key\n",
    "    JOIN `{PROJECT_ID}.{DIM_DATASET}.dim_location` pu ON f.pickup_location_id = pu.LocationID\n",
    "    JOIN `{PROJECT_ID}.{DIM_DATASET}.dim_location` do ON f.dropoff_location_id = do.LocationID\n",
    "    \n",
    "    WHERE f.total_amount > 0 \n",
    "      AND pu.Borough != 'Unknown' \n",
    "      AND do.Borough != 'Unknown'\n",
    "      \n",
    "    GROUP BY 1, 2, 3\n",
    "    ORDER BY trip_count DESC\n",
    "    \"\"\"\n",
    "    try:\n",
    "        client.query(sql).result()\n",
    "        print(\"‚úÖ agg_route_stats erstellt.\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Fehler: {e}\")\n",
    "\n",
    "create_route_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "56f55d15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 5. Erstelle Tabelle: agg_airport_trips ---\n",
      "‚úÖ agg_airport_trips erstellt.\n"
     ]
    }
   ],
   "source": [
    "def create_airport_stats():\n",
    "    print(\"--- 5. Erstelle Tabelle: agg_airport_trips ---\")\n",
    "    \n",
    "    sql = f\"\"\"\n",
    "    CREATE OR REPLACE TABLE `{PROJECT_ID}.{AGG_DATASET}.agg_airport_trips` AS\n",
    "    SELECT\n",
    "        d.year,\n",
    "        d.month_name,\n",
    "        f.source_system,\n",
    "        \n",
    "        -- War es eine Fahrt ZUM oder VOM Flughafen?\n",
    "        CASE \n",
    "            WHEN rc.rate_description LIKE '%JFK%' OR rc.rate_description LIKE '%Newark%' THEN 'Airport Rate'\n",
    "            ELSE 'Standard Rate to Airport Zone'\n",
    "        END AS trip_category,\n",
    "        \n",
    "        COUNT(*) AS total_trips,\n",
    "        ROUND(AVG(f.total_amount), 2) AS avg_ticket,\n",
    "        ROUND(AVG(f.tip_amount), 2) AS avg_tip\n",
    "        \n",
    "    FROM `{PROJECT_ID}.{DIM_DATASET}.Fact_Trips` f\n",
    "    JOIN `{PROJECT_ID}.{DIM_DATASET}.dim_date` d ON f.pickup_date_key = d.date_key\n",
    "    JOIN `{PROJECT_ID}.{DIM_DATASET}.dim_rate_code` rc ON f.rate_code_id = rc.rate_code_id\n",
    "    \n",
    "    -- Location Filter: 132=JFK, 138=LaGuardia, 1=Newark\n",
    "    WHERE (f.pickup_location_id IN (132, 138, 1) OR f.dropoff_location_id IN (132, 138, 1))\n",
    "      AND f.total_amount > 0\n",
    "      \n",
    "    GROUP BY 1, 2, 3, 4\n",
    "    \"\"\"\n",
    "    try:\n",
    "        client.query(sql).result()\n",
    "        print(\"‚úÖ agg_airport_trips erstellt.\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Fehler: {e}\")\n",
    "\n",
    "create_airport_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ed1c7461",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_quality_audit_mart():\n",
    "    print(\"--- 8. Erstelle Tabelle: agg_quality_audit ---\")\n",
    "    sql = f\"\"\"\n",
    "    CREATE OR REPLACE TABLE `{PROJECT_ID}.{AGG_DATASET}.agg_quality_audit` AS\n",
    "    SELECT\n",
    "        DATE_TRUNC(pickup_datetime, MONTH) as month,\n",
    "        source_system,\n",
    "        COUNT(*) as total_trips,\n",
    "        COUNTIF(trip_distance = 0 AND source_system != 'FHV') as gps_failures,\n",
    "        COUNTIF(pickup_location_id IN (263, 264)) as unknown_locations,\n",
    "        COUNTIF(dq_issue_flag = TRUE) as total_issues\n",
    "    FROM `{PROJECT_ID}.{DIM_DATASET}.Fact_Trips`\n",
    "    GROUP BY 1, 2\n",
    "    \"\"\"\n",
    "    client.query(sql).result()\n",
    "    print(\"‚úÖ agg_quality_audit erstellt.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d92a09a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_shared_ride_stats():\n",
    "    print(\"--- 7. Erstelle Tabelle: agg_shared_rides ---\")\n",
    "    sql = f\"\"\"\n",
    "    CREATE OR REPLACE TABLE `{PROJECT_ID}.{AGG_DATASET}.agg_shared_rides` AS\n",
    "    SELECT\n",
    "        d.year,\n",
    "        f.source_system,\n",
    "        f.sr_flag,\n",
    "        COUNT(*) AS trip_count,\n",
    "        ROUND(AVG(f.fare_amount), 2) AS avg_fare -- Nur f√ºr Yellow/Green sinnvoll\n",
    "    FROM `{PROJECT_ID}.{DIM_DATASET}.Fact_Trips` f\n",
    "    JOIN `{PROJECT_ID}.{DIM_DATASET}.dim_date` d ON f.pickup_date_key = d.date_key\n",
    "    GROUP BY 1, 2, 3\n",
    "    \"\"\"\n",
    "    client.query(sql).result()\n",
    "    print(\"‚úÖ agg_shared_rides erstellt.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7c37255a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- üìä FINAL DATA MART CHECK ---\n",
      "\n",
      "üïê TOP 5 ZEITFENSTER (agg_time_trends):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lania/Documents/GitHub/bi_project_task2/.venv/lib/python3.12/site-packages/google/cloud/bigquery/table.py:1994: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " day_name  hour_of_day source_system  trip_count  avg_fare\n",
      " Thursday           18        YELLOW      429644     29.42\n",
      "Wednesday           18        YELLOW      423982     28.90\n",
      "  Tuesday           18        YELLOW      403973     28.57\n",
      "   Friday           18        YELLOW      397860     28.56\n",
      " Thursday           17        YELLOW      396463     31.39\n",
      "\n",
      "üìç TOP 5 ROUTEN (agg_route_stats):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lania/Documents/GitHub/bi_project_task2/.venv/lib/python3.12/site-packages/google/cloud/bigquery/table.py:1994: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pickup_borough dropoff_borough  trip_count  avg_cost\n",
      "     Manhattan       Manhattan    20908052     20.34\n",
      "     Manhattan       Manhattan     7358395     12.41\n",
      "     Manhattan       Manhattan     6957972     12.28\n",
      "     Manhattan       Manhattan     6223453     12.24\n",
      "     Manhattan       Manhattan     5457148     12.20\n",
      "\n",
      "‚úàÔ∏è FLUGHAFEN STATS (agg_airport_trips):\n",
      " year                 trip_category source_system  total_trips  avg_ticket\n",
      " 2015 Standard Rate to Airport Zone        YELLOW       587996       43.19\n",
      " 2016 Standard Rate to Airport Zone        YELLOW       557057       43.96\n",
      " 2017 Standard Rate to Airport Zone        YELLOW       489819       45.04\n",
      " 2018 Standard Rate to Airport Zone        YELLOW       451924       44.57\n",
      " 2019 Standard Rate to Airport Zone        YELLOW       379443       44.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lania/Documents/GitHub/bi_project_task2/.venv/lib/python3.12/site-packages/google/cloud/bigquery/table.py:1994: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "def check_new_marts():\n",
    "    # Stelle sicher, dass die Variablen passen\n",
    "    PROJECT_ID = \"taxi-bi-project\"\n",
    "    AGG_DATASET = \"aggregational\"\n",
    "    \n",
    "    print(\"--- üìä FINAL DATA MART CHECK ---\")\n",
    "\n",
    "    # 1. RUSH HOUR (Wann ist am meisten los?)\n",
    "    print(\"\\nüïê TOP 5 ZEITFENSTER (agg_time_trends):\")\n",
    "    # Wir sortieren nach trip_count, um die gesch√§ftigsten Stunden zu sehen\n",
    "    sql_time = f\"\"\"\n",
    "    SELECT day_name, hour_of_day, source_system, trip_count, avg_fare\n",
    "    FROM `{PROJECT_ID}.{AGG_DATASET}.agg_time_trends`\n",
    "    ORDER BY trip_count DESC\n",
    "    LIMIT 5\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df_time = client.query(sql_time).to_dataframe()\n",
    "        print(df_time.to_string(index=False))\n",
    "    except Exception as e:\n",
    "        print(f\"Fehler: {e}\")\n",
    "\n",
    "    # 2. ROUTEN (Wer f√§hrt von wo nach wo?)\n",
    "    print(\"\\nüìç TOP 5 ROUTEN (agg_route_stats):\")\n",
    "    sql_routes = f\"\"\"\n",
    "    SELECT pickup_borough, dropoff_borough, trip_count, avg_cost\n",
    "    FROM `{PROJECT_ID}.{AGG_DATASET}.agg_route_stats`\n",
    "    ORDER BY trip_count DESC\n",
    "    LIMIT 5\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df_routes = client.query(sql_routes).to_dataframe()\n",
    "        print(df_routes.to_string(index=False))\n",
    "    except Exception as e:\n",
    "        print(f\"Fehler: {e}\")\n",
    "\n",
    "    # 3. FLUGHAFEN (Die Cash Cows)\n",
    "    print(\"\\n‚úàÔ∏è FLUGHAFEN STATS (agg_airport_trips):\")\n",
    "    sql_air = f\"\"\"\n",
    "    SELECT year, trip_category, source_system, total_trips, avg_ticket\n",
    "    FROM `{PROJECT_ID}.{AGG_DATASET}.agg_airport_trips`\n",
    "    ORDER BY total_trips DESC\n",
    "    LIMIT 5\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df_air = client.query(sql_air).to_dataframe()\n",
    "        print(df_air.to_string(index=False))\n",
    "    except Exception as e:\n",
    "        print(f\"Fehler: {e}\")\n",
    "\n",
    "check_new_marts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "560946ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Ziel-Dataset gefunden: taxi-bi-project.aggregational\n"
     ]
    }
   ],
   "source": [
    "# Zelle 1: Setup & Config\n",
    "from google.cloud import bigquery\n",
    "import pandas as pd\n",
    "import logging\n",
    "\n",
    "# Config\n",
    "PROJECT_ID = \"taxi-bi-project\"  \n",
    "DIM_DATASET = \"dimensional\"     # Quelle (Star Schema)\n",
    "AGG_DATASET = \"aggregational\"       # Ziel (Data Marts)\n",
    "\n",
    "client = bigquery.Client(project=PROJECT_ID)\n",
    "\n",
    "# Hilfsfunktion, um Datasets zu finden/erstellen\n",
    "def create_dataset_if_not_exists(dataset_id):\n",
    "    full_dataset_id = f\"{PROJECT_ID}.{dataset_id}\"\n",
    "    try:\n",
    "        client.get_dataset(full_dataset_id)\n",
    "        print(f\"âœ… Ziel-Dataset gefunden: {full_dataset_id}\")\n",
    "    except:\n",
    "        print(f\"Erstelle neues Dataset: {full_dataset_id} ...\")\n",
    "        # Wir holen uns die Region vom Quell-Dataset, damit alles gleich liegt (EU/US)\n",
    "        src_ds = client.get_dataset(f\"{PROJECT_ID}.{DIM_DATASET}\")\n",
    "        new_ds = bigquery.Dataset(full_dataset_id)\n",
    "        new_ds.location = src_ds.location\n",
    "        client.create_dataset(new_ds)\n",
    "        print(f\"âœ… Dataset erstellt (Region: {src_ds.location})\")\n",
    "\n",
    "create_dataset_if_not_exists(AGG_DATASET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0ae9323a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1. Erstelle Tabelle: agg_monthly_kpis ---\n",
      "âœ… agg_monthly_kpis erfolgreich erstellt.\n"
     ]
    }
   ],
   "source": [
    "# Zelle 2: Aggregation 1 - Monthly KPIs (Management View)\n",
    "# Diese Tabelle beantwortet: \"Wie entwickeln sich Umsatz und Fahrtenzahlen?\"\n",
    "\n",
    "def create_monthly_kpis():\n",
    "    print(\"--- 1. Erstelle Tabelle: agg_monthly_kpis ---\")\n",
    "    \n",
    "    sql = f\"\"\"\n",
    "    CREATE OR REPLACE TABLE `{PROJECT_ID}.{AGG_DATASET}.agg_monthly_kpis`\n",
    "    AS\n",
    "    SELECT\n",
    "        -- Dimensionen (Woran wollen wir schneiden?)\n",
    "        d.year,\n",
    "        d.month,\n",
    "        d.month_name,\n",
    "        d.quarter,\n",
    "        f.source_system,      -- Yellow vs Green vs FHV\n",
    "        v.vendor_name,        -- Creative Mobile vs Uber/Lyft Bases\n",
    "        p.payment_description, -- Cash vs Credit\n",
    "        \n",
    "        -- Metriken (Hier wird gerechnet!)\n",
    "        COUNT(f.trip_id) AS total_trips,\n",
    "        \n",
    "        -- Summen (Runden auf 2 Nachkommastellen spart Speicher und sieht besser aus)\n",
    "        ROUND(SUM(f.total_amount), 2) AS total_revenue,\n",
    "        ROUND(SUM(f.fare_amount), 2) AS total_fare,\n",
    "        ROUND(SUM(f.tip_amount), 2) AS total_tips,\n",
    "        \n",
    "        -- Durchschnitte (KPIs)\n",
    "        ROUND(AVG(f.total_amount), 2) AS avg_ticket_size,\n",
    "        ROUND(AVG(f.trip_distance), 2) AS avg_distance_miles,\n",
    "        ROUND(AVG(f.duration_minutes), 1) AS avg_duration_min\n",
    "\n",
    "    FROM `{PROJECT_ID}.{DIM_DATASET}.Fact_Trips` f\n",
    "    \n",
    "    -- JOINs zum Star Schema\n",
    "    LEFT JOIN `{PROJECT_ID}.{DIM_DATASET}.dim_date` d ON f.pickup_date_key = d.date_key\n",
    "    LEFT JOIN `{PROJECT_ID}.{DIM_DATASET}.dim_vendor` v ON f.vendor_id = v.vendor_id\n",
    "    LEFT JOIN `{PROJECT_ID}.{DIM_DATASET}.dim_payment_type` p ON f.payment_type_id = p.payment_type_id\n",
    "\n",
    "    -- FILTER:\n",
    "    -- Wir wollen hier nur \"echte\" Fahrten fÃ¼r die Statistik.\n",
    "    -- Wir schlieÃŸen 0$-Fahrten (Geister) aus.\n",
    "    -- Aber: Deine 3.80$ Fahrt (Short Trip) bleibt drin, weil total_amount > 0!\n",
    "    WHERE f.total_amount > 0\n",
    "    \n",
    "    GROUP BY 1, 2, 3, 4, 5, 6, 7\n",
    "    ORDER BY year DESC, month DESC, total_revenue DESC\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        job = client.query(sql)\n",
    "        job.result() # Warten auf Fertigstellung\n",
    "        print(\"âœ… agg_monthly_kpis erfolgreich erstellt.\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Fehler: {e}\")\n",
    "\n",
    "create_monthly_kpis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0f44a87e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 2. Erstelle Tabelle: agg_geo_stats ---\n",
      "âœ… agg_geo_stats erfolgreich erstellt!\n"
     ]
    }
   ],
   "source": [
    "def create_geo_stats_final():\n",
    "    print(\"--- 2. Erstelle Tabelle: agg_geo_stats ---\")\n",
    "    \n",
    "    # Wir nutzen SAFE_CAST und FORMAT_DATE, um sicherzugehen, dass der Key matcht\n",
    "    sql = f\"\"\"\n",
    "    CREATE OR REPLACE TABLE `{PROJECT_ID}.{AGG_DATASET}.agg_geo_stats` AS\n",
    "    SELECT\n",
    "        d.year,\n",
    "        d.quarter,\n",
    "        loc.borough AS pickup_borough,\n",
    "        loc.zone AS pickup_zone,\n",
    "        IFNULL(loc.service_zone, 'Other') AS service_zone,\n",
    "        f.source_system,\n",
    "        \n",
    "        COUNT(f.trip_id) AS pickup_count,\n",
    "        ROUND(SUM(f.total_amount), 0) AS total_revenue_generated,\n",
    "        ROUND(AVG(f.tip_amount), 2) AS avg_tip_here\n",
    "\n",
    "    FROM `{PROJECT_ID}.{DIM_DATASET}.Fact_Trips` f\n",
    "    \n",
    "    -- JOIN zur Datumstabelle\n",
    "    -- Wir wandeln das Trip-Datum in das Format YYYYMMDD um (Standard fÃ¼r date_key)\n",
    "    LEFT JOIN `{PROJECT_ID}.{DIM_DATASET}.dim_date` d \n",
    "        ON CAST(FORMAT_DATE('%Y%m%d', DATE(f.pickup_datetime)) AS INT64) = CAST(d.date_key AS INT64)\n",
    "        \n",
    "    LEFT JOIN `{PROJECT_ID}.{DIM_DATASET}.dim_location` loc \n",
    "        ON f.pickup_location_id = loc.location_id\n",
    "\n",
    "    WHERE f.total_amount > 0 \n",
    "    GROUP BY 1, 2, 3, 4, 5, 6\n",
    "    ORDER BY pickup_count DESC\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        client.query(sql).result()\n",
    "        print(\"âœ… agg_geo_stats erfolgreich erstellt!\")\n",
    "    except Exception as e:\n",
    "        # Falls date_key doch ein DATE-Typ ist, w Fallback:\n",
    "    \n",
    "        fallback_sql = sql.replace(\n",
    "            \"CAST(FORMAT_DATE('%Y%m%d', DATE(f.pickup_datetime)) AS INT64) = CAST(d.date_key AS INT64)\",\n",
    "            \"DATE(f.pickup_datetime) = d.date_key\"\n",
    "        )\n",
    "        try:\n",
    "            client.query(fallback_sql).result()\n",
    "            print(\"âœ… agg_geo_stats erfolgreich erstellt!\")\n",
    "        except Exception as e_inner:\n",
    "            print(f\"Kritischer Fehler: {e_inner}\")\n",
    "\n",
    "create_geo_stats_final()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "099ade7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- CHECK: Monthly KPIs (Top 5 Rows) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lania/Documents/GitHub/bi_project_task2/.venv/lib/python3.12/site-packages/google/cloud/bigquery/table.py:1994: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " year month_name source_system  total_trips  total_revenue  avg_ticket_size\n",
      " 2010       June        YELLOW      4628917    48508294.19            10.48\n",
      " 2011       June        YELLOW      4232780    44625418.33            10.54\n",
      " 2010       June        YELLOW      4225814    43097295.83            10.20\n",
      " 2011       June        YELLOW      4108120    44230599.26            10.77\n",
      " 2015       June        YELLOW      4056209    73857571.43            18.21\n",
      "\n",
      "--- CHECK: Geo Stats (Top 5 Zones) ---\n",
      "pickup_borough           pickup_zone source_system  pickup_count  total_revenue_generated\n",
      "     Manhattan Upper East Side South        YELLOW        541769                5080112.0\n",
      "     Manhattan        Midtown Center        YELLOW        532814                5729221.0\n",
      "     Manhattan Upper East Side South        YELLOW        530182                5210931.0\n",
      "     Manhattan Upper East Side South        YELLOW        522302                5185967.0\n",
      "     Manhattan        Midtown Center        YELLOW        513124                5759794.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lania/Documents/GitHub/bi_project_task2/.venv/lib/python3.12/site-packages/google/cloud/bigquery/table.py:1994: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Zelle 4: Quality Check (Kurzer Blick auf das Ergebnis)\n",
    "# PrÃ¼fen, ob die Tabellen gefÃ¼llt sind und die Geisterfahrten weg sind\n",
    "\n",
    "def check_aggregation():\n",
    "    print(\"\\n--- CHECK: Monthly KPIs (Top 5 Rows) ---\")\n",
    "    query_kpi = f\"\"\"\n",
    "    SELECT year, month_name, source_system, total_trips, total_revenue, avg_ticket_size \n",
    "    FROM `{PROJECT_ID}.{AGG_DATASET}.agg_monthly_kpis` \n",
    "    ORDER BY total_trips DESC \n",
    "    LIMIT 5\n",
    "    \"\"\"\n",
    "    print(client.query(query_kpi).to_dataframe().to_string(index=False))\n",
    "\n",
    "    print(\"\\n--- CHECK: Geo Stats (Top 5 Zones) ---\")\n",
    "    query_geo = f\"\"\"\n",
    "    SELECT pickup_borough, pickup_zone, source_system, pickup_count, total_revenue_generated\n",
    "    FROM `{PROJECT_ID}.{AGG_DATASET}.agg_geo_stats`\n",
    "    WHERE pickup_zone != 'NV' -- Wir ignorieren kurz die Unknowns\n",
    "    ORDER BY pickup_count DESC\n",
    "    LIMIT 5\n",
    "    \"\"\"\n",
    "    print(client.query(query_geo).to_dataframe().to_string(index=False))\n",
    "\n",
    "check_aggregation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2c069628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 3. Erstelle Tabelle: agg_time_trends ---\n",
      "âœ… agg_time_trends erstellt.\n"
     ]
    }
   ],
   "source": [
    "def create_time_trends():\n",
    "    print(\"--- 3. Erstelle Tabelle: agg_time_trends ---\")\n",
    "    \n",
    "    sql = f\"\"\"\n",
    "    CREATE OR REPLACE TABLE `taxi-bi-project.dimensional.dim_date` AS\n",
    "    SELECT\n",
    "        datum AS date_key,\n",
    "        EXTRACT(YEAR FROM datum) AS year,\n",
    "        EXTRACT(MONTH FROM datum) AS month,\n",
    "        FORMAT_DATE('%B', datum) AS month_name,\n",
    "        FORMAT_DATE('%A', datum) AS day_name,             -- WICHTIG: FÃ¼r dein Skript\n",
    "        EXTRACT(DAYOFWEEK FROM datum) AS day_of_week_num, -- WICHTIG: FÃ¼r dein Skript\n",
    "        EXTRACT(QUARTER FROM datum) AS quarter,\n",
    "        CASE WHEN EXTRACT(DAYOFWEEK FROM datum) IN (1, 7) THEN TRUE ELSE FALSE END AS is_weekend\n",
    "    FROM UNNEST(GENERATE_DATE_ARRAY('2010-01-01', '2025-12-31')) AS datum;\n",
    "    \"\"\"\n",
    "    try:\n",
    "        client.query(sql).result()\n",
    "        print(\"âœ… agg_time_trends erstellt.\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Fehler: {e}\")\n",
    "\n",
    "create_time_trends()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8ca09fc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 4. Erstelle Tabelle: agg_route_stats ---\n",
      "âœ… agg_route_stats erfolgreich erstellt.\n"
     ]
    }
   ],
   "source": [
    "def create_route_stats():\n",
    "    print(\"--- 4. Erstelle Tabelle: agg_route_stats ---\")\n",
    "    \n",
    "    # Hinweis: Ich habe LocationID zu location_id geÃ¤ndert. \n",
    "    # Bitte prÃ¼fe, ob die Spalte in deiner dim_location tatsÃ¤chlich so heiÃŸt.\n",
    "    sql = f\"\"\"\n",
    "    CREATE OR REPLACE TABLE `{PROJECT_ID}.{AGG_DATASET}.agg_route_stats` AS\n",
    "    SELECT\n",
    "        d.year,\n",
    "        d.month, -- Empfehlung: Monat hinzufÃ¼gen fÃ¼r bessere Zeitreihen\n",
    "        \n",
    "        -- VON -> NACH\n",
    "        pu.Borough AS pickup_borough,\n",
    "        do.Borough AS dropoff_borough,\n",
    "        \n",
    "        COUNT(*) AS trip_count,\n",
    "        ROUND(AVG(f.total_amount), 2) AS avg_cost,\n",
    "        -- Falls duration_minutes in Fact_Trips existiert:\n",
    "        ROUND(AVG(SAFE_DIVIDE(TIMESTAMP_DIFF(f.dropoff_datetime, f.pickup_datetime, SECOND), 60)), 1) AS avg_duration_min\n",
    "        \n",
    "    FROM `{PROJECT_ID}.{DIM_DATASET}.Fact_Trips` f\n",
    "    -- Join auf deine neue dim_date (oder dim_datetime)\n",
    "    JOIN `{PROJECT_ID}.{DIM_DATASET}.dim_date` d ON DATE(f.pickup_datetime) = d.date_key\n",
    "    -- Achte hier auf den Spaltennamen: location_id vs LocationID\n",
    "    JOIN `{PROJECT_ID}.{DIM_DATASET}.dim_location` pu ON f.pickup_location_id = pu.location_id\n",
    "    JOIN `{PROJECT_ID}.{DIM_DATASET}.dim_location` do ON f.dropoff_location_id = do.location_id\n",
    "    \n",
    "    WHERE f.total_amount > 0 \n",
    "      AND pu.Borough != 'Unknown' \n",
    "      AND do.Borough != 'Unknown'\n",
    "      \n",
    "    GROUP BY 1, 2, 3, 4\n",
    "    ORDER BY trip_count DESC\n",
    "    \"\"\"\n",
    "    try:\n",
    "        client.query(sql).result()\n",
    "        print(\"âœ… agg_route_stats erfolgreich erstellt.\")\n",
    "    except Exception as e:\n",
    "        # Detailliertere Fehlerausgabe\n",
    "        print(f\"âŒ Fehler bei der Erstellung von agg_route_stats: {e}\")\n",
    "\n",
    "create_route_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "56f55d15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 5. Erstelle Tabelle: agg_airport_trips ---\n",
      "âœ… agg_airport_trips erstellt.\n"
     ]
    }
   ],
   "source": [
    "def create_airport_stats():\n",
    "    print(\"--- 5. Erstelle Tabelle: agg_airport_trips ---\")\n",
    "    \n",
    "    sql = f\"\"\"\n",
    "    CREATE OR REPLACE TABLE `{PROJECT_ID}.{AGG_DATASET}.agg_airport_trips` AS\n",
    "    SELECT\n",
    "        d.year,\n",
    "        d.month_name,\n",
    "        f.source_system,\n",
    "        \n",
    "        -- War es eine Fahrt ZUM oder VOM Flughafen?\n",
    "        CASE \n",
    "            WHEN rc.rate_description LIKE '%JFK%' OR rc.rate_description LIKE '%Newark%' THEN 'Airport Rate'\n",
    "            ELSE 'Standard Rate to Airport Zone'\n",
    "        END AS trip_category,\n",
    "        \n",
    "        COUNT(*) AS total_trips,\n",
    "        ROUND(AVG(f.total_amount), 2) AS avg_ticket,\n",
    "        ROUND(AVG(f.tip_amount), 2) AS avg_tip\n",
    "        \n",
    "    FROM `{PROJECT_ID}.{DIM_DATASET}.Fact_Trips` f\n",
    "    JOIN `{PROJECT_ID}.{DIM_DATASET}.dim_date` d ON f.pickup_date_key = d.date_key\n",
    "    JOIN `{PROJECT_ID}.{DIM_DATASET}.dim_rate_code` rc ON f.rate_code_id = rc.rate_code_id\n",
    "    \n",
    "    -- Location Filter: 132=JFK, 138=LaGuardia, 1=Newark\n",
    "    WHERE (f.pickup_location_id IN (132, 138, 1) OR f.dropoff_location_id IN (132, 138, 1))\n",
    "      AND f.total_amount > 0\n",
    "      \n",
    "    GROUP BY 1, 2, 3, 4\n",
    "    \"\"\"\n",
    "    try:\n",
    "        client.query(sql).result()\n",
    "        print(\"âœ… agg_airport_trips erstellt.\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Fehler: {e}\")\n",
    "\n",
    "create_airport_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ed1c7461",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 8. Erstelle Tabelle: agg_quality_audit ---\n",
      "âœ… agg_quality_audit erstellt.\n"
     ]
    }
   ],
   "source": [
    "def create_quality_audit_mart():\n",
    "    print(\"--- 8. Erstelle Tabelle: agg_quality_audit ---\")\n",
    "    sql = f\"\"\"\n",
    "    CREATE OR REPLACE TABLE `{PROJECT_ID}.{AGG_DATASET}.agg_quality_audit` AS\n",
    "    SELECT\n",
    "        DATE_TRUNC(pickup_datetime, MONTH) as month,\n",
    "        source_system,\n",
    "        COUNT(*) as total_trips,\n",
    "        COUNTIF(trip_distance = 0 AND source_system != 'FHV') as gps_failures,\n",
    "        COUNTIF(pickup_location_id IN (263, 264)) as unknown_locations,\n",
    "        COUNTIF(dq_issue_flag = TRUE) as total_issues\n",
    "    FROM `{PROJECT_ID}.{DIM_DATASET}.Fact_Trips`\n",
    "    GROUP BY 1, 2\n",
    "    \"\"\"\n",
    "    client.query(sql).result()\n",
    "    print(\"âœ… agg_quality_audit erstellt.\")\n",
    "create_quality_audit_mart()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d92a09a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 7. Erstelle Tabelle: agg_shared_rides ---\n",
      "âœ… agg_shared_rides erstellt.\n"
     ]
    }
   ],
   "source": [
    "def create_shared_ride_stats():\n",
    "    print(\"--- 7. Erstelle Tabelle: agg_shared_rides ---\")\n",
    "    sql = f\"\"\"\n",
    "    CREATE OR REPLACE TABLE `{PROJECT_ID}.{AGG_DATASET}.agg_shared_rides` AS\n",
    "    SELECT\n",
    "        d.year,\n",
    "        f.source_system,\n",
    "        f.sr_flag,\n",
    "        COUNT(*) AS trip_count,\n",
    "        ROUND(AVG(f.fare_amount), 2) AS avg_fare -- Nur fÃ¼r Yellow/Green sinnvoll\n",
    "    FROM `{PROJECT_ID}.{DIM_DATASET}.Fact_Trips` f\n",
    "    JOIN `{PROJECT_ID}.{DIM_DATASET}.dim_date` d ON f.pickup_date_key = d.date_key\n",
    "    GROUP BY 1, 2, 3\n",
    "    \"\"\"\n",
    "    client.query(sql).result()\n",
    "    print(\"âœ… agg_shared_rides erstellt.\")\n",
    "create_shared_ride_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7c37255a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- ðŸ“Š FINAL DATA MART CHECK ---\n",
      "\n",
      "ðŸ• TOP 5 ZEITFENSTER (agg_time_trends):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lania/Documents/GitHub/bi_project_task2/.venv/lib/python3.12/site-packages/google/cloud/bigquery/table.py:1994: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " day_name  hour_of_day source_system  trip_count  avg_fare\n",
      " Thursday           18        YELLOW      429644     29.42\n",
      "Wednesday           18        YELLOW      423982     28.90\n",
      "  Tuesday           18        YELLOW      403973     28.57\n",
      "   Friday           18        YELLOW      397860     28.56\n",
      " Thursday           17        YELLOW      396463     31.39\n",
      "\n",
      "ðŸ“ TOP 5 ROUTEN (agg_route_stats):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lania/Documents/GitHub/bi_project_task2/.venv/lib/python3.12/site-packages/google/cloud/bigquery/table.py:1994: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pickup_borough dropoff_borough  trip_count  avg_cost\n",
      "     Manhattan       Manhattan    12410566     10.13\n",
      "     Manhattan       Manhattan    12330416      9.96\n",
      "     Manhattan       Manhattan    12316988      9.62\n",
      "     Manhattan       Manhattan    11819999     11.80\n",
      "     Manhattan       Manhattan    11183007     12.05\n",
      "\n",
      "âœˆï¸ FLUGHAFEN STATS (agg_airport_trips):\n",
      " year                 trip_category source_system  total_trips  avg_ticket\n",
      " 2014 Standard Rate to Airport Zone        YELLOW       614827       41.43\n",
      " 2013 Standard Rate to Airport Zone        YELLOW       601767       40.22\n",
      " 2012 Standard Rate to Airport Zone        YELLOW       596237       33.02\n",
      " 2015 Standard Rate to Airport Zone        YELLOW       587991       43.20\n",
      " 2011 Standard Rate to Airport Zone        YELLOW       578500       32.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lania/Documents/GitHub/bi_project_task2/.venv/lib/python3.12/site-packages/google/cloud/bigquery/table.py:1994: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "def check_new_marts():\n",
    "    # Stelle sicher, dass die Variablen passen\n",
    "    PROJECT_ID = \"taxi-bi-project\"\n",
    "    AGG_DATASET = \"aggregational\"\n",
    "    \n",
    "    print(\"--- ðŸ“Š FINAL DATA MART CHECK ---\")\n",
    "\n",
    "    # 1. RUSH HOUR (Wann ist am meisten los?)\n",
    "    print(\"\\nðŸ• TOP 5 ZEITFENSTER (agg_time_trends):\")\n",
    "    # Wir sortieren nach trip_count, um die geschÃ¤ftigsten Stunden zu sehen\n",
    "    sql_time = f\"\"\"\n",
    "    SELECT day_name, hour_of_day, source_system, trip_count, avg_fare\n",
    "    FROM `{PROJECT_ID}.{AGG_DATASET}.agg_time_trends`\n",
    "    ORDER BY trip_count DESC\n",
    "    LIMIT 5\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df_time = client.query(sql_time).to_dataframe()\n",
    "        print(df_time.to_string(index=False))\n",
    "    except Exception as e:\n",
    "        print(f\"Fehler: {e}\")\n",
    "\n",
    "    # 2. ROUTEN (Wer fÃ¤hrt von wo nach wo?)\n",
    "    print(\"\\nðŸ“ TOP 5 ROUTEN (agg_route_stats):\")\n",
    "    sql_routes = f\"\"\"\n",
    "    SELECT pickup_borough, dropoff_borough, trip_count, avg_cost\n",
    "    FROM `{PROJECT_ID}.{AGG_DATASET}.agg_route_stats`\n",
    "    ORDER BY trip_count DESC\n",
    "    LIMIT 5\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df_routes = client.query(sql_routes).to_dataframe()\n",
    "        print(df_routes.to_string(index=False))\n",
    "    except Exception as e:\n",
    "        print(f\"Fehler: {e}\")\n",
    "\n",
    "    # 3. FLUGHAFEN (Die Cash Cows)\n",
    "    print(\"\\nâœˆï¸ FLUGHAFEN STATS (agg_airport_trips):\")\n",
    "    sql_air = f\"\"\"\n",
    "    SELECT year, trip_category, source_system, total_trips, avg_ticket\n",
    "    FROM `{PROJECT_ID}.{AGG_DATASET}.agg_airport_trips`\n",
    "    ORDER BY total_trips DESC\n",
    "    LIMIT 5\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df_air = client.query(sql_air).to_dataframe()\n",
    "        print(df_air.to_string(index=False))\n",
    "    except Exception as e:\n",
    "        print(f\"Fehler: {e}\")\n",
    "\n",
    "check_new_marts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "362fa607",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Aktualisiere Peak Hours (mit Monat): taxi-bi-project.aggregational.agg_peak_hours ...\n",
      "âœ… Tabelle 'taxi-bi-project.aggregational.agg_peak_hours' erfolgreich aktualisiert!\n"
     ]
    }
   ],
   "source": [
    "# Funktion fÃ¼r 1) Peak Hours â€“ Taxi Demand\n",
    "def create_agg_peak_hours():\n",
    "    \"\"\"\n",
    "    Erstellt die Tabelle 'agg_peak_hours' im Aggregational Layer.\n",
    "    \n",
    "    Logik:\n",
    "    1. Basis: dimensional.Fact_Trips (Hier sind die Zeitstempel und die Fahrten selbst)\n",
    "    2. Join: dimensional.dim_location (Um statt LocationIDs echte Borough-Namen zu haben)\n",
    "    3. Ergebnis: Eine kleine, schnelle Tabelle, die nur noch Stunden und Anzahl enthÃ¤lt.\n",
    "    \"\"\"\n",
    "    \n",
    "    table_id = f\"{PROJECT_ID}.{AGG_DATASET}.agg_peak_hours\"\n",
    "    print(f\"ðŸ”„ Aktualisiere Peak Hours (mit Monat): {table_id} ...\")\n",
    "    \n",
    "    sql = f\"\"\"\n",
    "    CREATE OR REPLACE TABLE `{table_id}` AS\n",
    "    SELECT\n",
    "        EXTRACT(YEAR FROM f.pickup_datetime) as year,\n",
    "        EXTRACT(MONTH FROM f.pickup_datetime) as month, -- NEU\n",
    "        EXTRACT(HOUR FROM f.pickup_datetime) as hour,\n",
    "        \n",
    "        f.source_system as taxi_type,\n",
    "        COALESCE(loc.Borough, 'Unknown') as borough,\n",
    "        \n",
    "        COUNT(f.trip_id) as trip_count\n",
    "        \n",
    "    FROM `{PROJECT_ID}.{DIM_DATASET}.Fact_Trips` f\n",
    "    LEFT JOIN `{PROJECT_ID}.{DIM_DATASET}.dim_location` loc \n",
    "        ON f.pickup_location_id = loc.location_id\n",
    "        \n",
    "    WHERE f.pickup_datetime IS NOT NULL\n",
    "    \n",
    "    GROUP BY year, month, hour, taxi_type, borough -- NEU: month im Group By\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        client.query(sql).result()\n",
    "        print(f\"âœ… Tabelle '{table_id}' erfolgreich aktualisiert!\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Fehler: {e}\")\n",
    "\n",
    "create_agg_peak_hours()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4a39a97a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Aktualisiere Fare Stats (mit Monat): taxi-bi-project.aggregational.agg_fare_stats ...\n",
      "âœ… Tabelle 'taxi-bi-project.aggregational.agg_fare_stats' erfolgreich aktualisiert!\n"
     ]
    }
   ],
   "source": [
    "# Funktion fÃ¼r 2) Fare Distribution â€“ Boxplot Stats\n",
    "def create_agg_fare_stats():\n",
    "    \"\"\"\n",
    "    Erstellt die Tabelle 'agg_fare_stats' im Aggregational Layer.\n",
    "    \n",
    "    Zweck: \n",
    "    Bereitstellung von statistischen Daten fÃ¼r Boxplots (Preisverteilung).\n",
    "    Anstatt Rohdaten zu laden, berechnen wir Quantile (Min, 25%, Median, 75%, Max).\n",
    "    \n",
    "    Logik:\n",
    "    1. Basis: dimensional.Fact_Trips (fÃ¼r fare_amount)\n",
    "    2. Join: dimensional.dim_location (fÃ¼r Boroughs)\n",
    "    3. Berechnung: APPROX_QUANTILES teilt die Daten in 100 Teile.\n",
    "    \"\"\"\n",
    "    table_id = f\"{PROJECT_ID}.{AGG_DATASET}.agg_fare_stats\"\n",
    "    print(f\"ðŸ”„ Aktualisiere Fare Stats (mit Monat): {table_id} ...\")\n",
    "    \n",
    "    sql = f\"\"\"\n",
    "    CREATE OR REPLACE TABLE `{table_id}` AS\n",
    "    SELECT\n",
    "        EXTRACT(YEAR FROM f.pickup_datetime) as year,\n",
    "        EXTRACT(MONTH FROM f.pickup_datetime) as month, -- NEU\n",
    "        f.source_system as taxi_type,\n",
    "        COALESCE(loc.Borough, 'Unknown') as borough,\n",
    "        \n",
    "        -- Quantile mÃ¼ssen jetzt pro Monat berechnet werden\n",
    "        APPROX_QUANTILES(f.fare_amount, 100)[OFFSET(0)] as min_fare,\n",
    "        APPROX_QUANTILES(f.fare_amount, 100)[OFFSET(25)] as q1_fare,\n",
    "        APPROX_QUANTILES(f.fare_amount, 100)[OFFSET(50)] as median_fare,\n",
    "        APPROX_QUANTILES(f.fare_amount, 100)[OFFSET(75)] as q3_fare,\n",
    "        APPROX_QUANTILES(f.fare_amount, 100)[OFFSET(95)] as max_fare,\n",
    "        \n",
    "        COUNT(*) as trip_count\n",
    "        \n",
    "    FROM `{PROJECT_ID}.{DIM_DATASET}.Fact_Trips` f\n",
    "    JOIN `{PROJECT_ID}.{DIM_DATASET}.dim_location` loc \n",
    "        ON f.pickup_location_id = loc.location_id\n",
    "        \n",
    "    WHERE f.fare_amount > 0 \n",
    "      AND f.fare_amount < 1000\n",
    "      AND loc.Borough NOT IN ('Unknown', 'NV')\n",
    "      \n",
    "    GROUP BY year, month, taxi_type, borough\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        client.query(sql).result()\n",
    "        print(f\"âœ… Tabelle '{table_id}' erfolgreich aktualisiert!\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Fehler: {e}\")\n",
    "\n",
    "create_agg_fare_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8d31936c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Aktualisiere Tip Stats (mit Monat): taxi-bi-project.aggregational.agg_tip_stats ...\n",
      "âœ… Tabelle 'taxi-bi-project.aggregational.agg_tip_stats' erfolgreich aktualisiert!\n"
     ]
    }
   ],
   "source": [
    "def create_agg_tip_stats():\n",
    "    table_id = f\"{PROJECT_ID}.{AGG_DATASET}.agg_tip_stats\"\n",
    "    print(f\"ðŸ”„ Aktualisiere Tip Stats (mit Monat): {table_id} ...\")\n",
    "    \n",
    "    sql = f\"\"\"\n",
    "    CREATE OR REPLACE TABLE `{table_id}` AS\n",
    "    SELECT\n",
    "        EXTRACT(YEAR FROM f.pickup_datetime) as year,\n",
    "        EXTRACT(MONTH FROM f.pickup_datetime) as month, -- NEU\n",
    "        f.source_system as taxi_type,\n",
    "        COALESCE(loc.Borough, 'Unknown') as borough,\n",
    "        \n",
    "        SUM(f.tip_amount) as total_tip,\n",
    "        SUM(f.fare_amount) as total_fare,\n",
    "        COUNT(*) as card_trips\n",
    "        \n",
    "    FROM `{PROJECT_ID}.{DIM_DATASET}.Fact_Trips` f\n",
    "    JOIN `{PROJECT_ID}.{DIM_DATASET}.dim_location` loc \n",
    "        ON f.pickup_location_id = loc.location_id\n",
    "    JOIN `{PROJECT_ID}.{DIM_DATASET}.dim_payment_type` pay \n",
    "        ON f.payment_type_id = pay.payment_type_id\n",
    "        \n",
    "    WHERE pay.payment_description = 'Credit Card' \n",
    "      AND f.fare_amount > 0\n",
    "      AND loc.Borough NOT IN ('Unknown', 'NV')\n",
    "      \n",
    "    GROUP BY year, month, taxi_type, borough\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        client.query(sql).result()\n",
    "        print(f\"âœ… Tabelle '{table_id}' erfolgreich aktualisiert!\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Fehler: {e}\")\n",
    "\n",
    "create_agg_tip_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "677fc5aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Aktualisiere Demand Trends (mit Monat): taxi-bi-project.aggregational.agg_demand_years ...\n",
      "âœ… Tabelle 'taxi-bi-project.aggregational.agg_demand_years' erfolgreich aktualisiert!\n"
     ]
    }
   ],
   "source": [
    "# Funktion fÃ¼r 4) Demand Shift over Years\n",
    "def create_agg_demand_years():\n",
    "    table_id = f\"{PROJECT_ID}.{AGG_DATASET}.agg_demand_years\"\n",
    "    print(f\"ðŸ”„ Aktualisiere Demand Trends (mit Monat): {table_id} ...\")\n",
    "    \n",
    "    sql = f\"\"\"\n",
    "    CREATE OR REPLACE TABLE `{table_id}` AS\n",
    "    SELECT\n",
    "        EXTRACT(YEAR FROM f.pickup_datetime) as year,\n",
    "        EXTRACT(MONTH FROM f.pickup_datetime) as month, -- NEU\n",
    "        f.source_system as taxi_type,\n",
    "        COALESCE(loc.Borough, 'Unknown') as borough,\n",
    "        COUNT(*) as total_trips\n",
    "        \n",
    "    FROM `{PROJECT_ID}.{DIM_DATASET}.Fact_Trips` f\n",
    "    LEFT JOIN `{PROJECT_ID}.{DIM_DATASET}.dim_location` loc \n",
    "        ON f.pickup_location_id = loc.location_id\n",
    "    WHERE f.pickup_datetime IS NOT NULL  \n",
    "    GROUP BY year, month, taxi_type, borough\n",
    "    \"\"\"\n",
    "    try:\n",
    "        client.query(sql).result()\n",
    "        print(f\"âœ… Tabelle '{table_id}' erfolgreich aktualisiert!\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Fehler: {e}\")\n",
    "\n",
    "create_agg_demand_years()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "55c9f9d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Aktualisiere Weekly Patterns (mit Monat): taxi-bi-project.aggregational.agg_weekly_patterns ...\n",
      "âœ… Tabelle 'taxi-bi-project.aggregational.agg_weekly_patterns' erfolgreich aktualisiert!\n"
     ]
    }
   ],
   "source": [
    "def create_agg_weekly_patterns():\n",
    "    table_id = f\"{PROJECT_ID}.{AGG_DATASET}.agg_weekly_patterns\"\n",
    "    print(f\"ðŸ”„ Aktualisiere Weekly Patterns (mit Monat): {table_id} ...\")\n",
    "    \n",
    "    sql = f\"\"\"\n",
    "    CREATE OR REPLACE TABLE `{table_id}` AS\n",
    "    SELECT\n",
    "        EXTRACT(YEAR FROM f.pickup_datetime) as year,\n",
    "        EXTRACT(MONTH FROM f.pickup_datetime) as month, -- NEU\n",
    "        f.source_system as taxi_type,\n",
    "        COALESCE(loc.Borough, 'Unknown') as borough,\n",
    "        d.day_name,\n",
    "        d.day_of_week_num as day_of_week,\n",
    "        EXTRACT(HOUR FROM f.pickup_datetime) as hour,\n",
    "        COUNT(*) as trip_count\n",
    "        \n",
    "    FROM `{PROJECT_ID}.{DIM_DATASET}.Fact_Trips` f\n",
    "    LEFT JOIN `{PROJECT_ID}.{DIM_DATASET}.dim_location` loc \n",
    "        ON f.pickup_location_id = loc.location_id\n",
    "    INNER JOIN `{PROJECT_ID}.{DIM_DATASET}.dim_date` d\n",
    "        ON DATE(f.pickup_datetime) = d.date_key\n",
    "        \n",
    "    WHERE f.pickup_datetime IS NOT NULL\n",
    "    GROUP BY year, month, taxi_type, borough, d.day_name, d.day_of_week_num, hour\n",
    "    \"\"\"\n",
    "    try:\n",
    "        client.query(sql).result()\n",
    "        print(f\"âœ… Tabelle '{table_id}' erfolgreich aktualisiert!\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Fehler: {e}\")\n",
    "\n",
    "create_agg_weekly_patterns()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "51463f5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Aktualisiere Fare Dist (mit Monat): taxi-bi-project.aggregational.agg_fare_dist ...\n",
      "âœ… Tabelle 'taxi-bi-project.aggregational.agg_fare_dist' aktualisiert.\n"
     ]
    }
   ],
   "source": [
    "def create_agg_fare_dist():\n",
    "    table_id = f\"{PROJECT_ID}.{AGG_DATASET}.agg_fare_dist\"\n",
    "    print(f\"ðŸ”„ Aktualisiere Fare Dist (mit Monat): {table_id} ...\")\n",
    "    \n",
    "    sql = f\"\"\"\n",
    "    CREATE OR REPLACE TABLE `{table_id}` AS\n",
    "    SELECT\n",
    "        EXTRACT(YEAR FROM f.pickup_datetime) as year,\n",
    "        EXTRACT(MONTH FROM f.pickup_datetime) as month, -- NEU\n",
    "        f.source_system as taxi_type,\n",
    "        COALESCE(loc.Borough, 'Unknown') as borough,\n",
    "        \n",
    "        ROUND(f.trip_distance * 5) / 5 as dist_bin,\n",
    "        ROUND(f.fare_amount, 0) as fare_bin,\n",
    "        \n",
    "        COUNT(*) as trip_count\n",
    "        \n",
    "    FROM `{PROJECT_ID}.{DIM_DATASET}.Fact_Trips` f\n",
    "    LEFT JOIN `{PROJECT_ID}.{DIM_DATASET}.dim_location` loc \n",
    "        ON f.pickup_location_id = loc.location_id\n",
    "        \n",
    "    WHERE f.pickup_datetime IS NOT NULL\n",
    "      AND f.trip_distance > 0 AND f.trip_distance < 100\n",
    "      AND f.fare_amount > 0 AND f.fare_amount < 500\n",
    "      \n",
    "    GROUP BY year, month, taxi_type, borough, dist_bin, fare_bin\n",
    "    \"\"\"\n",
    "    client.query(sql).result()\n",
    "    print(f\"âœ… Tabelle '{table_id}' aktualisiert.\")\n",
    "\n",
    "create_agg_fare_dist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5be8bd67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Aktualisiere Borough Flows (mit Monat): taxi-bi-project.aggregational.agg_borough_flows ...\n",
      "âœ… Tabelle 'taxi-bi-project.aggregational.agg_borough_flows' aktualisiert.\n"
     ]
    }
   ],
   "source": [
    "def create_agg_flows():\n",
    "    table_id = f\"{PROJECT_ID}.{AGG_DATASET}.agg_borough_flows\"\n",
    "    print(f\"ðŸ”„ Aktualisiere Borough Flows (mit Monat): {table_id} ...\")\n",
    "    \n",
    "    sql = f\"\"\"\n",
    "    CREATE OR REPLACE TABLE `{table_id}` AS\n",
    "    SELECT\n",
    "        EXTRACT(YEAR FROM f.pickup_datetime) as year,\n",
    "        EXTRACT(MONTH FROM f.pickup_datetime) as month, -- NEU\n",
    "        f.source_system as taxi_type,\n",
    "        \n",
    "        COALESCE(loc_pu.Borough, 'Unknown') as pickup_borough,\n",
    "        COALESCE(loc_do.Borough, 'Unknown') as dropoff_borough,\n",
    "        \n",
    "        COUNT(*) as trips\n",
    "        \n",
    "    FROM `{PROJECT_ID}.{DIM_DATASET}.Fact_Trips` f\n",
    "    LEFT JOIN `{PROJECT_ID}.{DIM_DATASET}.dim_location` loc_pu \n",
    "        ON f.pickup_location_id = loc_pu.location_id\n",
    "    LEFT JOIN `{PROJECT_ID}.{DIM_DATASET}.dim_location` loc_do \n",
    "        ON f.dropoff_location_id = loc_do.location_id\n",
    "        \n",
    "    WHERE f.pickup_datetime IS NOT NULL\n",
    "      AND loc_pu.Borough IS NOT NULL AND loc_pu.Borough != 'Unknown'\n",
    "      AND loc_do.Borough IS NOT NULL AND loc_do.Borough != 'Unknown'\n",
    "      \n",
    "    GROUP BY year, month, taxi_type, pickup_borough, dropoff_borough\n",
    "    \"\"\"\n",
    "    client.query(sql).result()\n",
    "    print(f\"âœ… Tabelle '{table_id}' aktualisiert.\")\n",
    "\n",
    "create_agg_flows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4df8a7ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Aktualisiere Efficiency (mit Monat): taxi-bi-project.aggregational.agg_revenue_efficiency ...\n",
      "âœ… Tabelle 'taxi-bi-project.aggregational.agg_revenue_efficiency' aktualisiert.\n"
     ]
    }
   ],
   "source": [
    "def create_agg_revenue_efficiency():\n",
    "    table_id = f\"{PROJECT_ID}.{AGG_DATASET}.agg_revenue_efficiency\"\n",
    "    print(f\"ðŸ”„ Aktualisiere Efficiency (mit Monat): {table_id} ...\")\n",
    "    \n",
    "    sql = f\"\"\"\n",
    "    CREATE OR REPLACE TABLE `{table_id}` AS\n",
    "    WITH raw_calc AS (\n",
    "        SELECT\n",
    "            EXTRACT(YEAR FROM f.pickup_datetime) as year,\n",
    "            EXTRACT(MONTH FROM f.pickup_datetime) as month, -- NEU\n",
    "            f.source_system as taxi_type,\n",
    "            COALESCE(loc.Borough, 'Unknown') as borough,\n",
    "            TIMESTAMP_DIFF(f.dropoff_datetime, f.pickup_datetime, MINUTE) as duration_min,\n",
    "            f.fare_amount\n",
    "        FROM `{PROJECT_ID}.{DIM_DATASET}.Fact_Trips` f\n",
    "        LEFT JOIN `{PROJECT_ID}.{DIM_DATASET}.dim_location` loc\n",
    "            ON f.pickup_location_id = loc.location_id\n",
    "        WHERE f.pickup_datetime IS NOT NULL\n",
    "          AND f.fare_amount > 0\n",
    "          AND TIMESTAMP_DIFF(f.dropoff_datetime, f.pickup_datetime, MINUTE) BETWEEN 1 AND 180\n",
    "    ),\n",
    "    categorized AS (\n",
    "        SELECT *,\n",
    "            CASE\n",
    "                WHEN duration_min < 10 THEN '1. Kurzstrecke (< 10 min)'\n",
    "                WHEN duration_min < 20 THEN '2. Mittel (10 - 20 min)'\n",
    "                WHEN duration_min < 45 THEN '3. Lang (20 - 45 min)'\n",
    "                ELSE '4. Sehr Lang (> 45 min)'\n",
    "            END as trip_category,\n",
    "            SAFE_DIVIDE(fare_amount, duration_min) as fare_per_min\n",
    "        FROM raw_calc\n",
    "    )\n",
    "    SELECT\n",
    "        year, month, taxi_type, borough, trip_category,\n",
    "        COUNT(*) as total_trips,\n",
    "        APPROX_QUANTILES(fare_per_min, 4) as quantiles\n",
    "    FROM categorized\n",
    "    GROUP BY year, month, taxi_type, borough, trip_category\n",
    "    \"\"\"\n",
    "    client.query(sql).result()\n",
    "    print(f\"âœ… Tabelle '{table_id}' aktualisiert.\")\n",
    "\n",
    "create_agg_revenue_efficiency()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8bfb7c35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Erstelle Tabelle: agg_location_map (Optimiert) ---\n",
      "âœ… agg_location_map erfolgreich erstellt.\n"
     ]
    }
   ],
   "source": [
    "def create_agg_location_map():\n",
    "    table_id = f\"{PROJECT_ID}.{AGG_DATASET}.agg_location_map\"\n",
    "    print(f\"ðŸ”„ Erstelle Location Map NEU (mit avg_amount): {table_id} ...\")\n",
    "    \n",
    "    # Wir erstellen die Tabelle komplett neu\n",
    "    sql = f\"\"\"\n",
    "    CREATE OR REPLACE TABLE `{table_id}` AS\n",
    "    SELECT\n",
    "        EXTRACT(YEAR FROM f.pickup_datetime) as year,\n",
    "        EXTRACT(MONTH FROM f.pickup_datetime) as month,\n",
    "        f.source_system as taxi_type,\n",
    "        \n",
    "        f.pickup_location_id as location_id,\n",
    "        loc.Zone as zone,\n",
    "        loc.Borough as borough,\n",
    "        loc.geojson_str, \n",
    "        \n",
    "        COUNT(*) as trip_count,\n",
    "        \n",
    "        -- HIER IST DIE FEHLENDE SPALTE:\n",
    "        AVG(f.total_amount) as avg_amount\n",
    "        \n",
    "    FROM `{PROJECT_ID}.{DIM_DATASET}.Fact_Trips` f\n",
    "    JOIN `{PROJECT_ID}.{DIM_DATASET}.dim_location` loc \n",
    "        ON f.pickup_location_id = loc.location_id\n",
    "        \n",
    "    WHERE f.pickup_datetime IS NOT NULL\n",
    "      AND loc.Borough != 'Unknown'\n",
    "      AND loc.geojson_str IS NOT NULL \n",
    "      \n",
    "    GROUP BY 1, 2, 3, 4, 5, 6, 7\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        client.query(sql).result()\n",
    "        print(f\"âœ… Tabelle '{table_id}' erfolgreich aktualisiert (Spalte avg_amount hinzugefÃ¼gt)!\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ SQL FEHLER: {e}\")\n",
    "\n",
    "create_agg_location_map()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ada39293",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Korrigiere Airport Tabelle (total_trips Spalte): taxi-bi-project.aggregational.agg_airport_connectivity ...\n",
      "âœ… Tabelle 'taxi-bi-project.aggregational.agg_airport_connectivity' erfolgreich korrigiert!\n"
     ]
    }
   ],
   "source": [
    "def create_agg_airport_connectivity():\n",
    "    table_id = f\"{PROJECT_ID}.{AGG_DATASET}.agg_airport_connectivity\"\n",
    "    print(f\"ðŸ”„ Korrigiere Airport Tabelle (total_trips Spalte): {table_id} ...\")\n",
    "    \n",
    "    sql = f\"\"\"\n",
    "    CREATE OR REPLACE TABLE `{table_id}` AS\n",
    "    WITH raw_trips AS (\n",
    "        SELECT\n",
    "            EXTRACT(YEAR FROM f.pickup_datetime) as year,\n",
    "            EXTRACT(MONTH FROM f.pickup_datetime) as month,\n",
    "            f.source_system as taxi_type,\n",
    "            f.total_amount,\n",
    "            f.fare_amount,\n",
    "            f.tip_amount,\n",
    "            f.payment_type_id,\n",
    "            \n",
    "            loc_pu.Zone as pu_zone,\n",
    "            loc_pu.Borough as pu_borough,\n",
    "            loc_do.Zone as do_zone,\n",
    "            loc_do.Borough as do_borough,\n",
    "            f.rate_code_id\n",
    "        FROM `{PROJECT_ID}.{DIM_DATASET}.Fact_Trips` f\n",
    "        LEFT JOIN `{PROJECT_ID}.{DIM_DATASET}.dim_location` loc_pu ON f.pickup_location_id = loc_pu.location_id\n",
    "        LEFT JOIN `{PROJECT_ID}.{DIM_DATASET}.dim_location` loc_do ON f.dropoff_location_id = loc_do.location_id\n",
    "        WHERE f.pickup_datetime IS NOT NULL \n",
    "          AND f.total_amount > 0\n",
    "    )\n",
    "    SELECT\n",
    "        year,\n",
    "        month,\n",
    "        taxi_type,\n",
    "        \n",
    "        -- Dimensions\n",
    "        CASE \n",
    "            WHEN rate_code_id = 2 OR pu_zone LIKE '%JFK%' OR do_zone LIKE '%JFK%' THEN 'JFK'\n",
    "            WHEN rate_code_id = 3 OR pu_zone LIKE '%Newark%' OR do_zone LIKE '%Newark%' THEN 'EWR'\n",
    "            WHEN pu_zone LIKE '%LaGuardia%' OR do_zone LIKE '%LaGuardia%' THEN 'LGA'\n",
    "            ELSE 'Other'\n",
    "        END as airport,\n",
    "\n",
    "        CASE \n",
    "            WHEN rate_code_id = 2 OR rate_code_id = 3 OR pu_zone LIKE '%Airport%' THEN 'From Airport'\n",
    "            ELSE 'To Airport'\n",
    "        END as direction,\n",
    "\n",
    "        CASE \n",
    "            WHEN rate_code_id = 2 OR rate_code_id = 3 OR pu_zone LIKE '%Airport%' THEN do_borough \n",
    "            ELSE pu_borough \n",
    "        END as connected_borough,\n",
    "\n",
    "        -- Metrics\n",
    "        SUM(total_amount) as total_revenue,\n",
    "        \n",
    "        -- HIER WAR DER FEHLER: Wir nennen es jetzt 'total_trips', wie in Python erwartet\n",
    "        COUNT(*) as total_trips,\n",
    "        \n",
    "        SUM(fare_amount) as total_fare_all,\n",
    "        SUM(CASE WHEN payment_type_id = 1 THEN tip_amount ELSE 0 END) as total_tip,\n",
    "        SUM(CASE WHEN payment_type_id = 1 THEN fare_amount ELSE 0 END) as total_fare_card\n",
    "\n",
    "    FROM raw_trips\n",
    "    WHERE \n",
    "       (rate_code_id IN (2,3) \n",
    "        OR pu_zone LIKE '%Airport%' \n",
    "        OR do_zone LIKE '%Airport%')\n",
    "    \n",
    "    GROUP BY 1, 2, 3, 4, 5, 6\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        client.query(sql).result()\n",
    "        print(f\"âœ… Tabelle '{table_id}' erfolgreich korrigiert!\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Fehler: {e}\")\n",
    "\n",
    "create_agg_airport_connectivity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "915b351a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Aktualisiere Tip Distribution (mit Monat): taxi-bi-project.aggregational.agg_tip_distribution ...\n",
      "ðŸ”„ Aktualisiere Tip Zone Ranking (mit Monat): taxi-bi-project.aggregational.agg_tip_zone_ranking ...\n",
      "âœ… Tip-Tabellen erfolgreich aktualisiert!\n"
     ]
    }
   ],
   "source": [
    "# Zelle: Aggregation 10 - Tip Deep Dive (Update: Feinere GranularitÃ¤t > 25%)\n",
    "\n",
    "def create_tip_deepdive_tables():\n",
    "    # 1. Distribution\n",
    "    table_dist = f\"{PROJECT_ID}.{AGG_DATASET}.agg_tip_distribution\"\n",
    "    print(f\"ðŸ”„ Aktualisiere Tip Distribution (mit Monat): {table_dist} ...\")\n",
    "    \n",
    "    sql_dist = f\"\"\"\n",
    "    CREATE OR REPLACE TABLE `{table_dist}` AS\n",
    "    SELECT\n",
    "        EXTRACT(YEAR FROM f.pickup_datetime) as year,\n",
    "        EXTRACT(MONTH FROM f.pickup_datetime) as month, -- NEU\n",
    "        f.source_system as taxi_type,\n",
    "        COALESCE(loc.Borough, 'Unknown') as borough,\n",
    "        \n",
    "        CASE \n",
    "            WHEN f.tip_amount = 0 THEN '0% (No Tip)'\n",
    "            WHEN SAFE_DIVIDE(f.tip_amount, f.fare_amount) < 0.10 THEN '0 - 10%'\n",
    "            WHEN SAFE_DIVIDE(f.tip_amount, f.fare_amount) BETWEEN 0.10 AND 0.149 THEN '10 - 15%'\n",
    "            WHEN SAFE_DIVIDE(f.tip_amount, f.fare_amount) BETWEEN 0.149 AND 0.199 THEN '15 - 20%'\n",
    "            WHEN SAFE_DIVIDE(f.tip_amount, f.fare_amount) BETWEEN 0.199 AND 0.249 THEN '20 - 25%'\n",
    "            WHEN SAFE_DIVIDE(f.tip_amount, f.fare_amount) BETWEEN 0.249 AND 0.299 THEN '25 - 30%'\n",
    "            WHEN SAFE_DIVIDE(f.tip_amount, f.fare_amount) BETWEEN 0.299 AND 0.349 THEN '30 - 35%'\n",
    "            WHEN SAFE_DIVIDE(f.tip_amount, f.fare_amount) >= 0.349 THEN '> 35%'\n",
    "            ELSE 'Unknown'\n",
    "        END as tip_bin,\n",
    "        \n",
    "        CASE \n",
    "            WHEN f.tip_amount = 0 THEN 1\n",
    "            WHEN SAFE_DIVIDE(f.tip_amount, f.fare_amount) < 0.10 THEN 2\n",
    "            WHEN SAFE_DIVIDE(f.tip_amount, f.fare_amount) BETWEEN 0.10 AND 0.149 THEN 3\n",
    "            WHEN SAFE_DIVIDE(f.tip_amount, f.fare_amount) BETWEEN 0.149 AND 0.199 THEN 4\n",
    "            WHEN SAFE_DIVIDE(f.tip_amount, f.fare_amount) BETWEEN 0.199 AND 0.249 THEN 5\n",
    "            WHEN SAFE_DIVIDE(f.tip_amount, f.fare_amount) BETWEEN 0.249 AND 0.299 THEN 6\n",
    "            WHEN SAFE_DIVIDE(f.tip_amount, f.fare_amount) BETWEEN 0.299 AND 0.349 THEN 7\n",
    "            WHEN SAFE_DIVIDE(f.tip_amount, f.fare_amount) >= 0.349 THEN 8\n",
    "            ELSE 9\n",
    "        END as bin_order,\n",
    "\n",
    "        COUNT(*) as trip_count\n",
    "\n",
    "    FROM `{PROJECT_ID}.{DIM_DATASET}.Fact_Trips` f\n",
    "    JOIN `{PROJECT_ID}.{DIM_DATASET}.dim_location` loc \n",
    "        ON f.pickup_location_id = loc.location_id\n",
    "        \n",
    "    WHERE f.payment_type_id = 1 AND f.fare_amount > 0 AND f.total_amount > 0\n",
    "    GROUP BY year, month, taxi_type, borough, tip_bin, bin_order\n",
    "    \"\"\"\n",
    "    \n",
    "    # 2. Zone Ranking\n",
    "    table_zones = f\"{PROJECT_ID}.{AGG_DATASET}.agg_tip_zone_ranking\"\n",
    "    print(f\"ðŸ”„ Aktualisiere Tip Zone Ranking (mit Monat): {table_zones} ...\")\n",
    "    \n",
    "    sql_zones = f\"\"\"\n",
    "    CREATE OR REPLACE TABLE `{table_zones}` AS\n",
    "    SELECT\n",
    "        EXTRACT(YEAR FROM f.pickup_datetime) as year,\n",
    "        EXTRACT(MONTH FROM f.pickup_datetime) as month, -- NEU\n",
    "        f.source_system as taxi_type,\n",
    "        loc.Borough as borough,\n",
    "        loc.Zone as zone,\n",
    "        \n",
    "        COUNT(*) as trips,\n",
    "        ROUND(SAFE_DIVIDE(SUM(f.tip_amount), SUM(f.fare_amount)) * 100, 1) as avg_tip_pct\n",
    "\n",
    "    FROM `{PROJECT_ID}.{DIM_DATASET}.Fact_Trips` f\n",
    "    JOIN `{PROJECT_ID}.{DIM_DATASET}.dim_location` loc \n",
    "        ON f.pickup_location_id = loc.location_id\n",
    "        \n",
    "    WHERE f.payment_type_id = 1 AND f.fare_amount > 0\n",
    "    GROUP BY year, month, taxi_type, borough, zone\n",
    "    HAVING trips > 50 \n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        client.query(sql_dist).result()\n",
    "        client.query(sql_zones).result()\n",
    "        print(\"âœ… Tip-Tabellen erfolgreich aktualisiert!\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Fehler: {e}\")\n",
    "\n",
    "create_tip_deepdive_tables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d5d87266",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“ˆ Erstelle Tabelle: taxi-bi-project.aggregational.agg_seasonality_borough (Alle Trips, keine Umsatz-Filter) ...\n",
      "âœ… Tabelle 'taxi-bi-project.aggregational.agg_seasonality_borough' erfolgreich aktualisiert!\n"
     ]
    }
   ],
   "source": [
    "def create_agg_seasonality_borough():\n",
    "    # Wir Ã¼berschreiben die Tabelle - diesmal REIN auf Basis von Trip-Counts (Nachfrage)\n",
    "    table_id = f\"{PROJECT_ID}.{AGG_DATASET}.agg_seasonality_borough\"\n",
    "    print(f\"ðŸ“ˆ Erstelle Tabelle: {table_id} (Alle Trips, keine Umsatz-Filter) ...\")\n",
    "    \n",
    "    sql = f\"\"\"\n",
    "    CREATE OR REPLACE TABLE `{table_id}` AS\n",
    "    SELECT\n",
    "        EXTRACT(YEAR FROM f.pickup_datetime) as year,\n",
    "        EXTRACT(MONTH FROM f.pickup_datetime) as month,\n",
    "        FORMAT_DATE('%B', f.pickup_datetime) as month_name,\n",
    "        f.source_system as taxi_type,\n",
    "        COALESCE(loc.Borough, 'Unknown') as borough,\n",
    "        \n",
    "        -- WICHTIG: Einfach nur zÃ¤hlen. Das ist die Nachfrage.\n",
    "        COUNT(*) as total_trips\n",
    "        \n",
    "    FROM `{PROJECT_ID}.{DIM_DATASET}.Fact_Trips` f\n",
    "    LEFT JOIN `{PROJECT_ID}.{DIM_DATASET}.dim_location` loc \n",
    "        ON f.pickup_location_id = loc.location_id\n",
    "        \n",
    "    WHERE f.pickup_datetime IS NOT NULL\n",
    "      -- KEIN Filter auf total_amount > 0 mehr! \n",
    "      -- Damit sind auch FHV-Fahrten ohne Preisinfo enthalten.\n",
    "      \n",
    "    GROUP BY 1, 2, 3, 4, 5\n",
    "    \"\"\"\n",
    "    try:\n",
    "        client.query(sql).result()\n",
    "        print(f\"âœ… Tabelle '{table_id}' erfolgreich aktualisiert!\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Fehler: {e}\")\n",
    "\n",
    "create_agg_seasonality_borough()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "187e4147",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Aktualisiere Route Revenues (mit Monat): taxi-bi-project.aggregational.agg_route_revenues ...\n",
      "âœ… Tabelle 'taxi-bi-project.aggregational.agg_route_revenues' erfolgreich aktualisiert!\n"
     ]
    }
   ],
   "source": [
    "def create_agg_route_revenues():\n",
    "    table_id = f\"{PROJECT_ID}.{AGG_DATASET}.agg_route_revenues\"\n",
    "    print(f\"ðŸ”„ Aktualisiere Route Revenues (mit Monat): {table_id} ...\")\n",
    "    \n",
    "    sql = f\"\"\"\n",
    "    CREATE OR REPLACE TABLE `{table_id}` AS\n",
    "    SELECT\n",
    "        EXTRACT(YEAR FROM f.pickup_datetime) as year,\n",
    "        EXTRACT(MONTH FROM f.pickup_datetime) as month, -- NEU\n",
    "        f.source_system as taxi_type,\n",
    "        COALESCE(loc_pu.Borough, 'Unknown') as pickup_borough,\n",
    "        COALESCE(loc_do.Borough, 'Unknown') as dropoff_borough,\n",
    "        \n",
    "        COUNT(*) as total_trips,\n",
    "        SUM(f.total_amount) as total_revenue,\n",
    "        AVG(f.total_amount) as avg_fare,\n",
    "        AVG(f.trip_distance) as avg_distance\n",
    "        \n",
    "    FROM `{PROJECT_ID}.{DIM_DATASET}.Fact_Trips` f\n",
    "    LEFT JOIN `{PROJECT_ID}.{DIM_DATASET}.dim_location` loc_pu \n",
    "        ON f.pickup_location_id = loc_pu.location_id\n",
    "    LEFT JOIN `{PROJECT_ID}.{DIM_DATASET}.dim_location` loc_do \n",
    "        ON f.dropoff_location_id = loc_do.location_id\n",
    "        \n",
    "    WHERE f.pickup_datetime IS NOT NULL \n",
    "      AND f.total_amount > 0\n",
    "      AND loc_pu.Borough != 'Unknown' \n",
    "      AND loc_do.Borough != 'Unknown'\n",
    "      \n",
    "    GROUP BY year, month, taxi_type, pickup_borough, dropoff_borough\n",
    "    \"\"\"\n",
    "    try:\n",
    "        client.query(sql).result()\n",
    "        print(f\"âœ… Tabelle '{table_id}' erfolgreich aktualisiert!\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Fehler: {e}\")\n",
    "\n",
    "create_agg_route_revenues()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

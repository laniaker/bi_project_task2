{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37c66ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zelle 1: Setup & Config\n",
    "from google.cloud import bigquery\n",
    "from google.api_core.exceptions import NotFound\n",
    "\n",
    "import pandas as pd\n",
    "import uuid\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# sorgt daf√ºr, dass Plots im Notebook angezeigt werden\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d68c4b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- DIAGNOSE & REPARATUR ---\n",
      "‚úÖ QUELLE GEFUNDEN: Dataset 'staging' liegt in Region: 'EU'\n",
      "OK: Ziel-Dataset liegt bereits korrekt in 'EU'.\n",
      "\n",
      "Ready. Bitte jetzt Zelle 3 ausf√ºhren.\n"
     ]
    }
   ],
   "source": [
    "# Zelle 1 & 2: Setup mit automatischer Regionen-Korrektur\n",
    "from google.cloud import bigquery\n",
    "from google.api_core.exceptions import NotFound\n",
    "import logging\n",
    "import uuid\n",
    "import datetime\n",
    "\n",
    "# Logging Setup\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(message)s')\n",
    "logger = logging.getLogger()\n",
    "\n",
    "# --- CONFIG ---\n",
    "PROJECT_ID = \"taxi-bi-project\" # Deine ID aus dem Log\n",
    "SOURCE_DATASET = \"staging\"     # <--- Laut deinem Fehlerlog hei√üt es \"staging\"!\n",
    "TARGET_DATASET = \"canonical\"   \n",
    "\n",
    "# Tabellen\n",
    "TARGET_TABLE = \"canonical_unified_taxi\"\n",
    "ERROR_TABLE = \"error_records\"\n",
    "LOG_TABLE = \"etl_process_log\"\n",
    "\n",
    "client = bigquery.Client(project=PROJECT_ID)\n",
    "\n",
    "print(\"--- DIAGNOSE & REPARATUR ---\")\n",
    "try:\n",
    "    src_ds_ref = client.get_dataset(f\"{PROJECT_ID}.{SOURCE_DATASET}\")\n",
    "    CORRECT_LOCATION = src_ds_ref.location\n",
    "    print(f\"‚úÖ QUELLE GEFUNDEN: Dataset '{SOURCE_DATASET}' liegt in Region: '{CORRECT_LOCATION}'\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå KRITISCHER FEHLER: Konnte Quell-Dataset '{SOURCE_DATASET}' nicht finden!\")\n",
    "    print(\"Bitte pr√ºfe: Hei√üt dein Dataset in BigQuery wirklich 'staging' oder 'taxi_dwh'?\")\n",
    "    raise e\n",
    "\n",
    "# 2. Pr√ºfen, ob das Ziel-Dataset 'canonical' falsch liegt\n",
    "target_dataset_id = f\"{PROJECT_ID}.{TARGET_DATASET}\"\n",
    "try:\n",
    "    tgt_ds = client.get_dataset(target_dataset_id)\n",
    "    if tgt_ds.location != CORRECT_LOCATION:\n",
    "        print(f\"‚ö†Ô∏è KONFLIKT: Ziel '{TARGET_DATASET}' ist in '{tgt_ds.location}', muss aber nach '{CORRECT_LOCATION}'.\")\n",
    "        print(\"   L√∂sche falsches Dataset...\")\n",
    "        client.delete_dataset(target_dataset_id, delete_contents=True, not_found_ok=True)\n",
    "        print(\"   Gel√∂scht. Wird neu erstellt.\")\n",
    "        tgt_ds = None\n",
    "except NotFound:\n",
    "    tgt_ds = None\n",
    "\n",
    "# 3. Ziel-Dataset korrekt neu erstellen\n",
    "if not tgt_ds:\n",
    "    new_ds = bigquery.Dataset(target_dataset_id)\n",
    "    new_ds.location = CORRECT_LOCATION # <--- Hier zwingen wir die richtige Region!\n",
    "    client.create_dataset(new_ds)\n",
    "    print(f\"ZIEL ERSTELLT: Dataset '{TARGET_DATASET}' erfolgreich in Region '{CORRECT_LOCATION}' angelegt.\")\n",
    "else:\n",
    "    print(f\"OK: Ziel-Dataset liegt bereits korrekt in '{CORRECT_LOCATION}'.\")\n",
    "\n",
    "# Globale Variablen aktualisieren\n",
    "table_ref = f\"{PROJECT_ID}.{TARGET_DATASET}.{TARGET_TABLE}\"\n",
    "error_table_ref = f\"{PROJECT_ID}.{TARGET_DATASET}.{ERROR_TABLE}\"\n",
    "log_table_ref = f\"{PROJECT_ID}.{TARGET_DATASET}.{LOG_TABLE}\"\n",
    "\n",
    "print(\"\\nReady. Bitte jetzt Zelle 3 ausf√ºhren.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "fb071641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- üîç DIAGNOSE: Fehlen Location IDs bei alten Yellow Trips? ---\n",
      " year  total_trips  missing_pu_ids  missing_do_ids  pct_missing\n",
      " 2010      4514348               0               0          0.0\n",
      " 2011      4660462               0               0          0.0\n",
      " 2012      4669852               0               0          0.0\n",
      " 2013      4596563               0               0          0.0\n",
      " 2014      4555520               0               0          0.0\n",
      " 2015      8659004               0               0          0.0\n",
      " 2016      8421023               0               0          0.0\n",
      " 2017      8005526               0               0          0.0\n",
      " 2018      7655156               0               0          0.0\n",
      " 2019      6855858               0               0          0.0\n",
      " 2020       982184               0               0          0.0\n",
      " 2021      3859939               0               0          0.0\n",
      " 2022      4530162               0               0          0.0\n",
      " 2023      4241230               0               0          0.0\n",
      " 2024      4315051               0               0          0.0\n",
      " 2025      4669429               0               0          0.0\n",
      "\n",
      "‚úÖ Entwarnung: Die Staging-Tabelle scheint das schon bereinigt zu haben.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lania/Documents/GitHub/bi_project_task2/.venv/lib/python3.12/site-packages/google/cloud/bigquery/table.py:1994: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "def check_missing_locations_by_year():\n",
    "    print(\"--- üîç DIAGNOSE: Fehlen Location IDs bei alten Yellow Trips? ---\")\n",
    "    \n",
    "    # Wir gruppieren nach Jahr und z√§hlen, wie viele IDs fehlen\n",
    "    query = f\"\"\"\n",
    "    SELECT \n",
    "        EXTRACT(YEAR FROM pickup_datetime) as year,\n",
    "        COUNT(*) as total_trips,\n",
    "        COUNTIF(pickup_location_id IS NULL OR pickup_location_id = 0) as missing_pu_ids,\n",
    "        COUNTIF(dropoff_location_id IS NULL OR dropoff_location_id = 0) as missing_do_ids,\n",
    "        \n",
    "        -- Prozentualer Anteil der Fehler\n",
    "        ROUND(COUNTIF(pickup_location_id IS NULL OR pickup_location_id = 0) / COUNT(*) * 100, 2) as pct_missing\n",
    "        \n",
    "    FROM `{table_ref}`  -- Das ist deine 'canonical_unified_taxi'\n",
    "    WHERE source_system = 'YELLOW'\n",
    "    GROUP BY 1\n",
    "    ORDER BY 1\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        df = client.query(query).to_dataframe()\n",
    "        print(df.to_string(index=False))\n",
    "        \n",
    "        # Sofortige Analyse\n",
    "        if df['pct_missing'].max() > 10:\n",
    "            print(\"\\n‚ö†Ô∏è ALARM: Wir haben signifikante L√ºcken bei den Location IDs!\")\n",
    "            print(\"   -> Wahrscheinlich m√ºssen wir Longitude/Latitude mappen.\")\n",
    "        else:\n",
    "            print(\"\\n‚úÖ Entwarnung: Die Staging-Tabelle scheint das schon bereinigt zu haben.\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Fehler bei der Diagnose: {e}\")\n",
    "\n",
    "check_missing_locations_by_year()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0a050b00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- üïµÔ∏è‚Äç‚ôÇÔ∏è STAGING INSPECTION (Yellow Taxi) ---\n",
      "Gefundene Spalten in 'taxi-bi-project.staging.yellow_staging_unified':\n",
      " - Airport_fee\n",
      " - DOLocationID\n",
      " - PULocationID\n",
      " - RatecodeID\n",
      " - VendorID\n",
      " - congestion_surcharge\n",
      " - dropoff_latitude\n",
      " - dropoff_longitude\n",
      " - duplicate_flag\n",
      " - extra\n",
      " - fare_amount\n",
      " - improvement_surcharge\n",
      " - missing_flag\n",
      " - mta_tax\n",
      " - passenger_count\n",
      " - payment_type\n",
      " - pickup_latitude\n",
      " - pickup_longitude\n",
      " - store_and_fwd_flag\n",
      " - tip_amount\n",
      " - tolls_amount\n",
      " - total_amount\n",
      " - tpep_dropoff_datetime\n",
      " - tpep_pickup_datetime\n",
      " - trip_distance\n",
      "\n",
      "üîç Koordinaten-Check:\n",
      "‚úÖ Koordinaten gefunden: ['dropoff_latitude', 'dropoff_longitude', 'pickup_latitude', 'pickup_longitude']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lania/Documents/GitHub/bi_project_task2/.venv/lib/python3.12/site-packages/google/cloud/bigquery/table.py:1994: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "def inspect_staging_columns():\n",
    "    print(\"--- üïµÔ∏è‚Äç‚ôÇÔ∏è STAGING INSPECTION (Yellow Taxi) ---\")\n",
    "    \n",
    "    # Wir schauen uns eine Zeile aus der Staging Tabelle an\n",
    "    # Stelle sicher, dass der Tabellenname stimmt (yellow_staging_unified)\n",
    "    table_id = f\"{PROJECT_ID}.{SOURCE_DATASET}.yellow_staging_unified\"\n",
    "    \n",
    "    try:\n",
    "        # Wir laden nur die Spaltennamen\n",
    "        df = client.query(f\"SELECT * FROM `{table_id}` LIMIT 1\").to_dataframe()\n",
    "        \n",
    "        print(f\"Gefundene Spalten in '{table_id}':\")\n",
    "        cols = sorted(df.columns)\n",
    "        for c in cols:\n",
    "            print(f\" - {c}\")\n",
    "            \n",
    "        # Spezifischer Check auf Koordinaten\n",
    "        print(\"\\nüîç Koordinaten-Check:\")\n",
    "        coord_cols = [c for c in cols if 'lat' in c.lower() or 'lon' in c.lower()]\n",
    "        if coord_cols:\n",
    "            print(f\"‚úÖ Koordinaten gefunden: {coord_cols}\")\n",
    "        else:\n",
    "            print(\"‚ùå Keine direkten Koordinaten-Spalten (Lat/Lon) gefunden.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Fehler beim Lesen von Staging: {e}\")\n",
    "\n",
    "inspect_staging_columns()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "bf5f2caa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Tabelle neu erstellt: canonical_unified_taxi (Partition: MONTH)\n",
      "‚úÖ Tabelle neu erstellt: error_records (Partition: DAY)\n"
     ]
    }
   ],
   "source": [
    "# Zelle 2: Schema Definition (Fix: MONTH Partitioning)\n",
    "def create_all_tables():\n",
    "    base_schema = [\n",
    "        bigquery.SchemaField(\"trip_id\", \"STRING\", mode=\"REQUIRED\"),\n",
    "        bigquery.SchemaField(\"source_system\", \"STRING\", mode=\"REQUIRED\"),\n",
    "        bigquery.SchemaField(\"load_date\", \"TIMESTAMP\", mode=\"REQUIRED\"),\n",
    "        bigquery.SchemaField(\"vendor_id\", \"STRING\"), \n",
    "        bigquery.SchemaField(\"Affiliated_base_number\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"dispatching_base_nummer\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"pickup_datetime\", \"TIMESTAMP\", mode=\"REQUIRED\"),\n",
    "        bigquery.SchemaField(\"dropoff_datetime\", \"TIMESTAMP\"),\n",
    "        bigquery.SchemaField(\"pickup_location_id\", \"INT64\"), \n",
    "        bigquery.SchemaField(\"dropoff_location_id\", \"INT64\"), \n",
    "        bigquery.SchemaField(\"passenger_count\", \"INT64\"),\n",
    "        bigquery.SchemaField(\"trip_distance\", \"FLOAT64\"),\n",
    "        bigquery.SchemaField(\"store_and_fwd_flag\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"RatecodeID\", \"INT64\"),\n",
    "        bigquery.SchemaField(\"Trip_type\", \"INT64\"),\n",
    "        bigquery.SchemaField(\"SR_Flag\", \"BOOLEAN\"), \n",
    "        bigquery.SchemaField(\"fare_amount\", \"FLOAT64\"),\n",
    "        bigquery.SchemaField(\"tip_amount\", \"FLOAT64\"),\n",
    "        bigquery.SchemaField(\"total_amount\", \"FLOAT64\"),\n",
    "        bigquery.SchemaField(\"payment_type\", \"INT64\"),\n",
    "        bigquery.SchemaField(\"extra\", \"FLOAT64\"),\n",
    "        bigquery.SchemaField(\"mta_tax\", \"FLOAT64\"),\n",
    "        bigquery.SchemaField(\"tolls_amount\", \"FLOAT64\"),\n",
    "        bigquery.SchemaField(\"improvement_surcharge\", \"FLOAT64\"),\n",
    "        bigquery.SchemaField(\"congestion_surcharge\", \"FLOAT64\"),\n",
    "        bigquery.SchemaField(\"Airport_fee\", \"FLOAT64\"), \n",
    "        bigquery.SchemaField(\"ehail_fee\", \"FLOAT64\"),   \n",
    "        bigquery.SchemaField(\"dq_issue_flag\", \"BOOLEAN\") \n",
    "    ]\n",
    "\n",
    "    error_schema = base_schema + [bigquery.SchemaField(\"rejection_reason\", \"STRING\")]\n",
    "\n",
    "    # Hier setzen wir explizit MONTH statt DAY\n",
    "    tables_to_create = [\n",
    "        (table_ref, base_schema, \"pickup_datetime\", bigquery.TimePartitioningType.MONTH),\n",
    "        (error_table_ref, error_schema, \"load_date\", bigquery.TimePartitioningType.DAY) # Error bleibt DAY, da load_date nur HEUTE ist\n",
    "    ]\n",
    "\n",
    "    for t_ref, t_schema, p_field, p_type in tables_to_create:\n",
    "        try:\n",
    "            client.delete_table(t_ref, not_found_ok=True)\n",
    "            t = bigquery.Table(t_ref, schema=t_schema)\n",
    "            \n",
    "            t.time_partitioning = bigquery.TimePartitioning(\n",
    "                field=p_field,\n",
    "                type_=p_type\n",
    "            )\n",
    "            \n",
    "            t.clustering_fields = [\"source_system\", \"vendor_id\"]\n",
    "            client.create_table(t)\n",
    "            print(f\"‚úÖ Tabelle neu erstellt: {t_ref.split('.')[-1]} (Partition: {p_type})\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Fehler bei {t_ref}: {e}\")\n",
    "\n",
    "create_all_tables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "e9ea5df0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starte finale ETL Pipeline f√ºr den Canonical Layer...\n",
      "‚úÖ ETL Job erfolgreich abgeschlossen.\n",
      "   - Syntax-Fehler (Semikolon) behoben.\n",
      "   - Spalten-Alignment f√ºr INSERT sichergestellt.\n"
     ]
    }
   ],
   "source": [
    "def run_etl_split_logic():\n",
    "    print(f\"üöÄ Starte finale ETL Pipeline f√ºr den Canonical Layer...\")\n",
    "    \n",
    "    query = f\"\"\"\n",
    "    BEGIN\n",
    "        -- 1. TRANSFORMATION IN TEMP-SPEICHER\n",
    "        CREATE OR REPLACE TEMP TABLE temp_trips_processed AS\n",
    "        WITH combined_raw AS (\n",
    "            -- (A) YELLOW: 2023 (voll) + Juni (2010-2025)\n",
    "            SELECT \n",
    "                'YELLOW' as src,\n",
    "                CASE \n",
    "                    WHEN UPPER(CAST(VendorID AS STRING)) IN ('CMT', '1') THEN '1'\n",
    "                    WHEN UPPER(CAST(VendorID AS STRING)) IN ('VTS', '2', 'VERIFONE', 'CURB') THEN '2'\n",
    "                    WHEN UPPER(CAST(VendorID AS STRING)) = 'DDS' THEN '3' \n",
    "                    WHEN CAST(VendorID AS STRING) = '6' THEN '6'\n",
    "                    WHEN CAST(VendorID AS STRING) = '7' THEN '7'\n",
    "                    ELSE '99' \n",
    "                END as vid,\n",
    "                COALESCE(SAFE_CAST(tpep_pickup_datetime AS TIMESTAMP), SAFE.PARSE_TIMESTAMP('%Y-%m-%d %H:%M:%S', CAST(tpep_pickup_datetime AS STRING))) as t_pick,\n",
    "                COALESCE(SAFE_CAST(tpep_dropoff_datetime AS TIMESTAMP), SAFE.PARSE_TIMESTAMP('%Y-%m-%d %H:%M:%S', CAST(tpep_dropoff_datetime AS STRING))) as t_drop,\n",
    "                COALESCE(CAST(PULocationID AS INT64), (SELECT ANY_VALUE(location_id) FROM `{PROJECT_ID}.{SOURCE_DATASET}.taxi_zones_geo` WHERE ST_WITHIN(SAFE.ST_GEOGPOINT(pickup_longitude, pickup_latitude), zone_geom)), 263) as loc_pu,\n",
    "                COALESCE(CAST(DOLocationID AS INT64), (SELECT ANY_VALUE(location_id) FROM `{PROJECT_ID}.{SOURCE_DATASET}.taxi_zones_geo` WHERE ST_WITHIN(SAFE.ST_GEOGPOINT(dropoff_longitude, dropoff_latitude), zone_geom)), 263) as loc_do,\n",
    "                IFNULL(CAST(passenger_count AS INT64), 1) as pax, \n",
    "                CAST(trip_distance AS FLOAT64) as dist, \n",
    "                IFNULL(CAST(store_and_fwd_flag AS STRING), 'N') as flag,\n",
    "                COALESCE(SAFE_CAST(RatecodeID AS INT64), 99) as rate,\n",
    "                1 as t_type, \n",
    "                CAST(NULL AS BOOL) as sr_flag,\n",
    "                GREATEST(IFNULL(CAST(fare_amount AS FLOAT64), 0), 0) as f_amt,\n",
    "                GREATEST(IFNULL(CAST(tip_amount AS FLOAT64), 0), 0) as t_amt,\n",
    "                GREATEST(IFNULL(CAST(total_amount AS FLOAT64), 0), 0) as tot_amt,\n",
    "                CASE \n",
    "                    WHEN LOWER(CAST(payment_type AS STRING)) IN ('cre', 'credit', '1') THEN 1 \n",
    "                    WHEN LOWER(CAST(payment_type AS STRING)) IN ('cas', 'cash', '2') THEN 2 \n",
    "                    WHEN LOWER(CAST(payment_type AS STRING)) IN ('no', '3') THEN 3\n",
    "                    ELSE 5 \n",
    "                END as pay,\n",
    "                GREATEST(IFNULL(CAST(extra AS FLOAT64), 0), 0) as ex,\n",
    "                GREATEST(IFNULL(CAST(mta_tax AS FLOAT64), 0), 0) as mt, \n",
    "                GREATEST(IFNULL(CAST(tolls_amount AS FLOAT64), 0), 0) as tl,\n",
    "                GREATEST(IFNULL(CAST(improvement_surcharge AS FLOAT64), 0), 0) as im, \n",
    "                GREATEST(IFNULL(CAST(congestion_surcharge AS FLOAT64), 0), 0) as co,\n",
    "                GREATEST(IFNULL(CAST(Airport_fee AS FLOAT64), 0), 0) as ai, \n",
    "                CAST(NULL AS FLOAT64) as eh, \n",
    "                CAST(NULL AS STRING) as aff, \n",
    "                CAST(NULL AS STRING) as disp\n",
    "            FROM `{PROJECT_ID}.{SOURCE_DATASET}.yellow_staging_unified`\n",
    "            WHERE (EXTRACT(YEAR FROM tpep_pickup_datetime) = 2023) \n",
    "               OR (EXTRACT(MONTH FROM tpep_pickup_datetime) = 6)\n",
    "\n",
    "            UNION ALL\n",
    "\n",
    "           -- (B) GREEN: Mit Rescue-Logik f√ºr 2018 (Hier ist dein angepasster Block!)\n",
    "            SELECT \n",
    "                'GREEN' as src, \n",
    "                -- VENDOR MAPPING (Identisch zu Yellow f√ºr volle Konsistenz)\n",
    "                CASE \n",
    "                    WHEN UPPER(CAST(VendorID AS STRING)) IN ('CMT', '1') THEN '1'\n",
    "                    WHEN UPPER(CAST(VendorID AS STRING)) IN ('VTS', '2', 'VERIFONE', 'CURB') THEN '2'\n",
    "                    ELSE CAST(VendorID AS STRING) \n",
    "                END as vid,\n",
    "                CAST(lpep_pickup_datetime AS TIMESTAMP) as t_pick, \n",
    "                CAST(lpep_dropoff_datetime AS TIMESTAMP) as t_drop,\n",
    "                CAST(IFNULL(PULocationID, 263) AS INT64) as loc_pu, \n",
    "                CAST(IFNULL(DOLocationID, 263) AS INT64) as loc_do,\n",
    "                CAST(passenger_count AS INT64) as pax, \n",
    "                CAST(trip_distance AS FLOAT64) as dist, \n",
    "                store_and_fwd_flag as flag,\n",
    "                CAST(RatecodeID AS INT64) as rate, \n",
    "                CAST(trip_type AS INT64) as t_type, \n",
    "                -- SR_FLAG FIX: Green ist kein App-Pooler, also FALSE statt NULL\n",
    "                FALSE as sr_flag,\n",
    "                fare_amount as f_amt, \n",
    "                tip_amount as t_amt, \n",
    "                total_amount as tot_amt, \n",
    "                -- DEINE RESCUE LOGIK (Bleibt nat√ºrlich drin!)\n",
    "                CASE \n",
    "                    WHEN payment_type IS NOT NULL THEN CAST(ROUND(SAFE_CAST(payment_type AS FLOAT64)) AS INT64)\n",
    "                    WHEN payment_type IS NULL AND fare_amount > 0 THEN 5 \n",
    "                    ELSE 0 \n",
    "                END AS pay,\n",
    "                extra as ex, \n",
    "                mta_tax as mt, \n",
    "                tolls_amount as tl, \n",
    "                improvement_surcharge as im, \n",
    "                congestion_surcharge as co, \n",
    "                0.0 as ai, \n",
    "                ehail_fee as eh, \n",
    "                CAST(NULL AS STRING) as aff, \n",
    "                CAST(NULL AS STRING) as disp\n",
    "            FROM `{PROJECT_ID}.{SOURCE_DATASET}.green_staging_unified`\n",
    "            WHERE EXTRACT(YEAR FROM lpep_pickup_datetime) >= 2015\n",
    "\n",
    "            UNION ALL\n",
    "\n",
    "            -- (C) FHV\n",
    "            SELECT \n",
    "                'FHV', \n",
    "                CAST(dispatching_base_num AS STRING) as vid, \n",
    "                CAST(pickup_datetime AS TIMESTAMP), CAST(dropOff_datetime AS TIMESTAMP),\n",
    "                CAST(IFNULL(PULocationID, 263) AS INT64), CAST(IFNULL(DOLocationID, 263) AS INT64),\n",
    "                NULL, NULL, 'N', 99, 2, \n",
    "                CASE \n",
    "                    WHEN CAST(SR_Flag AS STRING) = '1' THEN TRUE \n",
    "                    ELSE FALSE \n",
    "                END as sr_flag,\n",
    "                NULL, NULL, NULL, 0, NULL, NULL, NULL, NULL, NULL, NULL, NULL, Affiliated_base_number, dispatching_base_num\n",
    "            FROM `{PROJECT_ID}.{SOURCE_DATASET}.fhv_staging_unified`\n",
    "            WHERE EXTRACT(YEAR FROM pickup_datetime) >= 2015\n",
    "        )\n",
    "        SELECT \n",
    "            *,\n",
    "            CASE \n",
    "                WHEN t_pick IS NULL OR t_drop IS NULL THEN 'Incorrect: Missing Timestamps'\n",
    "                WHEN t_pick >= t_drop THEN 'Incorrect: Invalid Duration'\n",
    "                WHEN t_pick > CURRENT_TIMESTAMP() THEN 'Incorrect: Future Date'\n",
    "                WHEN src IN ('YELLOW', 'GREEN') AND (tot_amt <= 0 OR f_amt <= 0) THEN 'Incorrect: Financials'\n",
    "                WHEN pax < 1 OR pax > 6 THEN 'Incorrect: Invalid Pax Count (Rule 1.4)'\n",
    "                WHEN dist < 0 OR dist >= 1000 THEN 'Incorrect: Invalid Distance (Rule 1.5)'\n",
    "                ELSE 'VALID'\n",
    "            END as row_status,\n",
    "            CASE WHEN dist > 500 OR (pay = 2 AND t_amt = 0) THEN TRUE ELSE FALSE END as dq_issue_flag\n",
    "        FROM combined_raw\n",
    "        QUALIFY ROW_NUMBER() OVER (\n",
    "                PARTITION BY \n",
    "                    src, \n",
    "                    t_pick, \n",
    "                    t_drop, \n",
    "                    loc_pu, \n",
    "                    loc_do, \n",
    "                    vid \n",
    "                ORDER BY t_pick\n",
    "            ) = 1;\n",
    "\n",
    "        -- 2. INSERT VALID DATA IN CANONICAL (Reihenfolge gem√§√ü Zelle 2)\n",
    "        INSERT INTO `{table_ref}` (\n",
    "            trip_id, source_system, load_date, vendor_id, \n",
    "            Affiliated_base_number, dispatching_base_nummer, \n",
    "            pickup_datetime, dropoff_datetime, pickup_location_id, dropoff_location_id, \n",
    "            passenger_count, trip_distance, store_and_fwd_flag, \n",
    "            RatecodeID, Trip_type, SR_Flag, fare_amount, tip_amount, total_amount, \n",
    "            payment_type, extra, mta_tax, tolls_amount, improvement_surcharge, \n",
    "            congestion_surcharge, Airport_fee, ehail_fee, dq_issue_flag\n",
    "        )\n",
    "        SELECT \n",
    "            CAST(FARM_FINGERPRINT(CONCAT(src, CAST(t_pick AS STRING), IFNULL(vid,''))) AS STRING),\n",
    "            src, CURRENT_TIMESTAMP(), vid, aff, disp, t_pick, t_drop, loc_pu, loc_do, \n",
    "            pax, dist, flag, rate, t_type, sr_flag, f_amt, t_amt, tot_amt, \n",
    "            pay, ex, mt, tl, im, co, ai, eh, dq_issue_flag\n",
    "        FROM temp_trips_processed WHERE row_status = 'VALID';\n",
    "\n",
    "        -- 3. INSERT ERROR DATA (Mit rejection_reason)\n",
    "        INSERT INTO `{error_table_ref}` (\n",
    "            trip_id, source_system, load_date, vendor_id, \n",
    "            Affiliated_base_number, dispatching_base_nummer, \n",
    "            pickup_datetime, dropoff_datetime, pickup_location_id, dropoff_location_id, \n",
    "            passenger_count, trip_distance, store_and_fwd_flag, \n",
    "            RatecodeID, Trip_type, SR_Flag, fare_amount, tip_amount, total_amount, \n",
    "            payment_type, extra, mta_tax, tolls_amount, improvement_surcharge, \n",
    "            congestion_surcharge, Airport_fee, ehail_fee, dq_issue_flag, rejection_reason\n",
    "        )\n",
    "        SELECT \n",
    "            CAST(FARM_FINGERPRINT(CONCAT(src, CAST(t_pick AS STRING), IFNULL(vid,''))) AS STRING),\n",
    "            src, CURRENT_TIMESTAMP(), vid, aff, disp, t_pick, t_drop, loc_pu, loc_do, \n",
    "            pax, dist, flag, rate, t_type, sr_flag, f_amt, t_amt, tot_amt, \n",
    "            pay, ex, mt, tl, im, co, ai, eh, TRUE, row_status\n",
    "        FROM temp_trips_processed WHERE row_status != 'VALID';\n",
    "    END;\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        client.query(query).result()\n",
    "        print(\"‚úÖ ETL Job erfolgreich abgeschlossen.\")\n",
    "        print(\"   - Syntax-Fehler (Semikolon) behoben.\")\n",
    "        print(\"   - Spalten-Alignment f√ºr INSERT sichergestellt.\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Fehler: {e}\")\n",
    "\n",
    "run_etl_split_logic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "4a7e58dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- CLEAN DATA SAMPLE ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lania/Documents/GitHub/bi_project_task2/.venv/lib/python3.12/site-packages/google/cloud/bigquery/table.py:1994: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           0\n",
      "monat                      6\n",
      "anzahl               2812445\n",
      "erfolgreich_gemappt  2693809\n",
      "unbekannte_zone       118636\n",
      "\n",
      "--- ERROR DATA SAMPLE  ---\n",
      "                          rejection_reason        cnt\n",
      "0                    Incorrect: Financials     588188\n",
      "1   Incorrect: Invalid Distance (Rule 1.5)       9646\n",
      "2  Incorrect: Invalid Pax Count (Rule 1.4)     879413\n",
      "3                   Incorrect: Future Date          8\n",
      "4              Incorrect: Invalid Duration  201180289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lania/Documents/GitHub/bi_project_task2/.venv/lib/python3.12/site-packages/google/cloud/bigquery/table.py:1994: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Zelle 4: Quality Check\n",
    "print(\"--- CLEAN DATA SAMPLE ---\")\n",
    "print(client.query(f\"SELECT EXTRACT(MONTH FROM pickup_datetime) as monat, COUNT(*) as anzahl, COUNTIF(pickup_location_id IS NOT NULL AND pickup_location_id != 263) as erfolgreich_gemappt, COUNTIF(pickup_location_id = 263) as unbekannte_zone FROM `{table_ref}` WHERE EXTRACT(YEAR FROM pickup_datetime) = 2010 GROUP BY 1;\").to_dataframe().T)\n",
    "\n",
    "print(\"\\n--- ERROR DATA SAMPLE  ---\")\n",
    "try:\n",
    "    err_df = client.query(f\"SELECT rejection_reason, count(*) as cnt FROM `{error_table_ref}` GROUP BY 1\").to_dataframe()\n",
    "    print(err_df)\n",
    "except:\n",
    "    print(\"Keine Fehler gefunden (Tabelle leer).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "62bacbb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Starte Daten-Audit (Staging vs. Canonical vs. Error)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lania/Documents/GitHub/bi_project_task2/.venv/lib/python3.12/site-packages/google/cloud/bigquery/table.py:1994: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 1. ROHDATEN IN STAGING (gefiltert) ---\n",
      "      src     anzahl\n",
      "0     FHV  783688849\n",
      "1   GREEN   68044817\n",
      "2  YELLOW  178437711\n",
      "Gesamt Rohdaten: 1,030,171,377\n",
      "\n",
      "--- 2. VERTEILUNG IM CANONICAL LAYER ---\n",
      "      src    cat     anzahl\n",
      "0  YELLOW  ERROR    2131071\n",
      "1   GREEN  ERROR     414561\n",
      "2   GREEN  VALID   67447832\n",
      "3     FHV  VALID  514630379\n",
      "4     FHV  ERROR  240175710\n",
      "5  YELLOW  VALID  172066569\n",
      "Gesamt (Valid + Error): 996,866,122\n",
      "\n",
      "--- ANALYSE ---\n",
      "Differenz: 33,305,255 Zeilen\n",
      "‚ÑπÔ∏è Hinweis: Diese 33,305,255 Zeilen wurden als DUPLIKATE entfernt (Qualify-Regel).\n"
     ]
    }
   ],
   "source": [
    "def run_data_audit():\n",
    "    print(\"üìä Starte Daten-Audit (Staging vs. Canonical vs. Error)...\")\n",
    "    \n",
    "    # Query f√ºr die Rohdaten (Staging) mit deinen Filtern\n",
    "    query_staging = f\"\"\"\n",
    "    SELECT 'YELLOW' as src, COUNT(*) as anzahl FROM `{PROJECT_ID}.{SOURCE_DATASET}.yellow_staging_unified` \n",
    "    WHERE (EXTRACT(YEAR FROM tpep_pickup_datetime) = 2023) OR (EXTRACT(MONTH FROM tpep_pickup_datetime) = 6)\n",
    "    UNION ALL\n",
    "    SELECT 'GREEN', COUNT(*) FROM `{PROJECT_ID}.{SOURCE_DATASET}.green_staging_unified` WHERE EXTRACT(YEAR FROM lpep_pickup_datetime) >= 2015\n",
    "    UNION ALL\n",
    "    SELECT 'FHV', COUNT(*) FROM `{PROJECT_ID}.{SOURCE_DATASET}.fhv_staging_unified` WHERE EXTRACT(YEAR FROM pickup_datetime) >= 2015\n",
    "    \"\"\"\n",
    "\n",
    "    # Query f√ºr das Ziel (Canonical + Error)\n",
    "    query_target = f\"\"\"\n",
    "    SELECT source_system as src, 'VALID' as cat, COUNT(*) as anzahl FROM `{table_ref}` GROUP BY 1\n",
    "    UNION ALL\n",
    "    SELECT source_system, 'ERROR', COUNT(*) FROM `{error_table_ref}` GROUP BY 1\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        df_staging = client.query(query_staging).to_dataframe()\n",
    "        df_target = client.query(query_target).to_dataframe()\n",
    "\n",
    "        print(\"\\n--- 1. ROHDATEN IN STAGING (gefiltert) ---\")\n",
    "        print(df_staging)\n",
    "        total_raw = df_staging['anzahl'].sum()\n",
    "        print(f\"Gesamt Rohdaten: {total_raw:,}\")\n",
    "\n",
    "        print(\"\\n--- 2. VERTEILUNG IM CANONICAL LAYER ---\")\n",
    "        print(df_target)\n",
    "        total_target = df_target['anzahl'].sum()\n",
    "        print(f\"Gesamt (Valid + Error): {total_target:,}\")\n",
    "\n",
    "        diff = total_raw - total_target\n",
    "        print(\"\\n--- ANALYSE ---\")\n",
    "        print(f\"Differenz: {diff:,} Zeilen\")\n",
    "        if diff > 0:\n",
    "            print(f\"‚ÑπÔ∏è Hinweis: Diese {diff:,} Zeilen wurden als DUPLIKATE entfernt (Qualify-Regel).\")\n",
    "        elif diff == 0:\n",
    "            print(\"‚úÖ Perfekt: Jede Zeile wurde entweder als VALID oder ERROR verarbeitet.\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Fehler beim Audit: {e}\")\n",
    "\n",
    "run_data_audit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "91c6736d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Analysiere Ratecode und Payment Type Mapping f√ºr 2010...\n",
      "\n",
      "--- 1. Verteilung RatecodeID (Ziel: 1=Standard, 2=JFK, etc.) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lania/Documents/GitHub/bi_project_task2/.venv/lib/python3.12/site-packages/google/cloud/bigquery/table.py:1994: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   RatecodeID   anzahl     Bezeichnung\n",
      "0           1  5473049        Standard\n",
      "1           2    96217             JFK\n",
      "2           0    21649             NaN\n",
      "3           4    13517  Nassau/Westch.\n",
      "4           5    10195            Neg.\n",
      "5           3     8548          Newark\n",
      "6           6      139           Group\n",
      "7         210       10             NaN\n",
      "8          65        2             NaN\n",
      "9           7        1             NaN\n",
      "\n",
      "--- 2. Verteilung Payment Type (Ziel: 1=Card, 2=Cash, etc.) ---\n",
      "   payment_type   anzahl Bezeichnung\n",
      "0             2  3613908        Cash\n",
      "1             1  1982293        Card\n",
      "2             5    27126     Unknown\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lania/Documents/GitHub/bi_project_task2/.venv/lib/python3.12/site-packages/google/cloud/bigquery/table.py:1994: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Zelle 5: Mapping-Check f√ºr Ratecode und Payment Type (Fokus 2010)\n",
    "def check_rate_and_payment():\n",
    "    print(\"üîç Analysiere Ratecode und Payment Type Mapping f√ºr 2010...\")\n",
    "\n",
    "    # Query f√ºr Ratecode Verteilung\n",
    "    query_ratecode = f\"\"\"\n",
    "    SELECT \n",
    "        RatecodeID, \n",
    "        COUNT(*) as anzahl\n",
    "    FROM `{table_ref}`\n",
    "    WHERE EXTRACT(YEAR FROM pickup_datetime) = 2010\n",
    "    GROUP BY 1\n",
    "    ORDER BY anzahl DESC\n",
    "    \"\"\"\n",
    "\n",
    "    # Query f√ºr Payment Type Verteilung\n",
    "    query_payment = f\"\"\"\n",
    "    SELECT \n",
    "        payment_type, \n",
    "        COUNT(*) as anzahl\n",
    "    FROM `{table_ref}`\n",
    "    WHERE EXTRACT(YEAR FROM pickup_datetime) = 2010\n",
    "    GROUP BY 1\n",
    "    ORDER BY anzahl DESC\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        print(\"\\n--- 1. Verteilung RatecodeID (Ziel: 1=Standard, 2=JFK, etc.) ---\")\n",
    "        df_rate = client.query(query_ratecode).to_dataframe()\n",
    "        # Mapping Label f√ºr die Anzeige\n",
    "        rate_map = {1: \"Standard\", 2: \"JFK\", 3: \"Newark\", 4: \"Nassau/Westch.\", 5: \"Neg.\", 6: \"Group\", 99: \"Unknown\"}\n",
    "        df_rate['Bezeichnung'] = df_rate['RatecodeID'].map(rate_map)\n",
    "        print(df_rate)\n",
    "\n",
    "        print(\"\\n--- 2. Verteilung Payment Type (Ziel: 1=Card, 2=Cash, etc.) ---\")\n",
    "        df_pay = client.query(query_payment).to_dataframe()\n",
    "        # Mapping Label f√ºr die Anzeige\n",
    "        pay_map = {1: \"Card\", 2: \"Cash\", 3: \"No Charge\", 4: \"Dispute\", 5: \"Unknown\", 6: \"Void\"}\n",
    "        df_pay['Bezeichnung'] = df_pay['payment_type'].map(pay_map)\n",
    "        print(df_pay)\n",
    "\n",
    "        # Erfolgskontrolle\n",
    "        if not df_rate.empty and all(isinstance(x, (int, float)) for x in df_rate['RatecodeID'].dropna()):\n",
    "            print(\"\\n‚úÖ SUCCESS: RatecodeID wurde erfolgreich in numerische Werte transformiert.\")\n",
    "        if not df_pay.empty and all(isinstance(x, (int, float)) for x in df_pay['payment_type'].dropna()):\n",
    "            print(\"‚úÖ SUCCESS: payment_type wurde erfolgreich in numerische Werte transformiert.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Fehler bei der Analyse: {e}\")\n",
    "\n",
    "check_rate_and_payment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b7894d6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Analyse der Payment Types (Rohdaten) ---\n",
      "               jahr raw_value    anzahl\n",
      "0   2010 (Schema 5)       Cre   5168999\n",
      "1   2010 (Schema 5)       CAS   5164878\n",
      "2   2010 (Schema 5)       Cas   4227711\n",
      "3   2010 (Schema 5)       CRE    225832\n",
      "4   2010 (Schema 5)       No      31091\n",
      "5   2010 (Schema 5)       Dis      6617\n",
      "6     2023 (Modern)         1  32449126\n",
      "7     2023 (Modern)         2   6957625\n",
      "8     2023 (Modern)         0   1409243\n",
      "9     2023 (Modern)         4    539200\n",
      "10    2023 (Modern)         3    262154\n",
      "11    2023 (Modern)         5         3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lania/Documents/GitHub/bi_project_task2/.venv/lib/python3.12/site-packages/google/cloud/bigquery/table.py:1994: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import bigquery\n",
    "\n",
    "client = bigquery.Client()\n",
    "\n",
    "# Wir pr√ºfen die Payment Types in den alten 2010er Daten und den neuen 2023er Daten\n",
    "query = \"\"\"\n",
    "SELECT \n",
    "    '2010 (Schema 5)' as jahr,\n",
    "    CAST(payment_type AS STRING) as raw_value, \n",
    "    COUNT(*) as anzahl\n",
    "FROM `taxi-bi-project.staging.yellow_schema_5`\n",
    "GROUP BY 1, 2\n",
    "\n",
    "UNION ALL\n",
    "\n",
    "SELECT \n",
    "    '2023 (Modern)' as jahr,\n",
    "    CAST(payment_type AS STRING) as raw_value, \n",
    "    COUNT(*) as anzahl\n",
    "FROM `taxi-bi-project.staging.yellow_staging_unified`\n",
    "WHERE EXTRACT(YEAR FROM tpep_pickup_datetime) = 2023\n",
    "GROUP BY 1, 2\n",
    "ORDER BY jahr, anzahl DESC\n",
    "\"\"\"\n",
    "\n",
    "df_payments = client.query(query).to_dataframe()\n",
    "print(\"--- Analyse der Payment Types (Rohdaten) ---\")\n",
    "print(df_payments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "6b888d92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            raw_string  anzahl\n",
      "0  2010-06-21 10:46:30       2\n",
      "1  2010-06-11 03:03:14       1\n",
      "2  2010-06-19 18:07:47       4\n",
      "3  2010-06-30 06:30:51       3\n",
      "4  2010-06-28 00:04:25       2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lania/Documents/GitHub/bi_project_task2/.venv/lib/python3.12/site-packages/google/cloud/bigquery/table.py:1994: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "query_date_check = \"\"\"\n",
    "SELECT \n",
    "    pickup_datetime as raw_string,\n",
    "    COUNT(*) as anzahl\n",
    "FROM `taxi-bi-project.staging.yellow_schema_5`\n",
    "GROUP BY 1\n",
    "LIMIT 5\n",
    "\"\"\"\n",
    "print(client.query(query_date_check).to_dataframe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "e12538c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- üîç DATA INSPECTION (Tabelle: taxi-bi-project.canonical.canonical_unified_taxi) ---\n",
      "\n",
      "üöï YELLOW TAXI SAMPLE (Sollte Finanzen & Ratecode haben):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lania/Documents/GitHub/bi_project_task2/.venv/lib/python3.12/site-packages/google/cloud/bigquery/table.py:1994: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trip_id</th>\n",
       "      <th>source_system</th>\n",
       "      <th>load_date</th>\n",
       "      <th>vendor_id</th>\n",
       "      <th>Affiliated_base_number</th>\n",
       "      <th>dispatching_base_nummer</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dropoff_datetime</th>\n",
       "      <th>pickup_location_id</th>\n",
       "      <th>dropoff_location_id</th>\n",
       "      <th>...</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "      <th>Airport_fee</th>\n",
       "      <th>ehail_fee</th>\n",
       "      <th>dq_issue_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1531786308848340242</td>\n",
       "      <td>YELLOW</td>\n",
       "      <td>2026-01-08 12:42:12.836802+00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2010-06-18 16:07:19+00:00</td>\n",
       "      <td>2010-06-18 16:07:48+00:00</td>\n",
       "      <td>229</td>\n",
       "      <td>229</td>\n",
       "      <td>...</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3607530224108402529</td>\n",
       "      <td>YELLOW</td>\n",
       "      <td>2026-01-08 12:42:12.836802+00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2010-06-06 08:36:37+00:00</td>\n",
       "      <td>2010-06-06 08:41:16+00:00</td>\n",
       "      <td>129</td>\n",
       "      <td>129</td>\n",
       "      <td>...</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1695272938504091367</td>\n",
       "      <td>YELLOW</td>\n",
       "      <td>2026-01-08 12:42:12.836802+00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2010-06-08 15:24:19+00:00</td>\n",
       "      <td>2010-06-08 16:44:03+00:00</td>\n",
       "      <td>263</td>\n",
       "      <td>263</td>\n",
       "      <td>...</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-4841951142003044862</td>\n",
       "      <td>YELLOW</td>\n",
       "      <td>2026-01-08 12:42:12.836802+00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2010-06-19 07:51:49+00:00</td>\n",
       "      <td>2010-06-19 08:03:45+00:00</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7494652164461089866</td>\n",
       "      <td>YELLOW</td>\n",
       "      <td>2026-01-08 12:42:12.836802+00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2010-06-20 09:32:19+00:00</td>\n",
       "      <td>2010-06-20 09:33:19+00:00</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>...</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2238987991992236317</td>\n",
       "      <td>YELLOW</td>\n",
       "      <td>2026-01-08 12:42:12.836802+00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2010-06-22 14:28:31+00:00</td>\n",
       "      <td>2010-06-22 14:29:11+00:00</td>\n",
       "      <td>88</td>\n",
       "      <td>87</td>\n",
       "      <td>...</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4170712180169412968</td>\n",
       "      <td>YELLOW</td>\n",
       "      <td>2026-01-08 12:42:12.836802+00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2010-06-08 09:50:24+00:00</td>\n",
       "      <td>2010-06-08 09:50:39+00:00</td>\n",
       "      <td>138</td>\n",
       "      <td>138</td>\n",
       "      <td>...</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4557762523158386914</td>\n",
       "      <td>YELLOW</td>\n",
       "      <td>2026-01-08 12:42:12.836802+00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2010-06-19 11:48:56+00:00</td>\n",
       "      <td>2010-06-19 11:49:48+00:00</td>\n",
       "      <td>186</td>\n",
       "      <td>186</td>\n",
       "      <td>...</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6618239509873616713</td>\n",
       "      <td>YELLOW</td>\n",
       "      <td>2026-01-08 12:42:12.836802+00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2010-06-23 11:30:28+00:00</td>\n",
       "      <td>2010-06-23 14:41:29+00:00</td>\n",
       "      <td>28</td>\n",
       "      <td>216</td>\n",
       "      <td>...</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>352918484745089667</td>\n",
       "      <td>YELLOW</td>\n",
       "      <td>2026-01-08 12:42:12.836802+00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2010-06-20 11:21:42+00:00</td>\n",
       "      <td>2010-06-20 11:23:16+00:00</td>\n",
       "      <td>237</td>\n",
       "      <td>237</td>\n",
       "      <td>...</td>\n",
       "      <td>2.9</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>6984992494914918662</td>\n",
       "      <td>YELLOW</td>\n",
       "      <td>2026-01-08 12:42:12.836802+00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2010-06-28 08:54:07+00:00</td>\n",
       "      <td>2010-06-28 08:55:08+00:00</td>\n",
       "      <td>230</td>\n",
       "      <td>230</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-4196097714372926486</td>\n",
       "      <td>YELLOW</td>\n",
       "      <td>2026-01-08 12:42:12.836802+00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2010-06-28 05:46:00+00:00</td>\n",
       "      <td>2010-06-28 05:51:20+00:00</td>\n",
       "      <td>233</td>\n",
       "      <td>230</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-2228744813550791337</td>\n",
       "      <td>YELLOW</td>\n",
       "      <td>2026-01-08 12:42:12.836802+00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2010-06-09 11:40:57+00:00</td>\n",
       "      <td>2010-06-09 11:41:22+00:00</td>\n",
       "      <td>263</td>\n",
       "      <td>263</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>926322911132159955</td>\n",
       "      <td>YELLOW</td>\n",
       "      <td>2026-01-08 12:42:12.836802+00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2010-06-30 12:04:26+00:00</td>\n",
       "      <td>2010-06-30 12:04:51+00:00</td>\n",
       "      <td>132</td>\n",
       "      <td>132</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-1914896560317943910</td>\n",
       "      <td>YELLOW</td>\n",
       "      <td>2026-01-08 12:42:12.836802+00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2010-06-21 13:58:42+00:00</td>\n",
       "      <td>2010-06-21 14:21:50+00:00</td>\n",
       "      <td>132</td>\n",
       "      <td>138</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15 rows √ó 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 trip_id source_system                        load_date  \\\n",
       "0    1531786308848340242        YELLOW 2026-01-08 12:42:12.836802+00:00   \n",
       "1    3607530224108402529        YELLOW 2026-01-08 12:42:12.836802+00:00   \n",
       "2    1695272938504091367        YELLOW 2026-01-08 12:42:12.836802+00:00   \n",
       "3   -4841951142003044862        YELLOW 2026-01-08 12:42:12.836802+00:00   \n",
       "4    7494652164461089866        YELLOW 2026-01-08 12:42:12.836802+00:00   \n",
       "5    2238987991992236317        YELLOW 2026-01-08 12:42:12.836802+00:00   \n",
       "6    4170712180169412968        YELLOW 2026-01-08 12:42:12.836802+00:00   \n",
       "7    4557762523158386914        YELLOW 2026-01-08 12:42:12.836802+00:00   \n",
       "8    6618239509873616713        YELLOW 2026-01-08 12:42:12.836802+00:00   \n",
       "9     352918484745089667        YELLOW 2026-01-08 12:42:12.836802+00:00   \n",
       "10   6984992494914918662        YELLOW 2026-01-08 12:42:12.836802+00:00   \n",
       "11  -4196097714372926486        YELLOW 2026-01-08 12:42:12.836802+00:00   \n",
       "12  -2228744813550791337        YELLOW 2026-01-08 12:42:12.836802+00:00   \n",
       "13    926322911132159955        YELLOW 2026-01-08 12:42:12.836802+00:00   \n",
       "14  -1914896560317943910        YELLOW 2026-01-08 12:42:12.836802+00:00   \n",
       "\n",
       "   vendor_id Affiliated_base_number dispatching_base_nummer  \\\n",
       "0          3                   None                    None   \n",
       "1          3                   None                    None   \n",
       "2          3                   None                    None   \n",
       "3          3                   None                    None   \n",
       "4          3                   None                    None   \n",
       "5          3                   None                    None   \n",
       "6          3                   None                    None   \n",
       "7          3                   None                    None   \n",
       "8          3                   None                    None   \n",
       "9          3                   None                    None   \n",
       "10         3                   None                    None   \n",
       "11         3                   None                    None   \n",
       "12         3                   None                    None   \n",
       "13         3                   None                    None   \n",
       "14         3                   None                    None   \n",
       "\n",
       "             pickup_datetime          dropoff_datetime  pickup_location_id  \\\n",
       "0  2010-06-18 16:07:19+00:00 2010-06-18 16:07:48+00:00                 229   \n",
       "1  2010-06-06 08:36:37+00:00 2010-06-06 08:41:16+00:00                 129   \n",
       "2  2010-06-08 15:24:19+00:00 2010-06-08 16:44:03+00:00                 263   \n",
       "3  2010-06-19 07:51:49+00:00 2010-06-19 08:03:45+00:00                  50   \n",
       "4  2010-06-20 09:32:19+00:00 2010-06-20 09:33:19+00:00                  39   \n",
       "5  2010-06-22 14:28:31+00:00 2010-06-22 14:29:11+00:00                  88   \n",
       "6  2010-06-08 09:50:24+00:00 2010-06-08 09:50:39+00:00                 138   \n",
       "7  2010-06-19 11:48:56+00:00 2010-06-19 11:49:48+00:00                 186   \n",
       "8  2010-06-23 11:30:28+00:00 2010-06-23 14:41:29+00:00                  28   \n",
       "9  2010-06-20 11:21:42+00:00 2010-06-20 11:23:16+00:00                 237   \n",
       "10 2010-06-28 08:54:07+00:00 2010-06-28 08:55:08+00:00                 230   \n",
       "11 2010-06-28 05:46:00+00:00 2010-06-28 05:51:20+00:00                 233   \n",
       "12 2010-06-09 11:40:57+00:00 2010-06-09 11:41:22+00:00                 263   \n",
       "13 2010-06-30 12:04:26+00:00 2010-06-30 12:04:51+00:00                 132   \n",
       "14 2010-06-21 13:58:42+00:00 2010-06-21 14:21:50+00:00                 132   \n",
       "\n",
       "    dropoff_location_id  ...  total_amount  payment_type extra  mta_tax  \\\n",
       "0                   229  ...           2.5             2   0.0      0.0   \n",
       "1                   129  ...           2.5             2   0.0      0.0   \n",
       "2                   263  ...           2.5             2   0.0      0.0   \n",
       "3                    50  ...           2.5             2   0.0      0.0   \n",
       "4                    39  ...           2.5             2   0.0      0.0   \n",
       "5                    87  ...           2.5             2   0.0      0.0   \n",
       "6                   138  ...           2.5             2   0.0      0.0   \n",
       "7                   186  ...           2.5             2   0.0      0.0   \n",
       "8                   216  ...           2.5             2   0.0      0.0   \n",
       "9                   237  ...           2.9             2   0.0      0.0   \n",
       "10                  230  ...           3.0             2   0.0      0.5   \n",
       "11                  230  ...           3.0             2   0.0      0.5   \n",
       "12                  263  ...           3.0             2   0.0      0.5   \n",
       "13                  132  ...           3.0             2   0.0      0.5   \n",
       "14                  138  ...           3.0             2   0.0      0.5   \n",
       "\n",
       "    tolls_amount  improvement_surcharge  congestion_surcharge  Airport_fee  \\\n",
       "0            0.0                    0.0                   0.0          0.0   \n",
       "1            0.0                    0.0                   0.0          0.0   \n",
       "2            0.0                    0.0                   0.0          0.0   \n",
       "3            0.0                    0.0                   0.0          0.0   \n",
       "4            0.0                    0.0                   0.0          0.0   \n",
       "5            0.0                    0.0                   0.0          0.0   \n",
       "6            0.0                    0.0                   0.0          0.0   \n",
       "7            0.0                    0.0                   0.0          0.0   \n",
       "8            0.0                    0.0                   0.0          0.0   \n",
       "9            0.0                    0.0                   0.0          0.0   \n",
       "10           0.0                    0.0                   0.0          0.0   \n",
       "11           0.0                    0.0                   0.0          0.0   \n",
       "12           0.0                    0.0                   0.0          0.0   \n",
       "13           0.0                    0.0                   0.0          0.0   \n",
       "14           0.0                    0.0                   0.0          0.0   \n",
       "\n",
       "    ehail_fee  dq_issue_flag  \n",
       "0         NaN           True  \n",
       "1         NaN           True  \n",
       "2         NaN           True  \n",
       "3         NaN           True  \n",
       "4         NaN           True  \n",
       "5         NaN           True  \n",
       "6         NaN           True  \n",
       "7         NaN           True  \n",
       "8         NaN           True  \n",
       "9         NaN           True  \n",
       "10        NaN           True  \n",
       "11        NaN           True  \n",
       "12        NaN           True  \n",
       "13        NaN           True  \n",
       "14        NaN           True  \n",
       "\n",
       "[15 rows x 28 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üíö GREEN TAXI SAMPLE (Sollte Trip_type & ehail_fee haben):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lania/Documents/GitHub/bi_project_task2/.venv/lib/python3.12/site-packages/google/cloud/bigquery/table.py:1994: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trip_id</th>\n",
       "      <th>source_system</th>\n",
       "      <th>load_date</th>\n",
       "      <th>vendor_id</th>\n",
       "      <th>Affiliated_base_number</th>\n",
       "      <th>dispatching_base_nummer</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dropoff_datetime</th>\n",
       "      <th>pickup_location_id</th>\n",
       "      <th>dropoff_location_id</th>\n",
       "      <th>...</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "      <th>Airport_fee</th>\n",
       "      <th>ehail_fee</th>\n",
       "      <th>dq_issue_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8934663925888110030</td>\n",
       "      <td>GREEN</td>\n",
       "      <td>2026-01-08 12:42:12.836802+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2017-09-24 00:32:37+00:00</td>\n",
       "      <td>2017-09-24 00:33:12+00:00</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4458259119911185826</td>\n",
       "      <td>GREEN</td>\n",
       "      <td>2026-01-08 12:42:12.836802+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2017-09-23 05:47:17+00:00</td>\n",
       "      <td>2017-09-23 05:48:01+00:00</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2082099856174231571</td>\n",
       "      <td>GREEN</td>\n",
       "      <td>2026-01-08 12:42:12.836802+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2017-09-21 01:28:05+00:00</td>\n",
       "      <td>2017-09-21 01:28:31+00:00</td>\n",
       "      <td>235</td>\n",
       "      <td>235</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6159180755314097705</td>\n",
       "      <td>GREEN</td>\n",
       "      <td>2026-01-08 12:42:12.836802+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2017-09-13 05:19:08+00:00</td>\n",
       "      <td>2017-09-13 05:22:16+00:00</td>\n",
       "      <td>243</td>\n",
       "      <td>243</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-2078796549061550083</td>\n",
       "      <td>GREEN</td>\n",
       "      <td>2026-01-08 12:42:12.836802+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2017-09-20 11:18:38+00:00</td>\n",
       "      <td>2017-09-20 11:19:23+00:00</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>...</td>\n",
       "      <td>0.31</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                trip_id source_system                        load_date  \\\n",
       "0   8934663925888110030         GREEN 2026-01-08 12:42:12.836802+00:00   \n",
       "1   4458259119911185826         GREEN 2026-01-08 12:42:12.836802+00:00   \n",
       "2   2082099856174231571         GREEN 2026-01-08 12:42:12.836802+00:00   \n",
       "3   6159180755314097705         GREEN 2026-01-08 12:42:12.836802+00:00   \n",
       "4  -2078796549061550083         GREEN 2026-01-08 12:42:12.836802+00:00   \n",
       "\n",
       "  vendor_id Affiliated_base_number dispatching_base_nummer  \\\n",
       "0         1                   None                    None   \n",
       "1         1                   None                    None   \n",
       "2         1                   None                    None   \n",
       "3         1                   None                    None   \n",
       "4         1                   None                    None   \n",
       "\n",
       "            pickup_datetime          dropoff_datetime  pickup_location_id  \\\n",
       "0 2017-09-24 00:32:37+00:00 2017-09-24 00:33:12+00:00                 255   \n",
       "1 2017-09-23 05:47:17+00:00 2017-09-23 05:48:01+00:00                 255   \n",
       "2 2017-09-21 01:28:05+00:00 2017-09-21 01:28:31+00:00                 235   \n",
       "3 2017-09-13 05:19:08+00:00 2017-09-13 05:22:16+00:00                 243   \n",
       "4 2017-09-20 11:18:38+00:00 2017-09-20 11:19:23+00:00                  36   \n",
       "\n",
       "   dropoff_location_id  ...  total_amount  payment_type extra  mta_tax  \\\n",
       "0                  255  ...          0.01             2   0.0      0.0   \n",
       "1                  255  ...          0.01             3   0.0      0.0   \n",
       "2                  235  ...          0.01             2   0.0      0.0   \n",
       "3                  243  ...          0.01             2   0.0      0.0   \n",
       "4                   36  ...          0.31             3   0.0      0.0   \n",
       "\n",
       "   tolls_amount  improvement_surcharge  congestion_surcharge  Airport_fee  \\\n",
       "0           0.0                    0.0                   NaN          0.0   \n",
       "1           0.0                    0.0                   NaN          0.0   \n",
       "2           0.0                    0.0                   NaN          0.0   \n",
       "3           0.0                    0.0                   NaN          0.0   \n",
       "4           0.0                    0.3                   NaN          0.0   \n",
       "\n",
       "   ehail_fee  dq_issue_flag  \n",
       "0        NaN           True  \n",
       "1        NaN          False  \n",
       "2        NaN           True  \n",
       "3        NaN           True  \n",
       "4        NaN          False  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üñ§ FHV SAMPLE (Muss Base-Nummern haben, aber KEINE Preise):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lania/Documents/GitHub/bi_project_task2/.venv/lib/python3.12/site-packages/google/cloud/bigquery/table.py:1994: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trip_id</th>\n",
       "      <th>source_system</th>\n",
       "      <th>load_date</th>\n",
       "      <th>vendor_id</th>\n",
       "      <th>Affiliated_base_number</th>\n",
       "      <th>dispatching_base_nummer</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dropoff_datetime</th>\n",
       "      <th>pickup_location_id</th>\n",
       "      <th>dropoff_location_id</th>\n",
       "      <th>...</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "      <th>Airport_fee</th>\n",
       "      <th>ehail_fee</th>\n",
       "      <th>dq_issue_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-6389995901186689913</td>\n",
       "      <td>FHV</td>\n",
       "      <td>2026-01-08 12:42:12.836802+00:00</td>\n",
       "      <td>B02127</td>\n",
       "      <td>B02127</td>\n",
       "      <td>B02127</td>\n",
       "      <td>2015-09-05 18:30:00+00:00</td>\n",
       "      <td>2018-09-05 19:30:00+00:00</td>\n",
       "      <td>263</td>\n",
       "      <td>263</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8505448901266430594</td>\n",
       "      <td>FHV</td>\n",
       "      <td>2026-01-08 12:42:12.836802+00:00</td>\n",
       "      <td>B02653</td>\n",
       "      <td>B02653</td>\n",
       "      <td>B02653</td>\n",
       "      <td>2021-10-29 05:00:12+00:00</td>\n",
       "      <td>2021-10-29 05:39:17+00:00</td>\n",
       "      <td>263</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-5090010053490920428</td>\n",
       "      <td>FHV</td>\n",
       "      <td>2026-01-08 12:42:12.836802+00:00</td>\n",
       "      <td>B02657</td>\n",
       "      <td>B02657</td>\n",
       "      <td>B02657</td>\n",
       "      <td>2021-10-04 12:51:44+00:00</td>\n",
       "      <td>2021-10-04 12:51:48+00:00</td>\n",
       "      <td>263</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2532296753196713593</td>\n",
       "      <td>FHV</td>\n",
       "      <td>2026-01-08 12:42:12.836802+00:00</td>\n",
       "      <td>B02661</td>\n",
       "      <td>B02661</td>\n",
       "      <td>B02661</td>\n",
       "      <td>2021-10-25 05:30:00+00:00</td>\n",
       "      <td>2021-10-25 06:13:00+00:00</td>\n",
       "      <td>84</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6238535805041828204</td>\n",
       "      <td>FHV</td>\n",
       "      <td>2026-01-08 12:42:12.836802+00:00</td>\n",
       "      <td>B02661</td>\n",
       "      <td>B02661</td>\n",
       "      <td>B02661</td>\n",
       "      <td>2021-10-23 05:30:00+00:00</td>\n",
       "      <td>2021-10-23 06:07:00+00:00</td>\n",
       "      <td>206</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                trip_id source_system                        load_date  \\\n",
       "0  -6389995901186689913           FHV 2026-01-08 12:42:12.836802+00:00   \n",
       "1   8505448901266430594           FHV 2026-01-08 12:42:12.836802+00:00   \n",
       "2  -5090010053490920428           FHV 2026-01-08 12:42:12.836802+00:00   \n",
       "3   2532296753196713593           FHV 2026-01-08 12:42:12.836802+00:00   \n",
       "4   6238535805041828204           FHV 2026-01-08 12:42:12.836802+00:00   \n",
       "\n",
       "  vendor_id Affiliated_base_number dispatching_base_nummer  \\\n",
       "0    B02127                 B02127                  B02127   \n",
       "1    B02653                 B02653                  B02653   \n",
       "2    B02657                 B02657                  B02657   \n",
       "3    B02661                 B02661                  B02661   \n",
       "4    B02661                 B02661                  B02661   \n",
       "\n",
       "            pickup_datetime          dropoff_datetime  pickup_location_id  \\\n",
       "0 2015-09-05 18:30:00+00:00 2018-09-05 19:30:00+00:00                 263   \n",
       "1 2021-10-29 05:00:12+00:00 2021-10-29 05:39:17+00:00                 263   \n",
       "2 2021-10-04 12:51:44+00:00 2021-10-04 12:51:48+00:00                 263   \n",
       "3 2021-10-25 05:30:00+00:00 2021-10-25 06:13:00+00:00                  84   \n",
       "4 2021-10-23 05:30:00+00:00 2021-10-23 06:07:00+00:00                 206   \n",
       "\n",
       "   dropoff_location_id  ...  total_amount  payment_type extra  mta_tax  \\\n",
       "0                  263  ...           NaN             0   NaN      NaN   \n",
       "1                    1  ...           NaN             0   NaN      NaN   \n",
       "2                    1  ...           NaN             0   NaN      NaN   \n",
       "3                    1  ...           NaN             0   NaN      NaN   \n",
       "4                    1  ...           NaN             0   NaN      NaN   \n",
       "\n",
       "   tolls_amount  improvement_surcharge  congestion_surcharge  Airport_fee  \\\n",
       "0           NaN                    NaN                   NaN          NaN   \n",
       "1           NaN                    NaN                   NaN          NaN   \n",
       "2           NaN                    NaN                   NaN          NaN   \n",
       "3           NaN                    NaN                   NaN          NaN   \n",
       "4           NaN                    NaN                   NaN          NaN   \n",
       "\n",
       "   ehail_fee  dq_issue_flag  \n",
       "0        NaN          False  \n",
       "1        NaN          False  \n",
       "2        NaN          False  \n",
       "3        NaN          False  \n",
       "4        NaN          False  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä VERTEILUNG NACH SYSTEM:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lania/Documents/GitHub/bi_project_task2/.venv/lib/python3.12/site-packages/google/cloud/bigquery/table.py:1994: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  source_system      count\n",
      "0        YELLOW  172066569\n",
      "1           FHV  514630379\n",
      "2         GREEN   67447832\n"
     ]
    }
   ],
   "source": [
    "# Zelle 5: Data Quality Check (Stichproben pro System)\n",
    "import pandas as pd\n",
    "\n",
    "def check_data_samples():\n",
    "    print(f\"--- üîç DATA INSPECTION (Tabelle: {table_ref}) ---\\n\")\n",
    "    \n",
    "    # 1. YELLOW CHECK (\"Cellos\")\n",
    "    # Fokus: Haben sie Ratecode? Sind Finanzen da?\n",
    "    print(\"üöï YELLOW TAXI SAMPLE (Sollte Finanzen & Ratecode haben):\")\n",
    "    sql_yellow = f\"\"\"\n",
    "    SELECT \n",
    "        *\n",
    "    FROM `{table_ref}`\n",
    "    WHERE source_system = 'YELLOW'\n",
    "    LIMIT 15\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df_y = client.query(sql_yellow).to_dataframe()\n",
    "        display(df_y) # Oder print(df_y) falls kein Jupyter\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "    # 2. GREEN CHECK\n",
    "    # Fokus: Haben sie Trip_type und Ehail_fee? (Spezifisch f√ºr Green)\n",
    "    print(\"\\nüíö GREEN TAXI SAMPLE (Sollte Trip_type & ehail_fee haben):\")\n",
    "    sql_green = f\"\"\"\n",
    "    SELECT \n",
    "        *\n",
    "    FROM `{table_ref}`\n",
    "    WHERE source_system = 'GREEN'\n",
    "    LIMIT 5\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df_g = client.query(sql_green).to_dataframe()\n",
    "        display(df_g)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "    # 3. FHV CHECK\n",
    "    # Fokus: Sind die neuen Base-Nummern da? Sind Preise WIRKLICH NULL?\n",
    "    print(\"\\nüñ§ FHV SAMPLE (Muss Base-Nummern haben, aber KEINE Preise):\")\n",
    "    sql_fhv = f\"\"\"\n",
    "    SELECT \n",
    "        *\n",
    "    FROM `{table_ref}`\n",
    "    WHERE source_system = 'FHV'\n",
    "    LIMIT 5\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df_f = client.query(sql_fhv).to_dataframe()\n",
    "        display(df_f)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "    # 4. STATISTIK\n",
    "    print(\"\\nüìä VERTEILUNG NACH SYSTEM:\")\n",
    "    sql_stats = f\"\"\"\n",
    "    SELECT source_system, COUNT(*) as count \n",
    "    FROM `{table_ref}` \n",
    "    GROUP BY source_system\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(client.query(sql_stats).to_dataframe())\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "check_data_samples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c2cd6f23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/88/9clxv4m57vjb1lzsxk3gkv2m0000gn/T/ipykernel_50106/1406648598.py:16: FutureWarning: to_gbq is deprecated and will be removed in a future version. Please use pandas_gbq.to_gbq instead: https://pandas-gbq.readthedocs.io/en/latest/api.html#pandas_gbq.to_gbq\n",
      "  df_to_upload.to_gbq('staging.taxi_zones_temp', project_id='taxi-bi-project', if_exists='replace')\n",
      "263 out of 263 rows loaded.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Tabelle taxi_zones_geo wurde mit 'borough' und 'zone' neu erstellt!\n"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "from google.cloud import bigquery\n",
    "\n",
    "client = bigquery.Client()\n",
    "\n",
    "# 1. GeoJSON mit allen Spalten laden\n",
    "geojson_path = '/Users/lania/Documents/GitHub/bi_project_task2/notebook_canonical/NYC_Taxi_Zones.geojson'\n",
    "gdf_zones = gpd.read_file(geojson_path)\n",
    "\n",
    "# 2. Alle wichtigen Spalten vorbereiten\n",
    "# Wir brauchen: location_id, zone, borough und die Geometrie als WKT\n",
    "gdf_zones['WKT_GEOMETRY'] = gdf_zones['geometry'].apply(lambda x: x.wkt)\n",
    "df_to_upload = gdf_zones[['location_id', 'zone', 'borough', 'WKT_GEOMETRY']].copy()\n",
    "\n",
    "# 3. Hochladen nach BigQuery (Temp-Tabelle)\n",
    "df_to_upload.to_gbq('staging.taxi_zones_temp', project_id='taxi-bi-project', if_exists='replace')\n",
    "\n",
    "# 4. Die finale Geo-Tabelle mit ALLEN Spalten erstellen\n",
    "fix_query = \"\"\"\n",
    "CREATE OR REPLACE TABLE `taxi-bi-project.staging.taxi_zones_geo` AS\n",
    "SELECT \n",
    "    CAST(location_id AS INT64) AS location_id,\n",
    "    zone,\n",
    "    borough,\n",
    "    ST_GEOGFROMTEXT(WKT_GEOMETRY) AS zone_geom\n",
    "FROM `taxi-bi-project.staging.taxi_zones_temp`;\n",
    "\"\"\"\n",
    "client.query(fix_query, location=\"EU\").result()\n",
    "\n",
    "print(\"‚úÖ Tabelle taxi_zones_geo wurde mit 'borough' und 'zone' neu erstellt!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460c8a4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Top Stadtbezirke im Juni 2010 ---\n",
      "pickup_borough  total_trips  avg_fare_usd  total_revenue_million_usd\n",
      "     Manhattan     13676019          9.30                     149.85\n",
      "        Queens       723918         24.90                      21.41\n",
      "      Brooklyn       271449         12.14                       3.81\n",
      "         Bronx        15879         11.28                       0.21\n",
      "           EWR         1309         61.50                       0.10\n",
      " Staten Island          910         12.68                       0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lania/Documents/GitHub/bi_project_task2/.venv/lib/python3.12/site-packages/google/cloud/bigquery/table.py:1994: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Bezirke in NYV\n",
    "from google.cloud import bigquery\n",
    "import pandas as pd\n",
    "\n",
    "client = bigquery.Client()\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT \n",
    "    z.borough AS pickup_borough,\n",
    "    COUNT(*) AS total_trips,\n",
    "    ROUND(AVG(fare_amount), 2) AS avg_fare_usd,\n",
    "    ROUND(SUM(total_amount) / 1000000, 2) AS total_revenue_million_usd\n",
    "FROM \n",
    "    `taxi-bi-project.canonical.canonical_unified_taxi` AS t\n",
    "LEFT JOIN \n",
    "    `taxi-bi-project.staging.taxi_zones_geo` AS z \n",
    "    ON t.pickup_location_id = z.location_id\n",
    "WHERE \n",
    "    EXTRACT(YEAR FROM t.pickup_datetime) = 2010\n",
    "GROUP BY \n",
    "    1\n",
    "ORDER BY \n",
    "    total_trips DESC\n",
    "\"\"\"\n",
    "\n",
    "try:\n",
    "    df_2010 = client.query(query, location=\"EU\").to_dataframe()\n",
    "    print(\"\\n--- Top Stadtbezirke im Juni 2010 ---\")\n",
    "    print(df_2010.to_string(index=False))\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Fehler: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89ee505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abfrage der Original-VendorIDs aus yellow_schema_5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lania/Documents/GitHub/bi_project_task2/.venv/lib/python3.12/site-packages/google/cloud/bigquery/table.py:1994: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Gefundene Anbieter in Schema 5 (2010) ---\n",
      "  vendor_id   anzahl\n",
      "0       VTS  7471719\n",
      "1       CMT  6670024\n",
      "2       DDS   683385\n"
     ]
    }
   ],
   "source": [
    "#Check Vendors in Yellow \n",
    "from google.cloud import bigquery\n",
    "\n",
    "client = bigquery.Client()\n",
    "\n",
    "# Wir fragen direkt die Tabelle yellow_schema_5 ab\n",
    "# Ich nutze hier 'vendor_id', da dies der Standardname in Schema 5 ist.\n",
    "# Falls es wirklich 'vendor_id' geschrieben wird, passen wir es an.\n",
    "query = \"\"\"\n",
    "SELECT \n",
    "    vendor_id, \n",
    "    COUNT(*) as anzahl\n",
    "FROM `taxi-bi-project.staging.yellow_schema_5`\n",
    "GROUP BY 1\n",
    "ORDER BY anzahl DESC\n",
    "\"\"\"\n",
    "\n",
    "print(\"Abfrage der Original-VendorIDs aus yellow_schema_5...\")\n",
    "\n",
    "try:\n",
    "    df_vendor_5 = client.query(query, location=\"EU\").to_dataframe()\n",
    "    print(\"\\n--- Gefundene Anbieter in Schema 5 (2010) ---\")\n",
    "    print(df_vendor_5)\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Fehler: {e}\")\n",
    "    print(\"\\nHinweis: Falls die Spalte anders geschrieben wird (z.B. vendor_name), versuche die Spaltenliste anzuzeigen.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "355c95d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lania/Documents/GitHub/bi_project_task2/.venv/lib/python3.12/site-packages/google/cloud/bigquery/table.py:1994: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   source_system  year                         rejection_reason        cnt\n",
      "0            FHV  2016              Incorrect: Invalid Duration  117677227\n",
      "1            FHV  2017              Incorrect: Invalid Duration   67187994\n",
      "2            FHV  2015              Incorrect: Invalid Duration   55302393\n",
      "3         YELLOW  2023  Incorrect: Invalid Pax Count (Rule 1.4)     581618\n",
      "4         YELLOW  2025                    Incorrect: Financials     244258\n",
      "5         YELLOW  2011  Incorrect: Invalid Pax Count (Rule 1.4)     238271\n",
      "6         YELLOW  2023                    Incorrect: Financials     225506\n",
      "7         YELLOW  2019  Incorrect: Invalid Pax Count (Rule 1.4)     127818\n",
      "8          GREEN  2015                    Incorrect: Financials      77079\n",
      "9         YELLOW  2018  Incorrect: Invalid Pax Count (Rule 1.4)      70559\n",
      "10        YELLOW  2025              Incorrect: Invalid Duration      68579\n",
      "11        YELLOW  2022  Incorrect: Invalid Pax Count (Rule 1.4)      68503\n",
      "12        YELLOW  2021  Incorrect: Invalid Pax Count (Rule 1.4)      66468\n",
      "13         GREEN  2016                    Incorrect: Financials      64712\n",
      "14        YELLOW  2013              Incorrect: Invalid Duration      52278\n",
      "15        YELLOW  2014              Incorrect: Invalid Duration      42266\n",
      "16        YELLOW  2024                    Incorrect: Financials      41253\n",
      "17         GREEN  2017                    Incorrect: Financials      41117\n",
      "18        YELLOW  2024  Incorrect: Invalid Pax Count (Rule 1.4)      35446\n",
      "19        YELLOW  2010              Incorrect: Invalid Duration      33786\n"
     ]
    }
   ],
   "source": [
    "# Debug Query: Woher kommen die 402 Millionen Fehler?\n",
    "query_debug = f\"\"\"\n",
    "SELECT \n",
    "    source_system, \n",
    "    EXTRACT(YEAR FROM pickup_datetime) as year,\n",
    "    rejection_reason, \n",
    "    COUNT(*) as cnt\n",
    "FROM `{error_table_ref}`\n",
    "GROUP BY 1, 2, 3\n",
    "ORDER BY cnt DESC\n",
    "LIMIT 20\n",
    "\"\"\"\n",
    "df_debug = client.query(query_debug).to_dataframe()\n",
    "print(df_debug)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

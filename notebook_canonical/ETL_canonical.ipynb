{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "37c66ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from google.cloud import bigquery\n",
    "from google.api_core.exceptions import NotFound\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# sorgt dafür, dass Plots im Notebook angezeigt werden\n",
    "%matplotlib inline\n",
    "\n",
    "# Lesbarkeit in der Exploration erhöhen\n",
    "pd.set_option(\"display.max_columns\", 200)\n",
    "pd.set_option(\"display.max_rows\", 200)\n",
    "pd.set_option(\"display.width\", 140)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3d68c4b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 'canonical' ist bereit.\n",
      "Ziel-Tabelle wird sein: taxi-bi-project.canonical.canonical_unified_taxi\n"
     ]
    }
   ],
   "source": [
    "# Zelle 1: Imports & Config\n",
    "from google.cloud import bigquery\n",
    "import logging\n",
    "\n",
    "# Logging Setup\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger()\n",
    "\n",
    "# --- KONFIGURATION ---\n",
    "PROJECT_ID = \"taxi-bi-project\"\n",
    "# Trennung: Wo liegen die Daten? Wohin sollen sie?\n",
    "SOURCE_DATASET = \"staging\"    # Hier liegen staging_yellow, staging_green, fhv\n",
    "TARGET_DATASET = \"canonical\"   # Hier soll die saubere Tabelle hin\n",
    "\n",
    "BQ_LOCATION = \"EU\"\n",
    "TARGET_TABLE = \"canonical_unified_taxi\"\n",
    "\n",
    "# Tabellennamen (Basierend auf deiner Exploration)\n",
    "STAGING_YELLOW = \"yellow_staging_unified\"\n",
    "STAGING_GREEN = \"green_staging_unified\"\n",
    "STAGING_FHV = \"fhv_staging_unified\" # <--- Name aus deinem Notebook übernommen\n",
    "\n",
    "# Client initialisieren\n",
    "client = bigquery.Client(project=PROJECT_ID)\n",
    "\n",
    "# WICHTIG: Das Ziel-Dataset 'canonical' muss existieren!\n",
    "# Wir erstellen es hier automatisch (Location 'EU' basierend auf deinem Fehlerlog)\n",
    "dataset_id = f\"{PROJECT_ID}.{TARGET_DATASET}\"\n",
    "dataset = bigquery.Dataset(dataset_id)\n",
    "dataset.location = \"EU\" # Falls deine Daten in US liegen, ändere dies auf \"US\"\n",
    "\n",
    "try:\n",
    "    client.create_dataset(dataset, exists_ok=True)\n",
    "    print(f\"Dataset '{TARGET_DATASET}' ist bereit.\")\n",
    "except Exception as e:\n",
    "    print(f\"Hinweis beim Dataset-Erstellen: {e}\")\n",
    "\n",
    "# Ziel-Referenz aktualisieren\n",
    "table_ref = f\"{PROJECT_ID}.{TARGET_DATASET}.{TARGET_TABLE}\"\n",
    "print(f\"Ziel-Tabelle wird sein: {table_ref}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "eef9b154",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabelle taxi-bi-project.canonical.canonical_unified_taxi wurde gelöscht (falls sie existierte).\n"
     ]
    }
   ],
   "source": [
    "# Zelle 3: Reset - Alte Tabelle löschen\n",
    "from google.api_core.exceptions import NotFound\n",
    "try:\n",
    "    client.delete_table(table_ref)\n",
    "    print(f\"Tabelle {table_ref} wurde gelöscht (falls sie existierte).\")\n",
    "except NotFound:\n",
    "    print(\"Tabelle existierte noch nicht. Alles okay.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f1e2eb52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zelle 4: DDL - Tabelle im Ziel-Dataset erstellen\n",
    "def create_canonical_table():\n",
    "    schema = [\n",
    "        bigquery.SchemaField(\"unique_row_id\", \"STRING\", description=\"Generierter Key\"),\n",
    "        bigquery.SchemaField(\"vendor_id\", \"STRING\"), \n",
    "        bigquery.SchemaField(\"rate_code_id\", \"INTEGER\"),\n",
    "        bigquery.SchemaField(\"payment_type\", \"INTEGER\"),\n",
    "        bigquery.SchemaField(\"pu_location_id\", \"INTEGER\"),\n",
    "        bigquery.SchemaField(\"do_location_id\", \"INTEGER\"),\n",
    "        bigquery.SchemaField(\"store_and_fwd_flag\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"pickup_datetime\", \"TIMESTAMP\"),\n",
    "        bigquery.SchemaField(\"dropoff_datetime\", \"TIMESTAMP\"),\n",
    "        bigquery.SchemaField(\"passenger_count\", \"INTEGER\"),\n",
    "        bigquery.SchemaField(\"trip_distance\", \"FLOAT\"),\n",
    "        bigquery.SchemaField(\"fare_amount\", \"NUMERIC\"),\n",
    "        bigquery.SchemaField(\"extra\", \"NUMERIC\"),\n",
    "        bigquery.SchemaField(\"mta_tax\", \"NUMERIC\"),\n",
    "        bigquery.SchemaField(\"tip_amount\", \"NUMERIC\"),\n",
    "        bigquery.SchemaField(\"tolls_amount\", \"NUMERIC\"),\n",
    "        bigquery.SchemaField(\"improvement_surcharge\", \"NUMERIC\"),\n",
    "        bigquery.SchemaField(\"congestion_surcharge\", \"NUMERIC\"),\n",
    "        bigquery.SchemaField(\"airport_fee\", \"NUMERIC\"),\n",
    "        bigquery.SchemaField(\"total_amount\", \"NUMERIC\"),\n",
    "        bigquery.SchemaField(\"source_type\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"valid_from\", \"TIMESTAMP\"),\n",
    "        bigquery.SchemaField(\"validation_status\", \"STRING\")\n",
    "    ]\n",
    "\n",
    "    table = bigquery.Table(table_ref, schema=schema)\n",
    "    \n",
    "    table.time_partitioning = bigquery.TimePartitioning(\n",
    "        type_=bigquery.TimePartitioningType.DAY, \n",
    "        field=\"pickup_datetime\"\n",
    "    )\n",
    "    table.clustering_fields = [\"vendor_id\", \"source_type\"]\n",
    "\n",
    "    try:\n",
    "        client.create_table(table)\n",
    "        print(f\"Tabelle {table_ref} erfolgreich angelegt.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Konnte Tabelle nicht anlegen (vielleicht existiert sie schon?): {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4a7e58dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zelle 5: ELT Transformation Query (Source -> Target)\n",
    "def run_transformation_query():\n",
    "    print(\"Bereite Transformation vor...\")\n",
    "    \n",
    "    START_DATE = '2015-01-01' \n",
    "    END_DATE = '2026-01-01'\n",
    "\n",
    "    # WICHTIG: Hier nutzen wir SOURCE_DATASET für das 'FROM'\n",
    "    query = f\"\"\"\n",
    "    -- (A) YELLOW\n",
    "    WITH yellow_clean AS (\n",
    "        SELECT 'yellow' as source_type, CAST(VendorID AS STRING) as vendor_id,\n",
    "        CAST(tpep_pickup_datetime AS TIMESTAMP) as pickup_datetime,\n",
    "        CAST(tpep_dropoff_datetime AS TIMESTAMP) as dropoff_datetime,\n",
    "        IFNULL(passenger_count, 1) as passenger_count, trip_distance, IFNULL(RatecodeID, 99) as rate_code_id,\n",
    "        IFNULL(store_and_fwd_flag, 'N') as store_and_fwd_flag, PULocationID as pu_location_id, DOLocationID as do_location_id,\n",
    "        payment_type,\n",
    "        GREATEST(IFNULL(fare_amount, 0), 0) as fare_amount, GREATEST(IFNULL(extra, 0), 0) as extra,\n",
    "        GREATEST(IFNULL(mta_tax, 0), 0) as mta_tax, GREATEST(IFNULL(tip_amount, 0), 0) as tip_amount,\n",
    "        GREATEST(IFNULL(tolls_amount, 0), 0) as tolls_amount, GREATEST(IFNULL(improvement_surcharge, 0), 0) as improvement_surcharge,\n",
    "        GREATEST(IFNULL(congestion_surcharge, 0), 0) as congestion_surcharge, GREATEST(IFNULL(airport_fee, 0), 0) as airport_fee\n",
    "        FROM `{PROJECT_ID}.{SOURCE_DATASET}.{STAGING_YELLOW}`\n",
    "    ),\n",
    "    -- (B) GREEN\n",
    "    green_clean AS (\n",
    "        SELECT 'green' as source_type, CAST(VendorID AS STRING) as vendor_id,\n",
    "        CAST(lpep_pickup_datetime AS TIMESTAMP) as pickup_datetime,\n",
    "        CAST(lpep_dropoff_datetime AS TIMESTAMP) as dropoff_datetime,\n",
    "        IFNULL(passenger_count, 1) as passenger_count, trip_distance, IFNULL(RatecodeID, 99) as rate_code_id,\n",
    "        IFNULL(store_and_fwd_flag, 'N') as store_and_fwd_flag, PULocationID as pu_location_id, DOLocationID as do_location_id,\n",
    "        payment_type,\n",
    "        GREATEST(IFNULL(fare_amount, 0), 0) as fare_amount, GREATEST(IFNULL(extra, 0), 0) as extra,\n",
    "        GREATEST(IFNULL(mta_tax, 0), 0) as mta_tax, GREATEST(IFNULL(tip_amount, 0), 0) as tip_amount,\n",
    "        GREATEST(IFNULL(tolls_amount, 0), 0) as tolls_amount, GREATEST(IFNULL(improvement_surcharge, 0), 0) as improvement_surcharge,\n",
    "        GREATEST(IFNULL(congestion_surcharge, 0), 0) as congestion_surcharge, 0 as airport_fee\n",
    "        FROM `{PROJECT_ID}.{SOURCE_DATASET}.{STAGING_GREEN}`\n",
    "    ),\n",
    "    -- (C) FHV\n",
    "    fhv_clean AS (\n",
    "        SELECT 'fhv' as source_type, dispatching_base_num as vendor_id,\n",
    "        CAST(pickup_datetime AS TIMESTAMP) as pickup_datetime,\n",
    "        CAST(dropOff_datetime AS TIMESTAMP) as dropoff_datetime,\n",
    "        1 as passenger_count, NULL as trip_distance, 99 as rate_code_id, 'N' as store_and_fwd_flag,\n",
    "        PULocationID as pu_location_id, DOLocationID as do_location_id, NULL as payment_type,\n",
    "        NULL as fare_amount, NULL as extra, NULL as mta_tax, NULL as tip_amount,\n",
    "        NULL as tolls_amount, NULL as improvement_surcharge, NULL as congestion_surcharge, NULL as airport_fee\n",
    "        FROM `{PROJECT_ID}.{SOURCE_DATASET}.{STAGING_FHV}`\n",
    "    ),\n",
    "    -- (D) Union\n",
    "    final_logic AS (\n",
    "        SELECT * FROM yellow_clean UNION ALL SELECT * FROM green_clean UNION ALL SELECT * FROM fhv_clean\n",
    "    )\n",
    "\n",
    "    -- (E) Write to Target\n",
    "    SELECT \n",
    "        FARM_FINGERPRINT(CONCAT(source_type, CAST(pickup_datetime AS STRING), IFNULL(vendor_id, ''))) as unique_row_id,\n",
    "        *,\n",
    "        (IFNULL(fare_amount,0) + IFNULL(extra,0) + IFNULL(mta_tax,0) + IFNULL(tolls_amount,0) + \n",
    "         IFNULL(improvement_surcharge,0) + IFNULL(congestion_surcharge,0) + IFNULL(airport_fee,0)) as total_amount,\n",
    "        CURRENT_TIMESTAMP() as valid_from, \n",
    "        'VALID' as validation_status\n",
    "    FROM final_logic\n",
    "    WHERE \n",
    "      pickup_datetime < dropoff_datetime \n",
    "      AND (trip_distance IS NULL OR (trip_distance >= 0 AND trip_distance < 1000))\n",
    "      AND pickup_datetime >= TIMESTAMP('{START_DATE}') \n",
    "      AND pickup_datetime < TIMESTAMP('{END_DATE}')\n",
    "\n",
    "    QUALIFY ROW_NUMBER() OVER (PARTITION BY source_type, pickup_datetime, dropoff_datetime, vendor_id ORDER BY pickup_datetime) = 1\n",
    "    \"\"\"\n",
    "\n",
    "    # HIER nutzen wir table_ref (welches auf TARGET_DATASET zeigt)\n",
    "    job_config = bigquery.QueryJobConfig(\n",
    "        destination=table_ref,\n",
    "        write_disposition=\"WRITE_TRUNCATE\"\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        print(\"Starte Query auf BigQuery...\")\n",
    "        query_job = client.query(query, job_config=job_config)\n",
    "        query_job.result()\n",
    "        print(f\"ERFOLG! Daten wurden in {table_ref} gespeichert.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Fehler im Query Job: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "35b50f90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabelle taxi-bi-project.canonical.canonical_unified_taxi erfolgreich angelegt.\n",
      "Bereite Transformation vor...\n",
      "Starte Query auf BigQuery...\n",
      "ERFOLG! Daten wurden in taxi-bi-project.canonical.canonical_unified_taxi gespeichert.\n"
     ]
    }
   ],
   "source": [
    "# Zelle 6: Pipeline ausführen\n",
    "create_canonical_table()\n",
    "run_transformation_query()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "33c669e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Check Results ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lania/Documents/GitHub/bi_project_task2/.venv/lib/python3.12/site-packages/google/cloud/bigquery/table.py:1994: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Zeilen pro Typ:\n",
      "  source_type        cnt\n",
      "0      yellow  101134534\n",
      "1       green   67736493\n",
      "2         fhv  514439669\n",
      "\n",
      "Vorschau (5 Zeilen):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lania/Documents/GitHub/bi_project_task2/.venv/lib/python3.12/site-packages/google/cloud/bigquery/table.py:1994: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_row_id</th>\n",
       "      <th>source_type</th>\n",
       "      <th>vendor_id</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>rate_code_id</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>pu_location_id</th>\n",
       "      <th>do_location_id</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "      <th>airport_fee</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>valid_from</th>\n",
       "      <th>validation_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7646351569098648074</td>\n",
       "      <td>green</td>\n",
       "      <td>2</td>\n",
       "      <td>2015-12-21 16:02:56+00:00</td>\n",
       "      <td>2015-12-21 16:04:14+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>193</td>\n",
       "      <td>193</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2025-12-23 12:15:02.305718+00:00</td>\n",
       "      <td>VALID</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8321490569331597801</td>\n",
       "      <td>green</td>\n",
       "      <td>2</td>\n",
       "      <td>2015-12-21 20:21:31+00:00</td>\n",
       "      <td>2015-12-21 20:23:40+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.44</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>49</td>\n",
       "      <td>61</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2025-12-23 12:15:02.305718+00:00</td>\n",
       "      <td>VALID</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1769977943478882486</td>\n",
       "      <td>green</td>\n",
       "      <td>2</td>\n",
       "      <td>2015-12-21 10:15:16+00:00</td>\n",
       "      <td>2015-12-21 10:19:25+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.81</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>244</td>\n",
       "      <td>244</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2025-12-23 12:15:02.305718+00:00</td>\n",
       "      <td>VALID</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-6282569189110701693</td>\n",
       "      <td>green</td>\n",
       "      <td>2</td>\n",
       "      <td>2015-12-21 22:41:35+00:00</td>\n",
       "      <td>2015-12-21 22:44:56+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>33</td>\n",
       "      <td>33</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2025-12-23 12:15:02.305718+00:00</td>\n",
       "      <td>VALID</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7995879999250307598</td>\n",
       "      <td>green</td>\n",
       "      <td>2</td>\n",
       "      <td>2015-12-21 14:47:27+00:00</td>\n",
       "      <td>2015-12-21 14:47:34+00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>247</td>\n",
       "      <td>247</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2025-12-23 12:15:02.305718+00:00</td>\n",
       "      <td>VALID</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          unique_row_id source_type vendor_id           pickup_datetime          dropoff_datetime  passenger_count  trip_distance  \\\n",
       "0   7646351569098648074       green         2 2015-12-21 16:02:56+00:00 2015-12-21 16:04:14+00:00                1           0.00   \n",
       "1   8321490569331597801       green         2 2015-12-21 20:21:31+00:00 2015-12-21 20:23:40+00:00                1           0.44   \n",
       "2   1769977943478882486       green         2 2015-12-21 10:15:16+00:00 2015-12-21 10:19:25+00:00                1           0.81   \n",
       "3  -6282569189110701693       green         2 2015-12-21 22:41:35+00:00 2015-12-21 22:44:56+00:00                1           0.70   \n",
       "4   7995879999250307598       green         2 2015-12-21 14:47:27+00:00 2015-12-21 14:47:34+00:00                2           0.00   \n",
       "\n",
       "   rate_code_id store_and_fwd_flag  pu_location_id  do_location_id  payment_type  fare_amount  extra  mta_tax  tip_amount  tolls_amount  \\\n",
       "0             1                  N             193             193             1          0.0    0.0      0.0         0.0           0.0   \n",
       "1             1                  N              49              61             3          0.0    0.0      0.0         0.0           0.0   \n",
       "2             1                  N             244             244             4          0.0    0.0      0.0         0.0           0.0   \n",
       "3             1                  N              33              33             3          0.0    0.0      0.0         0.0           0.0   \n",
       "4             1                  N             247             247             3          0.0    0.0      0.0         0.0           0.0   \n",
       "\n",
       "   improvement_surcharge  congestion_surcharge  airport_fee  total_amount                       valid_from validation_status  \n",
       "0                    0.0                   0.0          0.0           0.0 2025-12-23 12:15:02.305718+00:00             VALID  \n",
       "1                    0.0                   0.0          0.0           0.0 2025-12-23 12:15:02.305718+00:00             VALID  \n",
       "2                    0.0                   0.0          0.0           0.0 2025-12-23 12:15:02.305718+00:00             VALID  \n",
       "3                    0.0                   0.0          0.0           0.0 2025-12-23 12:15:02.305718+00:00             VALID  \n",
       "4                    0.0                   0.0          0.0           0.0 2025-12-23 12:15:02.305718+00:00             VALID  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Zelle 7: Ergebnis prüfen\n",
    "print(\"--- Check Results ---\")\n",
    "try:\n",
    "    # Zählen\n",
    "    count_query = f\"SELECT source_type, count(*) as cnt FROM `{table_ref}` GROUP BY 1\"\n",
    "    df_count = client.query(count_query).to_dataframe()\n",
    "    print(\"\\nZeilen pro Typ:\")\n",
    "    print(df_count)\n",
    "    \n",
    "    # Vorschau\n",
    "    print(\"\\nVorschau (5 Zeilen):\")\n",
    "    df_sample = client.query(f\"SELECT * FROM `{table_ref}` LIMIT 5\").to_dataframe()\n",
    "    display(df_sample) # oder print(df_sample)\n",
    "except Exception as e:\n",
    "    print(f\"Konnte Daten nicht lesen: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

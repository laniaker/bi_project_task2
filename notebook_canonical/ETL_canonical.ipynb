{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c66ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zelle 1: Setup & Config\n",
    "from google.cloud import bigquery\n",
    "from google.api_core.exceptions import NotFound\n",
    "\n",
    "import pandas as pd\n",
    "import uuid\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# sorgt dafür, dass Plots im Notebook angezeigt werden\n",
    "%matplotlib inline\n",
    "\n",
    "# Lesbarkeit in der Exploration erhöhen\n",
    "pd.set_option(\"display.max_columns\", 200)\n",
    "pd.set_option(\"display.max_rows\", 200)\n",
    "pd.set_option(\"display.width\", 140)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d68c4b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 'canonical' ist bereit.\n",
      "Ziel-Tabelle wird sein: taxi-bi-project.canonical.canonical_unified_taxi\n"
     ]
    }
   ],
   "source": [
    "# Zelle 1: Imports & Config\n",
    "from google.cloud import bigquery\n",
    "import logging\n",
    "\n",
    "# Logging Setup\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger()\n",
    "\n",
    "# --- KONFIGURATION ---\n",
    "PROJECT_ID = \"taxi-bi-project\"\n",
    "# Trennung: Wo liegen die Daten? Wohin sollen sie?\n",
    "SOURCE_DATASET = \"staging\"    # Hier liegen staging_yellow, staging_green, fhv\n",
    "TARGET_DATASET = \"canonical\"   # Hier soll die saubere Tabelle hin\n",
    "# Tabellennamen (Basierend auf deiner Exploration)\n",
    "STAGING_YELLOW = \"yellow_staging_unified\"\n",
    "STAGING_GREEN = \"green_staging_unified\"\n",
    "STAGING_FHV = \"fhv_staging_unified\" # <--- Name aus deinem Notebook übernommen\n",
    "\n",
    "BQ_LOCATION = \"EU\"\n",
    "# Tabellen\n",
    "TARGET_TABLE = \"canonical_unified_taxi\"\n",
    "ERROR_TABLE = \"error_records\"\n",
    "LOG_TABLE = \"etl_process_log\"\n",
    "\n",
    "# Client\n",
    "client = bigquery.Client(project=PROJECT_ID)\n",
    "\n",
    "# Dataset Location Check (verhindert 404 Fehler)\n",
    "try:\n",
    "    src_ds = client.get_dataset(f\"{PROJECT_ID}.{SOURCE_DATASET}\")\n",
    "    LOCATION = src_ds.location\n",
    "    print(f\"Region erkannt: {LOCATION}\")\n",
    "    \n",
    "    # Ziel-Dataset anlegen/prüfen\n",
    "    tgt_ref = bigquery.Dataset(f\"{PROJECT_ID}.{TARGET_DATASET}\")\n",
    "    tgt_ref.location = LOCATION\n",
    "    client.create_dataset(tgt_ref, exists_ok=True)\n",
    "    print(f\"Ziel-Dataset '{TARGET_DATASET}' ist bereit.\")\n",
    "except Exception as e:\n",
    "    print(f\"Setup-Fehler: {e}\")\n",
    "\n",
    "# Referenzen\n",
    "table_ref = f\"{PROJECT_ID}.{TARGET_DATASET}.{TARGET_TABLE}\"\n",
    "error_table_ref = f\"{PROJECT_ID}.{TARGET_DATASET}.{ERROR_TABLE}\"\n",
    "log_table_ref = f\"{PROJECT_ID}.{TARGET_DATASET}.{LOG_TABLE}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5f2caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zelle 2: Tabellen-DDL (Canonical & Error & Log)\n",
    "def create_all_tables():\n",
    "    # 1. Schema für Taxi-Daten (Valid & Error sind fast identisch)\n",
    "    base_schema = [\n",
    "        bigquery.SchemaField(\"trip_id\", \"STRING\", description=\"Unique ID für ALLE\"),\n",
    "        bigquery.SchemaField(\"source_system\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"load_date\", \"TIMESTAMP\"),\n",
    "        bigquery.SchemaField(\"vendor_id\", \"STRING\"), \n",
    "        bigquery.SchemaField(\"pickup_datetime\", \"TIMESTAMP\"),\n",
    "        bigquery.SchemaField(\"dropoff_datetime\", \"TIMESTAMP\"),\n",
    "        bigquery.SchemaField(\"pickup_location_id\", \"INTEGER\"),\n",
    "        bigquery.SchemaField(\"dropoff_location_id\", \"INTEGER\"),\n",
    "        bigquery.SchemaField(\"passenger_count\", \"INTEGER\"),\n",
    "        bigquery.SchemaField(\"trip_distance\", \"FLOAT\"),\n",
    "        bigquery.SchemaField(\"store_and_fwd_flag\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"fare_amount\", \"FLOAT\"),\n",
    "        bigquery.SchemaField(\"tip_amount\", \"FLOAT\"),\n",
    "        bigquery.SchemaField(\"total_amount\", \"FLOAT\"),\n",
    "        bigquery.SchemaField(\"payment_type\", \"INTEGER\"),\n",
    "        bigquery.SchemaField(\"is_shared_ride\", \"BOOLEAN\"),\n",
    "        bigquery.SchemaField(\"dq_issue_flag\", \"BOOLEAN\") # Soft Validation\n",
    "    ]\n",
    "\n",
    "    # Error Tabelle bekommt eine Zusatz-Spalte\n",
    "    error_schema = base_schema + [bigquery.SchemaField(\"rejection_reason\", \"STRING\")]\n",
    "\n",
    "    # Log Schema\n",
    "    log_schema = [\n",
    "        bigquery.SchemaField(\"run_id\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"start_time\", \"TIMESTAMP\"),\n",
    "        bigquery.SchemaField(\"status\", \"STRING\"),\n",
    "        bigquery.SchemaField(\"valid_rows\", \"INTEGER\"),\n",
    "        bigquery.SchemaField(\"error_rows\", \"INTEGER\"),\n",
    "        bigquery.SchemaField(\"error_msg\", \"STRING\")\n",
    "    ]\n",
    "\n",
    "    # Tabellen anlegen\n",
    "    tables_to_create = [\n",
    "        (table_ref, base_schema),\n",
    "        (error_table_ref, error_schema),\n",
    "        (log_table_ref, log_schema)\n",
    "    ]\n",
    "\n",
    "    for t_ref, t_schema in tables_to_create:\n",
    "        try:\n",
    "            t = bigquery.Table(t_ref, schema=t_schema)\n",
    "            # Partitionierung für Performance\n",
    "            if \"log\" in t_ref:\n",
    "                t.time_partitioning = bigquery.TimePartitioning(field=\"start_time\")\n",
    "            else:\n",
    "                t.time_partitioning = bigquery.TimePartitioning(field=\"pickup_datetime\")\n",
    "            \n",
    "            client.create_table(t, exists_ok=True)\n",
    "            print(f\"Tabelle bereit: {t_ref.split('.')[-1]}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Fehler bei {t_ref}: {e}\")\n",
    "\n",
    "create_all_tables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef9b154",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabelle taxi-bi-project.canonical.canonical_unified_taxi wurde gelöscht (falls sie existierte).\n"
     ]
    }
   ],
   "source": [
    "# Zelle: Reset - Alte Tabelle löschen\n",
    "from google.api_core.exceptions import NotFound\n",
    "try:\n",
    "    client.delete_table(table_ref)\n",
    "    print(f\"Tabelle {table_ref} wurde gelöscht (falls sie existierte).\")\n",
    "except NotFound:\n",
    "    print(\"Tabelle existierte noch nicht. Alles okay.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e2eb52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zelle 3: ETL Pipeline (Split: Valid vs. Error)\n",
    "def run_etl_split_logic():\n",
    "    print(\"Starte ETL mit Error-Handling & Unique IDs...\")\n",
    "    \n",
    "    run_id = str(uuid.uuid4())\n",
    "    start_ts = datetime.datetime.now(datetime.timezone.utc)\n",
    "    \n",
    "    # Filter-Konstanten\n",
    "    START_DATE = '2015-01-01'\n",
    "    END_DATE = '2026-01-01'\n",
    "\n",
    "    # Das SQL Skript\n",
    "    query = f\"\"\"\n",
    "    BEGIN\n",
    "        -- 1. Temp Tabelle mit ALLEN Daten (Roh-Harmonisierung)\n",
    "        CREATE TEMP TABLE temp_all_trips AS\n",
    "        WITH raw_combined AS (\n",
    "            -- (A) YELLOW\n",
    "            SELECT \n",
    "                'YELLOW' as source, CAST(VendorID AS STRING) as vid,\n",
    "                CAST(tpep_pickup_datetime AS TIMESTAMP) as t_pick, CAST(tpep_dropoff_datetime AS TIMESTAMP) as t_drop,\n",
    "                PULocationID as loc_pu, DOLocationID as loc_do,\n",
    "                IFNULL(passenger_count, 1) as pax, trip_distance as dist, IFNULL(store_and_fwd_flag, 'N') as flag,\n",
    "                GREATEST(IFNULL(fare_amount, 0), 0) as fare, GREATEST(IFNULL(tip_amount, 0), 0) as tip, GREATEST(IFNULL(total_amount, 0), 0) as total,\n",
    "                IFNULL(payment_type, 0) as pay_type, FALSE as shared,\n",
    "                GREATEST(IFNULL(airport_fee, 0), 0) as air_fee\n",
    "            FROM `{PROJECT_ID}.{SOURCE_DATASET}.staging_yellow_taxi`\n",
    "            \n",
    "            UNION ALL\n",
    "            \n",
    "            -- (B) GREEN\n",
    "            SELECT \n",
    "                'GREEN', CAST(VendorID AS STRING),\n",
    "                CAST(lpep_pickup_datetime AS TIMESTAMP), CAST(lpep_dropoff_datetime AS TIMESTAMP),\n",
    "                PULocationID, DOLocationID,\n",
    "                IFNULL(passenger_count, 1), trip_distance, IFNULL(store_and_fwd_flag, 'N'),\n",
    "                GREATEST(IFNULL(fare_amount, 0), 0), GREATEST(IFNULL(tip_amount, 0), 0), GREATEST(IFNULL(total_amount, 0), 0),\n",
    "                IFNULL(payment_type, 0), FALSE, 0\n",
    "            FROM `{PROJECT_ID}.{SOURCE_DATASET}.staging_green_taxi`\n",
    "\n",
    "            UNION ALL\n",
    "\n",
    "            -- (C) FHV\n",
    "            SELECT \n",
    "                'FHV', dispatching_base_num,\n",
    "                CAST(pickup_datetime AS TIMESTAMP), CAST(dropOff_datetime AS TIMESTAMP),\n",
    "                PULocationID, DOLocationID,\n",
    "                NULL, NULL, 'N', -- Pax & Dist NULL\n",
    "                NULL, NULL, NULL, -- Finanzen NULL\n",
    "                NULL, -- Payment Type\n",
    "                IF(CAST(SR_Flag AS STRING)='1', TRUE, FALSE), -- Shared Ride Check\n",
    "                NULL -- Air Fee\n",
    "            FROM `{PROJECT_ID}.{SOURCE_DATASET}.fhv_unified`\n",
    "        )\n",
    "        \n",
    "        -- Anreichern mit ID und DQ-Checks\n",
    "        SELECT\n",
    "            FARM_FINGERPRINT(CONCAT(source, CAST(t_pick AS STRING), IFNULL(vid,''))) as trip_id,\n",
    "            source as source_system,\n",
    "            CURRENT_TIMESTAMP() as load_date,\n",
    "            vid as vendor_id,\n",
    "            t_pick as pickup_datetime,\n",
    "            t_drop as dropoff_datetime,\n",
    "            loc_pu as pickup_location_id,\n",
    "            loc_do as dropoff_location_id,\n",
    "            pax as passenger_count,\n",
    "            dist as trip_distance,\n",
    "            flag as store_and_fwd_flag,\n",
    "            fare as fare_amount,\n",
    "            tip as tip_amount,\n",
    "            total as total_amount,\n",
    "            pay_type as payment_type,\n",
    "            shared as is_shared_ride,\n",
    "            \n",
    "            -- SOFT VALIDATION (DQ Issue Flag) -> Landet in Canonical, aber markiert\n",
    "            CASE \n",
    "                WHEN dist > 500 THEN TRUE\n",
    "                WHEN source IN ('YELLOW', 'GREEN') AND pax > 5 THEN TRUE\n",
    "                WHEN pay_type = 2 AND tip > 10 THEN TRUE\n",
    "                WHEN air_fee > 0 AND (loc_pu NOT IN (132, 138) AND loc_do NOT IN (132, 138)) THEN TRUE\n",
    "                ELSE FALSE \n",
    "            END as dq_issue_flag,\n",
    "\n",
    "            -- HARD VALIDATION (Rejection Logic) -> Bestimmt Ziel-Tabelle\n",
    "            CASE\n",
    "                WHEN t_pick IS NULL OR t_drop IS NULL THEN 'Missing Timestamps'\n",
    "                WHEN t_pick >= t_drop THEN 'Negative Duration'\n",
    "                WHEN t_pick < TIMESTAMP('{START_DATE}') THEN 'Date too old (<2015)'\n",
    "                WHEN t_pick > CURRENT_TIMESTAMP() THEN 'Future Date'\n",
    "                ELSE 'VALID'\n",
    "            END as row_status\n",
    "\n",
    "        FROM raw_combined;\n",
    "\n",
    "        -- 2. Clean Table befüllen (Nur VALID)\n",
    "        CREATE OR REPLACE TABLE `{table_ref}` AS\n",
    "        SELECT * EXCEPT(row_status)\n",
    "        FROM temp_all_trips\n",
    "        WHERE row_status = 'VALID';\n",
    "\n",
    "        -- 3. Error Table befüllen (Nur INVALID)\n",
    "        CREATE OR REPLACE TABLE `{error_table_ref}` AS\n",
    "        SELECT * EXCEPT(row_status), row_status as rejection_reason\n",
    "        FROM temp_all_trips\n",
    "        WHERE row_status != 'VALID';\n",
    "\n",
    "    END;\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        # Job starten\n",
    "        query_job = client.query(query)\n",
    "        query_job.result() # Warten auf Fertigstellung\n",
    "        \n",
    "        # Statistik holen\n",
    "        cnt_valid = client.get_table(table_ref).num_rows\n",
    "        cnt_error = client.get_table(error_table_ref).num_rows\n",
    "        status = \"SUCCESS\"\n",
    "        print(f\"✅ Fertig! Valid: {cnt_valid} | Errors: {cnt_error}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Fehler: {e}\")\n",
    "        status = \"FAILURE\"\n",
    "        cnt_valid = 0\n",
    "        cnt_error = 0\n",
    "        error_msg = str(e)\n",
    "    \n",
    "    # Log schreiben\n",
    "    try:\n",
    "        end_ts = datetime.datetime.now(datetime.timezone.utc)\n",
    "        client.insert_rows_json(log_table_ref, [{\n",
    "            \"run_id\": run_id,\n",
    "            \"start_time\": start_ts.isoformat(),\n",
    "            \"status\": status,\n",
    "            \"valid_rows\": cnt_valid,\n",
    "            \"error_rows\": cnt_error,\n",
    "            \"error_msg\": str(error_msg) if 'error_msg' in locals() else None\n",
    "        }])\n",
    "        print(\"Log geschrieben.\")\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "run_etl_split_logic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7e58dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zelle 4: Quality Check\n",
    "print(\"--- CLEAN DATA SAMPLE ---\")\n",
    "print(client.query(f\"SELECT * FROM `{table_ref}` LIMIT 3\").to_dataframe().T)\n",
    "\n",
    "print(\"\\n--- ERROR DATA SAMPLE (Warum abgelehnt?) ---\")\n",
    "try:\n",
    "    err_df = client.query(f\"SELECT rejection_reason, count(*) as cnt FROM `{error_table_ref}` GROUP BY 1\").to_dataframe()\n",
    "    print(err_df)\n",
    "except:\n",
    "    print(\"Keine Fehler gefunden (Tabelle leer).\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
